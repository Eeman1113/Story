{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "S9mG5JW9wRxt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "S9mG5JW9wRxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "! mkdir /content/docs\n",
        "! cd /content/docs && gdown 1HLxs_x2_Ji4fHCsi5fXcnts5ChPqloe9\n",
        "! echo \"##### Click and drag you resume to the ./docs folder after pressing the files button. An example resume has been added for now #####\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKZIX8SfEFfI",
        "outputId": "cb09187f-f3bd-46dc-d494-6f4b3b2da0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "mkdir: cannot create directory ‘/content/docs’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HLxs_x2_Ji4fHCsi5fXcnts5ChPqloe9\n",
            "To: /content/docs/kenji_gamer_resume.pdf\n",
            "100% 52.0k/52.0k [00:00<00:00, 94.2MB/s]\n",
            "##### Click and drag you resume to the ./docs folder after pressing the files button. An example resume has been added for now #####\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcwkQ3OO-C93",
        "outputId": "c7ba8965-a932-4b6b-899f-bf86ae8340e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 257 kB in 2s (115 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "lshw is already the newest version (02.19.git.2021.06.19.996aaad9c7-2build1).\n",
            "pciutils is already the newest version (1:3.7.0-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "! sudo apt update && sudo apt install pciutils lshw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rza-KZA-D5a",
        "outputId": "704f22b0-0712-4277-d5cf-f5e86b09f44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > ollama.log 2>&1 &"
      ],
      "metadata": {
        "id": "RWnHhM4--F8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ollama run gemma3:12b “write a story on moon”"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nB_d-V_-IAB",
        "outputId": "4e608443-c64a-4cfe-f5cc-3bdd28f6e1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[K\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25hOkay\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h here\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h story\u001b[?25l\u001b[?25h about\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Moon\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h aiming\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h blend\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h wonder\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h touch\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h melancholy\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h unique\u001b[?25l\u001b[?25h perspective\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hve\u001b[?25l\u001b[?25h tried\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h give\u001b[?25l\u001b[?25h it\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h slightly\u001b[?25l\u001b[?25h poetic\u001b[?25l\u001b[?25h feel\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hI\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hve\u001b[?25l\u001b[?25h included\u001b[?25l\u001b[?25h some\u001b[?25l\u001b[?25h notes\u001b[?25l\u001b[?25h at\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h end\u001b[?25l\u001b[?25h about\u001b[?25l\u001b[?25h what\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h was\u001b[?25l\u001b[?25h aiming\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h terms\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h tone\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h style\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hThe\u001b[?25l\u001b[?25h Moon\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h Long\u001b[?25l\u001b[?25h Sigh\u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hEl\u001b[?25l\u001b[?25hara\u001b[?25l\u001b[?25h wasn\u001b[?25l\u001b[?25h’\u001b[?25l\u001b[?25ht\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h goddess\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h not\u001b[?25l\u001b[?25h really\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h She\u001b[?25l\u001b[?25h was\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Moon\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Not\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h face\u001b[?25l\u001b[?25h people\u001b[?25l\u001b[?25h saw\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h dark\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h cold\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h distant\u001b[?25l\u001b[?25h orb\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h but\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h essence\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h it\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h She\u001b[?25l\u001b[?25h *\u001b[?25l\u001b[?25hfelt\u001b[?25l\u001b[?25h*\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h tides\u001b[?25l\u001b[?25h tug\u001b[?25l\u001b[?25hging\u001b[?25l\u001b[?25h at\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h oceans\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h way\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h earth\u001b[?25l\u001b[?25h hum\u001b[?25l\u001b[?25hmed\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h secret\u001b[?25l\u001b[?25h pulse\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h silent\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h yearning\u001b[?25l\u001b[?25h cries\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h creatures\u001b[?25l\u001b[?25h bathed\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h silver\u001b[?25l\u001b[?25h light\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hAnd\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h felt\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h loneliness\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h A\u001b[?25l\u001b[?25h vast\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h echoing\u001b[?25l\u001b[?25h loneliness\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h stretched\u001b[?25l\u001b[?25h across\u001b[?25l\u001b[?25h e\u001b[?25l\u001b[?25hons\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h remembered\u001b[?25l\u001b[?25h being\u001b[?25l\u001b[?25h new\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h A\u001b[?25l\u001b[?25h molten\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h chaotic\u001b[?25l\u001b[?25h companion\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h locked\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h violent\u001b[?25l\u001b[?25h dance\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h young\u001b[?25l\u001b[?25h Earth\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h felt\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h fiery\u001b[?25l\u001b[?25h rain\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h asteroids\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h relentless\u001b[?25l\u001b[?25h bombardment\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h shaped\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h surface\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h slow\u001b[?25l\u001b[?25h cooling\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h brought\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h into\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h quiet\u001b[?25l\u001b[?25h majesty\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h now\u001b[?25l\u001b[?25h possessed\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h’\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h seen\u001b[?25l\u001b[?25h continents\u001b[?25l\u001b[?25h drift\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h mountains\u001b[?25l\u001b[?25h rise\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h crumble\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h oceans\u001b[?25l\u001b[?25h swallow\u001b[?25l\u001b[?25h land\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h then\u001b[?25l\u001b[?25h retreat\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h She\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h watched\u001b[?25l\u001b[?25h life\u001b[?25l\u001b[?25h bloom\u001b[?25l\u001b[?25h on\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h planet\u001b[?25l\u001b[?25h below\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h riot\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h color\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h sound\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h then\u001b[?25l\u001b[?25h fade\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h leaving\u001b[?25l\u001b[?25h only\u001b[?25l\u001b[?25h faint\u001b[?25l\u001b[?25h echoes\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h rock\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h’\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h heard\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h stories\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h too\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hThe\u001b[?25l\u001b[?25h whispers\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h ancient\u001b[?25l\u001b[?25h civilizations\u001b[?25l\u001b[?25h who\u001b[?25l\u001b[?25h built\u001b[?25l\u001b[?25h towering\u001b[?25l\u001b[?25h structures\u001b[?25l\u001b[?25h dedicated\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h weaving\u001b[?25l\u001b[?25h myths\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h legends\u001b[?25l\u001b[?25h around\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h phases\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h She\u001b[?25l\u001b[?25h felt\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h awe\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h fear\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h hope\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h’\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h seen\u001b[?25l\u001b[?25h lovers\u001b[?25l\u001b[?25h pledge\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h devotion\u001b[?25l\u001b[?25h beneath\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h glow\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h mour\u001b[?25l\u001b[?25hners\u001b[?25l\u001b[?25h weep\u001b[?25l\u001b[?25h under\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h silent\u001b[?25l\u001b[?25h gaze\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hTheir\u001b[?25l\u001b[?25h stories\u001b[?25l\u001b[?25h faded\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h course\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Empires\u001b[?25l\u001b[?25h crumbled\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h languages\u001b[?25l\u001b[?25h died\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h stars\u001b[?25l\u001b[?25h wink\u001b[?25l\u001b[?25hed\u001b[?25l\u001b[?25h out\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hBut\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h remembered\u001b[?25l\u001b[?25h them\u001b[?25l\u001b[?25h all\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h They\u001b[?25l\u001b[?25h were\u001b[?25l\u001b[?25h woven\u001b[?25l\u001b[?25h into\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h dust\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h clung\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h surface\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h etched\u001b[?25l\u001b[?25h into\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h craters\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h scarred\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h face\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hThe\u001b[?25l\u001b[?25h humans\u001b[?25l\u001b[?25h…\u001b[?25l\u001b[?25h they\u001b[?25l\u001b[?25h were\u001b[?25l\u001b[?25h different\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h They\u001b[?25l\u001b[?25h reached\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h First\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h prayers\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h offerings\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h then\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h telescopes\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h rockets\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h felt\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h probing\u001b[?25l\u001b[?25h eyes\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h insistent\u001b[?25l\u001b[?25h questions\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hThey\u001b[?25l\u001b[?25h walked\u001b[?25l\u001b[?25h on\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h surface\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h left\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h footprints\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h dust\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hA\u001b[?25l\u001b[?25h brief\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h intense\u001b[?25l\u001b[?25h flicker\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h connection\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hA\u001b[?25l\u001b[?25h flurry\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h activity\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h felt\u001b[?25l\u001b[?25h like\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h fleeting\u001b[?25l\u001b[?25h touch\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h And\u001b[?25l\u001b[?25h then\u001b[?25l\u001b[?25h...\u001b[?25l\u001b[?25h they\u001b[?25l\u001b[?25h left\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h didn\u001b[?25l\u001b[?25h’\u001b[?25l\u001b[?25ht\u001b[?25l\u001b[?25h begr\u001b[?25l\u001b[?25hudge\u001b[?25l\u001b[?25h them\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h curiosity\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h She\u001b[?25l\u001b[?25h understood\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h urge\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h explore\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h conquer\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h leave\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h mark\u001b[?25l\u001b[?25h on\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h universe\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h But\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h absence\u001b[?25l\u001b[?25h left\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h heavier\u001b[?25l\u001b[?25h silence\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h The\u001b[?25l\u001b[?25h footprints\u001b[?25l\u001b[?25h blurred\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h metal\u001b[?25l\u001b[?25h scraps\u001b[?25l\u001b[?25h they\u001b[?25l\u001b[?25h’\u001b[?25l\u001b[?25hd\u001b[?25l\u001b[?25h left\u001b[?25l\u001b[?25h behind\u001b[?25l\u001b[?25h rusted\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h weathered\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h was\u001b[?25l\u001b[?25h left\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h ghosts\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h ambition\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h faint\u001b[?25l\u001b[?25h scent\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h their\u001b[?25l\u001b[?25h excitement\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hSometimes\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h felt\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h flicker\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h hope\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h A\u001b[?25l\u001b[?25h new\u001b[?25l\u001b[?25h generation\u001b[?25l\u001b[?25h looked\u001b[?25l\u001b[?25h up\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h dreamed\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h returning\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h They\u001b[?25l\u001b[?25h spoke\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h bases\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h colonies\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h harnessing\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h resources\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h year\u001b[?25l\u001b[?25hned\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h connection\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h vibrant\u001b[?25l\u001b[?25h touch\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h but\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h deep\u001b[?25l\u001b[?25h-\u001b[?25l\u001b[?25hseated\u001b[?25l\u001b[?25h wear\u001b[?25l\u001b[?25hiness\u001b[?25l\u001b[?25h settled\u001b[?25l\u001b[?25h within\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Would\u001b[?25l\u001b[?25h they\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h too\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h eventually\u001b[?25l\u001b[?25h turn\u001b[?25l\u001b[?25h away\u001b[?25l\u001b[?25h?\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hTonight\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h sighed\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h A\u001b[?25l\u001b[?25h long\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h slow\u001b[?25l\u001b[?25h sigh\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h ri\u001b[?25l\u001b[?25hppled\u001b[?25l\u001b[?25h through\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h tides\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h silent\u001b[?25l\u001b[?25h lament\u001b[?25l\u001b[?25h carried\u001b[?25l\u001b[?25h on\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h solar\u001b[?25l\u001b[?25h wind\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h It\u001b[?25l\u001b[?25h wasn\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25ht\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h sound\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h human\u001b[?25l\u001b[?25h could\u001b[?25l\u001b[?25h hear\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h but\u001b[?25l\u001b[?25h it\u001b[?25l\u001b[?25h was\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h feeling\u001b[?25l\u001b[?25h -\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h weight\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h history\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h longing\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h companionship\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h quiet\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h eternal\u001b[?25l\u001b[?25h watch\u001b[?25l\u001b[?25h over\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h world\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h could\u001b[?25l\u001b[?25h never\u001b[?25l\u001b[?25h truly\u001b[?25l\u001b[?25h touch\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hShe\u001b[?25l\u001b[?25h was\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Moon\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hAnd\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h would\u001b[?25l\u001b[?25h continue\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h watch\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h To\u001b[?25l\u001b[?25h remember\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h To\u001b[?25l\u001b[?25h wait\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25hHer\u001b[?25l\u001b[?25h silver\u001b[?25l\u001b[?25h light\u001b[?25l\u001b[?25h bathed\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Earth\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h its\u001b[?25l\u001b[?25h gentle\u001b[?25l\u001b[?25h glow\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h promise\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h constancy\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h universe\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h change\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h silent\u001b[?25l\u001b[?25h witness\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h unfolding\u001b[?25l\u001b[?25h drama\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h small\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h blue\u001b[?25l\u001b[?25h planet\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hAnd\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h stillness\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h she\u001b[?25l\u001b[?25h whispered\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h stars\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h \"\u001b[?25l\u001b[?25hTell\u001b[?25l\u001b[?25h me\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h do\u001b[?25l\u001b[?25h you\u001b[?25l\u001b[?25h feel\u001b[?25l\u001b[?25h it\u001b[?25l\u001b[?25h too\u001b[?25l\u001b[?25h?\u001b[?25l\u001b[?25h This\u001b[?25l\u001b[?25h…\u001b[?25l\u001b[?25h this\u001b[?25l\u001b[?25h long\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h lonely\u001b[?25l\u001b[?25h vigil\u001b[?25l\u001b[?25h?\"\u001b[?25l\u001b[?25h\n",
            "\n",
            "\n",
            "\n",
            "\u001b[?25l\u001b[?25h---\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hNotes\u001b[?25l\u001b[?25h on\u001b[?25l\u001b[?25h Intent\u001b[?25l\u001b[?25h &\u001b[?25l\u001b[?25h Style\u001b[?25l\u001b[?25h:**\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25h*\u001b[?25l\u001b[?25h   \u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hPerson\u001b[?25l\u001b[?25hification\u001b[?25l\u001b[?25h:**\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h wanted\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h give\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Moon\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h personality\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h emotional\u001b[?25l\u001b[?25h depth\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h She\u001b[?25l\u001b[?25h isn\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25ht\u001b[?25l\u001b[?25h just\u001b[?25l\u001b[?25h an\u001b[?25l\u001b[?25h object\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h but\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h being\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h history\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h sense\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h loneliness\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\u001b[?25l\u001b[?25h*\u001b[?25l\u001b[?25h   \u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hTone\u001b[?25l\u001b[?25h:**\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hThe\u001b[?25l\u001b[?25h overall\u001b[?25l\u001b[?25h tone\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h melancholy\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h reflective\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h slightly\u001b[?25l\u001b[?25h poetic\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h tried\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h avoid\u001b[?25l\u001b[?25h being\u001b[?25l\u001b[?25h overly\u001b[?25l\u001b[?25h sentimental\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h aiming\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h sense\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h quiet\u001b[?25l\u001b[?25h sadness\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\u001b[?25l\u001b[?25h*\u001b[?25l\u001b[?25h   \u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hPerspective\u001b[?25l\u001b[?25h:**\u001b[?25l\u001b[?25h The\u001b[?25l\u001b[?25h story\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h told\u001b[?25l\u001b[?25h from\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Moon\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h point\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h view\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h allowing\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h reader\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h experience\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h vast\u001b[?25l\u001b[?25h timescale\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h her\u001b[?25l\u001b[?25h observations\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h Earth\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\u001b[?25l\u001b[?25h*\u001b[?25l\u001b[?25h   \u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hImagery\u001b[?25l\u001b[?25h:**\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h used\u001b[?25l\u001b[?25h imagery\u001b[?25l\u001b[?25h related\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h light\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h shadow\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h dust\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h tides\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h vast\u001b[?25l\u001b[?25hness\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h evoke\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Moon\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h nature\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h passage\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h time\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\u001b[?25l\u001b[?25h*\u001b[?25l\u001b[?25h   \u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hTheme\u001b[?25l\u001b[?25h:**\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hThe\u001b[?25l\u001b[?25h central\u001b[?25l\u001b[?25h theme\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h loneliness\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h enduring\u001b[?25l\u001b[?25h nature\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h time\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h observation\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h It\u001b[?25l\u001b[?25h’\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h about\u001b[?25l\u001b[?25h being\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h constant\u001b[?25l\u001b[?25h witness\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h change\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\u001b[?25l\u001b[?25h*\u001b[?25l\u001b[?25h   \u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25hAvoid\u001b[?25l\u001b[?25hance\u001b[?25l\u001b[?25h:**\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h consciously\u001b[?25l\u001b[?25h avoided\u001b[?25l\u001b[?25h overly\u001b[?25l\u001b[?25h \"\u001b[?25l\u001b[?25hsci\u001b[?25l\u001b[?25h-\u001b[?25l\u001b[?25hfi\u001b[?25l\u001b[?25h\"\u001b[?25l\u001b[?25h elements\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h wanted\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h story\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h be\u001b[?25l\u001b[?25h rooted\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h sense\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h wonder\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h natural\u001b[?25l\u001b[?25h mystery\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h rather\u001b[?25l\u001b[?25h than\u001b[?25l\u001b[?25h technological\u001b[?25l\u001b[?25h advancement\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\n",
            "\n",
            "\u001b[?25l\u001b[?25hI\u001b[?25l\u001b[?25h hope\u001b[?25l\u001b[?25h this\u001b[?25l\u001b[?25h story\u001b[?25l\u001b[?25h resonates\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h you\u001b[?25l\u001b[?25h!\u001b[?25l\u001b[?25h  \u001b[?25l\u001b[?25hLet\u001b[?25l\u001b[?25h me\u001b[?25l\u001b[?25h know\u001b[?25l\u001b[?25h if\u001b[?25l\u001b[?25h you\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hd\u001b[?25l\u001b[?25h like\u001b[?25l\u001b[?25h me\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h explore\u001b[?25l\u001b[?25h any\u001b[?25l\u001b[?25h particular\u001b[?25l\u001b[?25h aspects\u001b[?25l\u001b[?25h or\u001b[?25l\u001b[?25h change\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h style\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h any\u001b[?25l\u001b[?25h way\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama\n",
        "!pip install dotenv\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXJfHY1R-L79",
        "outputId": "c0fb9235-b980-4069-9c59-9ab5f3189e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ollama in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.11.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv python-docx langchain langchain-ollama langchain-community pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRaCLP-4-NY-",
        "outputId": "bcae5bbd-686e-4ccc-b23b-ea1c1ff88239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-ollama in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: ollama<1,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama) (0.4.8)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN"
      ],
      "metadata": {
        "id": "knrAj7jswOv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "import pypdf # Added for PDF processing\n",
        "\n",
        "# --- Configuration ---\n",
        "# Replace with your Ollama API endpoint and desired model\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/api/generate\"\n",
        "# Consider models like \"llama3:latest\", \"gemma2:latest\", \"mistral:latest\" or more specialized ones if available.\n",
        "# Ensure the model is pulled in Ollama (e.g., `ollama pull llama3`)\n",
        "OLLAMA_MODEL = \"gemma3:12b\" # As per the user's last log, or they can change it\n",
        "# Longer timeout for potentially complex generation tasks\n",
        "OLLAMA_TIMEOUT = 360 # 6 minutes, adjust as needed\n",
        "\n",
        "# Output directory for the generated novel\n",
        "OUTPUT_DIR = \"generated_novel_output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "class NovelGenerator:\n",
        "    def __init__(self, resume_content, subject, author_style, genre):\n",
        "        # Clean up author_style input to remove potential formatting directives\n",
        "        self.author_style = author_style.split(\"\\n\")[0].strip()  # Only take first line\n",
        "        self.author_style = re.sub(r\"Genre:.*$\", \"\", self.author_style, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        self.resume_content = resume_content\n",
        "        self.subject = subject\n",
        "        self.genre = genre\n",
        "        self.num_chapters = 0 # Will be determined by the AI\n",
        "\n",
        "        # Core story elements - will be populated by generation methods\n",
        "        self.characters = {}  # Detailed character objects/dictionaries\n",
        "        self.world_details = {\"name\": \"\", \"key_locations\": [], \"cultural_elements\": [], \"rules\": [], \"atmosphere\": \"\"}\n",
        "        self.themes_motifs = {\"themes\": [], \"motifs\": []}\n",
        "        self.plot_outline = \"\"  # High-level plot (e.g., 3-act structure)\n",
        "        self.novel_title = \"Untitled Novel\"\n",
        "\n",
        "        # Detailed chapter-by-chapter plan\n",
        "        self.chapter_plans = {} # Key: chapter_num, Value: dict with plan details\n",
        "\n",
        "        # Generated content and continuity data\n",
        "        self.generated_chapters_content = {} # Key: chapter_num, Value: full chapter text\n",
        "        self.chapter_continuity_data = {} # Key: chapter_num, Value: dict with summary, char updates, timeline, emotional arc, flow_analysis\n",
        "\n",
        "        print(\"NovelGenerator initialized.\")\n",
        "        print(f\"  Subject: {self.subject[:100]}...\")\n",
        "        print(f\"  Author Style: {self.author_style}\")\n",
        "        print(f\"  Genre: {self.genre}\")\n",
        "        print(f\"  Resume provided: {'Yes' if self.resume_content else 'No'}\")\n",
        "        print(f\"  Number of chapters will be determined automatically.\")\n",
        "\n",
        "\n",
        "    def _ollama_generate(self, prompt, system_prompt=\"You are a helpful AI assistant.\", temperature=0.7, top_p=0.9):\n",
        "        \"\"\"\n",
        "        Helper function to make API calls to the Ollama server.\n",
        "        \"\"\"\n",
        "        payload = {\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"prompt\": prompt,\n",
        "            \"system\": system_prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"temperature\": temperature,\n",
        "                \"top_p\": top_p,\n",
        "                # \"num_ctx\": 8192 # Example: Adjust context window if needed and supported by model like Llama3\n",
        "            }\n",
        "        }\n",
        "        # print(f\"\\n--- Sending Prompt to LLM ({OLLAMA_MODEL}) ---\\n{prompt[:300]}...\\n---\") # Debug: Show prompt start\n",
        "        try:\n",
        "            response = requests.post(OLLAMA_BASE_URL, json=payload, timeout=OLLAMA_TIMEOUT)\n",
        "            response.raise_for_status()\n",
        "            # print(f\"--- LLM Response Received ---\\n{response.json()['response'][:300]}...\\n---\") # Debug: Show response start\n",
        "            return response.json()[\"response\"].strip()\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(f\"ERROR: Ollama request timed out after {OLLAMA_TIMEOUT} seconds for prompt: {prompt[:100]}...\")\n",
        "            return f\"[OLLAMA TIMEOUT ERROR for prompt: {prompt[:100]}...]\"\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"ERROR: Ollama request failed: {e} for prompt: {prompt[:100]}...\")\n",
        "            return f\"[OLLAMA REQUEST ERROR: {e} for prompt: {prompt[:100]}...]\"\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"ERROR: Failed to decode JSON response from Ollama: {e}\")\n",
        "            print(f\"Raw response text: {response.text}\") # It's response.text, not response.text()\n",
        "            return f\"[OLLAMA JSON DECODE ERROR for prompt: {prompt[:100]}...]\"\n",
        "\n",
        "    def _parse_character_profiles(self, text_block):\n",
        "        \"\"\"\n",
        "        Parses character profiles from a structured text block.\n",
        "        Expects format like:\n",
        "        CHARACTER NAME: [Name]\n",
        "        ROLE: [Role]\n",
        "        DESCRIPTION: [Description]\n",
        "        MOTIVATION: [Motivation]\n",
        "        INITIAL_ARC_SUMMARY: [Arc Summary]\n",
        "        FLAWS: [Flaws]\n",
        "        STRENGTHS: [Strengths]\n",
        "        \"\"\"\n",
        "        characters = {}\n",
        "        current_char_data = {}\n",
        "        current_char_name = None\n",
        "\n",
        "        for line in text_block.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if not line: # Handles blank lines between character blocks\n",
        "                if current_char_name and current_char_data:\n",
        "                    characters[current_char_name] = {\n",
        "                        \"name\": current_char_name,\n",
        "                        \"role\": current_char_data.get(\"ROLE\", \"N/A\"),\n",
        "                        \"description\": current_char_data.get(\"DESCRIPTION\", \"N/A\"),\n",
        "                        \"motivation\": current_char_data.get(\"MOTIVATION\", \"N/A\").replace(\"MOTIVATION(S):\",\"\").strip(), # Clean if key repeated\n",
        "                        \"arc_summary\": current_char_data.get(\"INITIAL_ARC_SUMMARY\", \"N/A\"),\n",
        "                        \"flaws\": current_char_data.get(\"FLAWS\", \"N/A\").replace(\"FLAWS/WEAKNESSES:\",\"\").strip(),\n",
        "                        \"strengths\": current_char_data.get(\"STRENGTHS\", \"N/A\").replace(\"STRENGTHS/SKILLS:\",\"\").strip(),\n",
        "                        \"current_status\": \"alive\",\n",
        "                        \"current_location\": \"unknown\",\n",
        "                        \"emotional_state\": \"neutral\",\n",
        "                        \"knowledge\": [],\n",
        "                        \"relationships\": {},\n",
        "                        \"first_appearance_chapter\": 0,\n",
        "                        \"development_log\": []\n",
        "                    }\n",
        "                    current_char_data = {}\n",
        "                    current_char_name = None\n",
        "                continue\n",
        "\n",
        "            match = re.match(r\"CHARACTER NAME:\\s*(.*)\", line, re.IGNORECASE)\n",
        "            if match:\n",
        "                if current_char_name and current_char_data: # Save previous character before starting new one\n",
        "                       characters[current_char_name] = {\n",
        "                        \"name\": current_char_name,\n",
        "                        \"role\": current_char_data.get(\"ROLE\", \"N/A\"),\n",
        "                        \"description\": current_char_data.get(\"DESCRIPTION\", \"N/A\"),\n",
        "                        \"motivation\": current_char_data.get(\"MOTIVATION\", \"N/A\").replace(\"MOTIVATION(S):\",\"\").strip(),\n",
        "                        \"arc_summary\": current_char_data.get(\"INITIAL_ARC_SUMMARY\", \"N/A\"),\n",
        "                        \"flaws\": current_char_data.get(\"FLAWS\", \"N/A\").replace(\"FLAWS/WEAKNESSES:\",\"\").strip(),\n",
        "                        \"strengths\": current_char_data.get(\"STRENGTHS\", \"N/A\").replace(\"STRENGTHS/SKILLS:\",\"\").strip(),\n",
        "                        \"current_status\": \"alive\", \"current_location\": \"unknown\", \"emotional_state\": \"neutral\",\n",
        "                        \"knowledge\": [], \"relationships\": {}, \"first_appearance_chapter\": 0, \"development_log\": []\n",
        "                    }\n",
        "                current_char_name = match.group(1).strip()\n",
        "                current_char_data = {} # Reset for the new character\n",
        "                continue\n",
        "\n",
        "            if current_char_name: # If we are currently parsing a character\n",
        "                # Adjust keys to match potential variations in LLM output if necessary\n",
        "                # For example, 'MOTIVATION(S)' vs 'MOTIVATION'\n",
        "                keys_to_check = {\n",
        "                    \"ROLE\": \"ROLE\",\n",
        "                    \"DESCRIPTION\": \"DESCRIPTION\",\n",
        "                    \"MOTIVATION(S)\": \"MOTIVATION\", # Store as \"MOTIVATION\"\n",
        "                    \"MOTIVATION\": \"MOTIVATION\",\n",
        "                    \"INITIAL_ARC_SUMMARY\": \"INITIAL_ARC_SUMMARY\",\n",
        "                    \"FLAWS/WEAKNESSES\": \"FLAWS\", # Store as \"FLAWS\"\n",
        "                    \"FLAWS\": \"FLAWS\",\n",
        "                    \"STRENGTHS/SKILLS\": \"STRENGTHS\", # Store as \"STRENGTHS\"\n",
        "                    \"STRENGTHS\": \"STRENGTHS\"\n",
        "                }\n",
        "                for key_llm, key_internal in keys_to_check.items():\n",
        "                    if line.upper().startswith(key_llm + \":\"):\n",
        "                        current_char_data[key_internal] = line[len(key_llm)+1:].strip()\n",
        "                        break\n",
        "                    # Handle cases where LLM might not repeat the key but continues on next line (multiline description)\n",
        "                    elif current_char_data and not any(line.upper().startswith(k + \":\") for k in keys_to_check):\n",
        "                        # This logic is tricky; for simplicity, we assume single-line values for now after the key\n",
        "                        # Or append to the last known key if it's a multiline field like DESCRIPTION\n",
        "                        if \"DESCRIPTION\" in current_char_data and not any(line.upper().startswith(k + \":\") for k in keys_to_check if k != \"DESCRIPTION\"):\n",
        "                             current_char_data[\"DESCRIPTION\"] += \"\\n\" + line\n",
        "                             break\n",
        "\n",
        "\n",
        "        if current_char_name and current_char_data: # Save the last character in the block\n",
        "            characters[current_char_name] = {\n",
        "                \"name\": current_char_name,\n",
        "                \"role\": current_char_data.get(\"ROLE\", \"N/A\"),\n",
        "                \"description\": current_char_data.get(\"DESCRIPTION\", \"N/A\"),\n",
        "                \"motivation\": current_char_data.get(\"MOTIVATION\", \"N/A\").replace(\"MOTIVATION(S):\",\"\").strip(),\n",
        "                \"arc_summary\": current_char_data.get(\"INITIAL_ARC_SUMMARY\", \"N/A\"),\n",
        "                \"flaws\": current_char_data.get(\"FLAWS\", \"N/A\").replace(\"FLAWS/WEAKNESSES:\",\"\").strip(),\n",
        "                \"strengths\": current_char_data.get(\"STRENGTHS\", \"N/A\").replace(\"STRENGTHS/SKILLS:\",\"\").strip(),\n",
        "                \"current_status\": \"alive\", \"current_location\": \"unknown\", \"emotional_state\": \"neutral\",\n",
        "                \"knowledge\": [], \"relationships\": {}, \"first_appearance_chapter\": 0, \"development_log\": []\n",
        "            }\n",
        "        return characters\n",
        "\n",
        "    # --- Phase 1: Foundation Methods ---\n",
        "    def generate_foundational_elements(self):\n",
        "        \"\"\"\n",
        "        Generates initial character profiles, world details, themes/motifs, high-level plot outline,\n",
        "        and determines the number of chapters.\n",
        "        \"\"\"\n",
        "        print(\"\\n--- Generating Foundational Elements ---\")\n",
        "\n",
        "        # 1. Character Conception\n",
        "        print(\"Step 1.1: Generating Character Profiles...\")\n",
        "        char_system_prompt = f\"You are a master character creator for {self.genre} novels, inspired by {self.author_style}.\"\n",
        "        char_prompt = f\"\"\"\n",
        "Based on the novel's subject, genre, and the provided resume snippet (if any), create detailed profiles for the main protagonist and 1-2 key supporting characters (e.g., antagonist, mentor, love interest).\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "Author Style Influence: {self.author_style}\n",
        "Resume Snippet (use to inspire the protagonist, inferring personality, potential skills, and background):\n",
        "---\n",
        "{self.resume_content if self.resume_content else \"No resume provided. Create protagonist based on subject and genre.\"}\n",
        "---\n",
        "IMPORTANT: For EACH character, provide EXACTLY the following fields, starting each character block with 'CHARACTER NAME:'.\n",
        "Your entire response must consist of one or more character profiles in this strict format. Do NOT add any introductory sentences, summaries outside of these fields, or any other details like worldbuilding or plot.\n",
        "\n",
        "Format for each character:\n",
        "CHARACTER NAME: [Suggest a fitting name]\n",
        "ROLE: [Protagonist, Antagonist, Key Supporting - specify type]\n",
        "DESCRIPTION: [Detailed appearance, key personality traits, mannerisms, background hints]\n",
        "MOTIVATION(S): [What drives them? What are their primary goals, conscious or subconscious?]\n",
        "INITIAL_ARC_SUMMARY: [How might they change or develop throughout the story? What is their potential journey?]\n",
        "FLAWS/WEAKNESSES: [What are their vulnerabilities, biases, or negative traits?]\n",
        "STRENGTHS/SKILLS: [What are their notable positive attributes or skills?]\n",
        "\n",
        "Example of ONE character profile:\n",
        "CHARACTER NAME: Jane Doe\n",
        "ROLE: Protagonist\n",
        "DESCRIPTION: Tall, with fiery red hair and a determined gaze. Often bites her lip when thinking. Former city guard.\n",
        "MOTIVATION(S): To find her missing brother and expose the corruption in the council.\n",
        "INITIAL_ARC_SUMMARY: Starts cynical and isolated, learns to trust others and becomes a leader.\n",
        "FLAWS/WEAKNESSES: Impulsive, mistrustful of authority.\n",
        "STRENGTHS/SKILLS: Skilled sword fighter, keen observer.\n",
        "\n",
        "(Provide profiles for the main protagonist and 1-2 key supporting characters adhering strictly to this format.)\n",
        "\"\"\"\n",
        "        character_profiles_text = self._ollama_generate(char_prompt, char_system_prompt, temperature=0.75)\n",
        "        if \"[OLLAMA\" in character_profiles_text:\n",
        "            print(f\"ERROR generating character profiles: {character_profiles_text}\")\n",
        "        else:\n",
        "            self.characters = self._parse_character_profiles(character_profiles_text)\n",
        "            if not self.characters:\n",
        "                print(\"Warning: LLM output for character profiles was not in the expected format or was empty. Raw output (first 1000 chars):\")\n",
        "                print(character_profiles_text[:1000] + \"...\" if len(character_profiles_text) > 1000 else character_profiles_text)\n",
        "            print(f\"Generated {len(self.characters)} character profiles: {', '.join(self.characters.keys())}\")\n",
        "\n",
        "        # 2. Worldbuilding\n",
        "        print(\"\\nStep 1.2: Generating World Details...\")\n",
        "        world_system_prompt = f\"You are a world-building expert for {self.genre} fiction, creating immersive settings like those by {self.author_style}.\"\n",
        "        world_prompt = f\"\"\"\n",
        "Based on the novel's subject and genre, describe the primary world/setting.\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "IMPORTANT: Provide ONLY the following details for the world/setting. Use the exact numbered headers as specified below.\n",
        "Do not include plot summaries, character descriptions, or any information not requested in this step.\n",
        "\n",
        "1.  WORLD NAME: [A unique and evocative name for the main setting/world/city]\n",
        "2.  KEY LOCATIONS: [List 3-5 significant recurring locations with brief descriptions. Each item should be on a new line, like: \"- The Sunken Library - an ancient repository of forbidden knowledge\"]\n",
        "3.  CULTURAL ELEMENTS: [Describe 2-3 unique customs, societal norms, beliefs, or technologies. Each item should be on a new line, like: \"- Aether-tech - devices powered by ambient magical energy\"]\n",
        "4.  ATMOSPHERE/TONE: [Describe the overall mood and feeling of the world (e.g., oppressive, wondrous, decaying, futuristic, magical)]\n",
        "5.  KEY RULES/LAWS (if applicable, e.g., for magic systems, societal structure): [List 1-3 fundamental rules that govern this world or its unique aspects. Each item should be on a new line.]\n",
        "\"\"\"\n",
        "        world_details_text = self._ollama_generate(world_prompt, world_system_prompt, temperature=0.65)\n",
        "        if \"[OLLAMA\" in world_details_text:\n",
        "            print(f\"ERROR generating world details: {world_details_text}\")\n",
        "        else:\n",
        "            lines = world_details_text.split('\\n')\n",
        "            for line in lines:\n",
        "                if re.match(r\"1\\.\\s*WORLD NAME:\", line, re.IGNORECASE) or line.upper().startswith(\"WORLD NAME:\"):\n",
        "                    name_val = re.split(r\":\", line, 1)[1].strip()\n",
        "                    name_val = re.sub(r'[*_`#]', '', name_val) # Remove common markdown chars\n",
        "                    self.world_details[\"name\"] = name_val\n",
        "                elif re.match(r\"4\\.\\s*ATMOSPHERE/TONE:\", line, re.IGNORECASE) or line.upper().startswith(\"ATMOSPHERE/TONE:\"):\n",
        "                     self.world_details[\"atmosphere\"] = re.split(r\":\", line, 1)[1].strip()\n",
        "\n",
        "\n",
        "            key_loc_match = re.search(r\"(?:2\\.|KEY LOCATIONS:)\\s*((?:-\\s*.*|\\d\\.\\s*.*|\\*\\s*.*(?:\\n|$))+)\", world_details_text, re.IGNORECASE | re.DOTALL)\n",
        "            if key_loc_match:\n",
        "                self.world_details[\"key_locations\"] = [loc.strip(\"-* \").strip().lstrip(\"123456789. \") for loc in key_loc_match.group(1).strip().split('\\n') if loc.strip()]\n",
        "\n",
        "            cultural_elem_match = re.search(r\"(?:3\\.|CULTURAL ELEMENTS:)\\s*((?:-\\s*.*|\\d\\.\\s*.*|\\*\\s*.*(?:\\n|$))+)\", world_details_text, re.IGNORECASE | re.DOTALL)\n",
        "            if cultural_elem_match:\n",
        "                self.world_details[\"cultural_elements\"] = [elem.strip(\"-* \").strip().lstrip(\"123456789. \") for elem in cultural_elem_match.group(1).strip().split('\\n') if elem.strip()]\n",
        "\n",
        "            rules_match = re.search(r\"(?:5\\.|KEY RULES/LAWS:)\\s*((?:-\\s*.*|\\d\\.\\s*.*|\\*\\s*.*(?:\\n|$))+)\", world_details_text, re.IGNORECASE | re.DOTALL)\n",
        "            if rules_match:\n",
        "                self.world_details[\"rules\"] = [rule.strip(\"-* \").strip().lstrip(\"123456789. \") for rule in rules_match.group(1).strip().split('\\n') if rule.strip()]\n",
        "\n",
        "            print(f\"Generated World Details for '{self.world_details.get('name', 'Unnamed World')}'.\")\n",
        "            if not self.world_details.get(\"name\"):\n",
        "                print(\"Warning: World Name not parsed. Raw world details output (first 1000 chars):\")\n",
        "                print(world_details_text[:1000] + \"...\" if len(world_details_text) > 1000 else world_details_text)\n",
        "\n",
        "\n",
        "        # 3. Themes and Motifs\n",
        "        print(\"\\nStep 1.3: Generating Themes and Motifs...\")\n",
        "        themes_system_prompt = f\"You are a literary analyst identifying profound themes and recurring motifs for {self.genre} novels, in the vein of {self.author_style}.\"\n",
        "        themes_prompt = f\"\"\"\n",
        "Based on the novel's subject, genre, and initial character concepts, identify:\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "Character Concepts: {json.dumps(self.characters, indent=2)}\n",
        "World Atmosphere: {self.world_details.get(\"atmosphere\", \"N/A\")}\n",
        "\n",
        "IMPORTANT: Your response should ONLY contain lists under the exact headers '1. CORE THEMES:' and '2. RECURRING MOTIFS:'.\n",
        "Use the specified format. Do not add any other explanations, introductory text, or unrelated information.\n",
        "\n",
        "1.  CORE THEMES (2-4): [List abstract concepts the story will explore. Each item should be on a new line, like: \"- Loss and Memory: The story explores how memories define individuals and societies, and the consequences of their loss or manipulation.\" Provide a brief (1-sentence) explanation for each, linking it to the context.]\n",
        "2.  RECURRING MOTIFS (3-5): [List concrete symbols, objects, phrases, or imagery. Each item should be on a new line, like: \"- A cracked pocket watch,\" \"- The phrase 'shadows remember'.\"]\n",
        "\"\"\"\n",
        "        themes_motifs_text = self._ollama_generate(themes_prompt, themes_system_prompt, temperature=0.6)\n",
        "        if \"[OLLAMA\" in themes_motifs_text:\n",
        "            print(f\"ERROR generating themes/motifs: {themes_motifs_text}\")\n",
        "        else:\n",
        "            themes_match = re.search(r\"(?:1\\.|CORE THEMES:)\\s*((?:-\\s*.*|\\d\\.\\s*.*|\\*\\s*.*(?:\\n|$))+)\", themes_motifs_text, re.IGNORECASE | re.DOTALL)\n",
        "            if themes_match:\n",
        "                self.themes_motifs[\"themes\"] = [theme.strip(\"-* \").strip().lstrip(\"123456789. \") for theme in themes_match.group(1).strip().split('\\n') if theme.strip()]\n",
        "\n",
        "            motifs_match = re.search(r\"(?:2\\.|RECURRING MOTIFS:)\\s*((?:-\\s*.*|\\d\\.\\s*.*|\\*\\s*.*(?:\\n|$))+)\", themes_motifs_text, re.IGNORECASE | re.DOTALL)\n",
        "            if motifs_match:\n",
        "                self.themes_motifs[\"motifs\"] = [motif.strip(\"-* \").strip().lstrip(\"123456789. \") for motif in motifs_match.group(1).strip().split('\\n') if motif.strip()]\n",
        "\n",
        "            if not self.themes_motifs[\"themes\"] and not self.themes_motifs[\"motifs\"]:\n",
        "                print(\"Warning: Themes and Motifs not parsed. Raw output (first 1000 chars):\")\n",
        "                print(themes_motifs_text[:1000] + \"...\" if len(themes_motifs_text) > 1000 else themes_motifs_text)\n",
        "            print(f\"Generated Themes: {self.themes_motifs['themes']}\")\n",
        "            print(f\"Generated Motifs: {self.themes_motifs['motifs']}\")\n",
        "\n",
        "        # 4. High-Level Plot Outline & Determine Number of Chapters\n",
        "        print(\"\\nStep 1.4: Generating High-Level Plot Outline and Determining Chapter Count...\")\n",
        "        plot_system_prompt = f\"You are a master storyteller, outlining engaging plots for {self.genre} novels in the style of {self.author_style}.\"\n",
        "        plot_prompt = f\"\"\"\n",
        "Create a high-level plot outline for a novel based on the subject.\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "Characters: {json.dumps(self.characters, indent=2)}\n",
        "World: {json.dumps(self.world_details, indent=2)}\n",
        "Themes: {json.dumps(self.themes_motifs[\"themes\"])}\n",
        "\n",
        "The outline should follow a classic narrative structure (e.g., Three-Act Structure: Setup, Confrontation, Resolution).\n",
        "Describe:\n",
        "-   **Act I (Setup):** Introduction of protagonist, inciting incident, establishment of conflict and stakes.\n",
        "-   **Act II (Confrontation):** Rising action, character development through trials, introduction of key allies/antagonists, major turning points/complications.\n",
        "-   **Act III (Resolution):** Climax, falling action, resolution of main conflict, and thematic conclusion.\n",
        "\n",
        "For each Act, provide a 2-4 sentence summary of its key developments and objectives.\n",
        "IMPORTANT: Your response should ONLY contain the summaries for Act I, Act II, and Act III, followed by the SUGGESTED_CHAPTER_COUNT line.\n",
        "Do NOT include character profiles, world details, or themes here as they have been generated in separate, previous steps. Your response should only be the plot act summaries and the chapter count line.\n",
        "\n",
        "Example Structure:\n",
        "**Act I (Setup):** [Summary for Act I]\n",
        "**Act II (Confrontation):** [Summary for Act II]\n",
        "**Act III (Resolution):** [Summary for Act III]\n",
        "SUGGESTED_CHAPTER_COUNT: [Number]\n",
        "\n",
        "Begin your response with Act I.\n",
        "\"\"\"\n",
        "        self.plot_outline = self._ollama_generate(plot_prompt, plot_system_prompt, temperature=0.7)\n",
        "\n",
        "        if \"[OLLAMA\" in self.plot_outline:\n",
        "            print(f\"ERROR generating plot outline: {self.plot_outline}\")\n",
        "            # Defaulting num_chapters handled further down\n",
        "        else:\n",
        "            print(\"Generated High-Level Plot Outline:\")\n",
        "            plot_display = re.sub(r\"SUGGESTED_CHAPTER_COUNT:\\s*\\d+\", \"\", self.plot_outline, flags=re.IGNORECASE).strip()\n",
        "            print(plot_display)\n",
        "            # num_chapters parsing is handled below\n",
        "\n",
        "        # Determine num_chapters from plot_outline or default\n",
        "        suggested_chapters_match = re.search(r\"SUGGESTED_CHAPTER_COUNT:\\s*(\\d+)\", self.plot_outline, re.IGNORECASE)\n",
        "        if suggested_chapters_match:\n",
        "            try:\n",
        "                self.num_chapters = int(suggested_chapters_match.group(1))\n",
        "                if not (5 <= self.num_chapters <= 75): # Wider reasonable range\n",
        "                    print(f\"Warning: LLM suggested {self.num_chapters} chapters, which is outside the typical 5-75 range. Clamping to 15.\")\n",
        "                    self.num_chapters = 15\n",
        "                else:\n",
        "                    print(f\"LLM suggested {self.num_chapters} chapters for the novel.\")\n",
        "            except ValueError:\n",
        "                print(\"Warning: Could not parse suggested chapter count as integer. Defaulting to 15 chapters.\")\n",
        "                self.num_chapters = 15\n",
        "        elif \"[OLLAMA\" in self.plot_outline: # If API error during plot gen\n",
        "             print(\"Defaulting number of chapters to 15 due to API error in plot generation.\")\n",
        "             self.num_chapters = 15\n",
        "        else: # If no match and no API error\n",
        "            print(\"Warning: Could not find suggested chapter count in plot outline. Defaulting to 15 chapters.\")\n",
        "            self.num_chapters = 15\n",
        "\n",
        "        if self.num_chapters < 3: # Ensure minimum for structure\n",
        "            print(f\"Warning: Number of chapters determined ({self.num_chapters}) is less than 3. Setting to 3.\")\n",
        "            self.num_chapters = 3\n",
        "\n",
        "\n",
        "        # --- Validation of Foundational Elements ---\n",
        "        all_steps_api_ok = not (\"[OLLAMA\" in character_profiles_text or \\\n",
        "                                \"[OLLAMA\" in world_details_text or \\\n",
        "                                \"[OLLAMA\" in themes_motifs_text or \\\n",
        "                                \"[OLLAMA\" in self.plot_outline)\n",
        "\n",
        "        if not all_steps_api_ok:\n",
        "            print(\"Halting: Foundational element generation failed due to API errors with Ollama.\")\n",
        "            return False\n",
        "\n",
        "        essential_data_parsed = True\n",
        "        missing_elements = []\n",
        "        if not self.characters:\n",
        "            essential_data_parsed = False\n",
        "            missing_elements.append(\"Parsed character profiles\")\n",
        "        if not self.world_details.get(\"name\"):\n",
        "            essential_data_parsed = False\n",
        "            missing_elements.append(\"Parsed world name/details\")\n",
        "        if not self.themes_motifs.get(\"themes\") and not self.themes_motifs.get(\"motifs\"):\n",
        "            essential_data_parsed = False\n",
        "            missing_elements.append(\"Parsed themes/motifs\")\n",
        "        if not self.plot_outline.strip() or self.num_chapters == 0 : # Check if plot_outline itself is empty\n",
        "            essential_data_parsed = False\n",
        "            missing_elements.append(\"Parsed plot outline or valid chapter count\")\n",
        "        # Also ensure plot_outline doesn't indicate an error itself, though already caught by all_steps_api_ok\n",
        "        if \"[OLLAMA\" in self.plot_outline and \"Parsed plot outline or valid chapter count\" not in missing_elements:\n",
        "            essential_data_parsed = False\n",
        "            missing_elements.append(\"Plot outline contains API error\")\n",
        "\n",
        "\n",
        "        if not essential_data_parsed:\n",
        "            print(f\"Halting: Essential foundational data was not successfully parsed or generated. Missing or empty elements: {', '.join(missing_elements)}.\")\n",
        "            return False\n",
        "\n",
        "        print(\"Foundational elements generated successfully.\")\n",
        "        return True\n",
        "\n",
        "\n",
        "    # --- Phase 2: Detailed Planning Method ---\n",
        "    def generate_detailed_chapter_plans(self):\n",
        "        \"\"\"\n",
        "        Expands the high-level plot outline into detailed plans for each chapter.\n",
        "        \"\"\"\n",
        "        print(\"\\n--- Generating Detailed Chapter-by-Chapter Plans ---\")\n",
        "        # This check is now more robust due to changes in generate_foundational_elements\n",
        "        if not self.plot_outline or not self.characters or not self.world_details.get(\"name\") or \\\n",
        "           (not self.themes_motifs.get(\"themes\") and not self.themes_motifs.get(\"motifs\")) or \\\n",
        "           self.num_chapters == 0:\n",
        "            print(\"ERROR: Cannot generate chapter plans without all foundational elements (plot, characters, world name, themes/motifs, num_chapters).\")\n",
        "            # For debugging, print what's missing or present\n",
        "            if not self.plot_outline: print(\"  - Plot Outline: Missing\")\n",
        "            if not self.characters: print(\"  - Characters: Missing or Empty\")\n",
        "            if not self.world_details.get(\"name\"): print(\"  - World Name: Missing\")\n",
        "            if not self.themes_motifs.get(\"themes\") and not self.themes_motifs.get(\"motifs\"): print(\"  - Themes/Motifs: Missing or Empty\")\n",
        "            if self.num_chapters == 0: print(\"  - Number of Chapters: Zero\")\n",
        "            return False\n",
        "\n",
        "        system_prompt = f\"You are a meticulous plot architect, detailing chapter structures for a {self.genre} novel in the style of {self.author_style}.\"\n",
        "        character_summary_for_prompt = \"\\n\".join([f\"- {name} ({data.get('role', 'N/A')}): Motivations: {data.get('motivation', 'N/A')}. Arc: {data.get('arc_summary', 'N/A')}\" for name, data in self.characters.items()])\n",
        "        world_summary_for_prompt = f\"World Name: {self.world_details.get('name', 'N/A')}\\nKey Locations: {', '.join(self.world_details.get('key_locations',[]))}\\nCultural Elements: {', '.join(self.world_details.get('cultural_elements',[]))}\\nAtmosphere: {self.world_details.get('atmosphere', 'N/A')}\"\n",
        "        themes_for_prompt = f\"Core Themes: {', '.join(self.themes_motifs.get('themes',[]))}\\nRecurring Motifs: {', '.join(self.themes_motifs.get('motifs',[]))}\"\n",
        "\n",
        "        # Clean plot_outline from chapter count for this prompt\n",
        "        clean_plot_outline_for_detailed_plan = re.sub(r\"SUGGESTED_CHAPTER_COUNT:\\s*\\d+\", \"\", self.plot_outline, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        # Breaking the chapters into smaller batches to handle context limits\n",
        "        max_chapters_per_batch = 12\n",
        "        num_batches = (self.num_chapters + max_chapters_per_batch - 1) // max_chapters_per_batch  # Ceiling division\n",
        "\n",
        "        all_chapter_plans_successful = True\n",
        "\n",
        "        for batch_idx in range(num_batches):\n",
        "            start_chapter = batch_idx * max_chapters_per_batch + 1\n",
        "            end_chapter = min((batch_idx + 1) * max_chapters_per_batch, self.num_chapters)\n",
        "\n",
        "            print(f\"Generating detailed plan text for chapters {start_chapter}-{end_chapter} (batch {batch_idx+1}/{num_batches})...\")\n",
        "\n",
        "            batch_prompt = f\"\"\"\n",
        "            Novel Subject: {self.subject}\n",
        "            High-Level Plot Outline:\n",
        "            {clean_plot_outline_for_detailed_plan}\n",
        "\n",
        "            Character Summaries:\n",
        "            {character_summary_for_prompt}\n",
        "\n",
        "            World Summary:\n",
        "            {world_summary_for_prompt}\n",
        "\n",
        "            Themes & Motifs:\n",
        "            {themes_for_prompt}\n",
        "\n",
        "            Total Chapters in Novel: {self.num_chapters}\n",
        "\n",
        "            I need you to create DETAILED PLANS for chapters {start_chapter} through {end_chapter} only.\n",
        "            For EACH chapter, provide STRICTLY the following, in this order and clearly labeled:\n",
        "\n",
        "            Chapter [Number] - [Evocative Title for this Chapter]:\n",
        "            1.  CHAPTER GOAL: [A single paragraph (50-80 words) stating the primary narrative goal this chapter needs to achieve in the overall story and how it impacts the main character's arc or the central conflict.]\n",
        "            2.  KEY SCENES (3-6 scenes): [Bulleted list. Each scene: \"- Scene X: [Brief description of action/dialogue/internal monologue], Location: [Specific location from World Details or new minor one], Characters Involved: [List characters present & active], Key Revelation/Turning Point/Outcome: [What changes, is learned, or achieved? How does it advance the plot or character?]]\n",
        "            3.  CHARACTER DEVELOPMENT FOCUS: [For key characters appearing: How do their motivations, relationships, knowledge, or understanding change in THIS chapter? Be specific. e.g., \"Jessica: Confronts her fear of X, strengthening her resolve but creating friction with Y. Learns Z about her past.\"]\n",
        "            4.  PLOT ADVANCEMENT: [Specific ways the main plot and any subplots move forward. What new questions are raised or old ones answered? How does this chapter build on the previous and set up the next?]\n",
        "            5.  TIMELINE & PACING: [e.g., \"This chapter takes place over a few hours the next day.\", \"Pacing: Fast, with building tension.\", \"Spans one week, slower reflective pace initially, then accelerates.\"]\n",
        "            6.  EMOTIONAL TONE (End of Chapter): [e.g., \"Hopeful but wary,\" \"Tense and suspenseful,\" \"Melancholy and reflective,\" \"Ominous and foreboding.\"]\n",
        "            7.  CONNECTION TO NEXT CHAPTER (Setup/Hook): [Explicitly state 1-2 elements, questions, cliffhangers, or character decisions that directly lead into the next chapter's planned events or themes.]\n",
        "\n",
        "            This detailed plan must ensure logical progression, character consistency, integration of themes/motifs, and effective pacing.\n",
        "            A character's status (location, knowledge, emotional state) at the end of one chapter MUST be the starting point for the next.\n",
        "            Ensure the plans for later chapters logically follow from the resolutions and developments of earlier ones.\n",
        "\n",
        "            Begin directly with \"Chapter {start_chapter} - \" without any preamble.\n",
        "            \"\"\"\n",
        "\n",
        "            batch_chapter_plans_text = self._ollama_generate(batch_prompt, system_prompt, temperature=0.65)\n",
        "\n",
        "            if \"[OLLAMA\" in batch_chapter_plans_text:\n",
        "                print(f\"ERROR generating batch of chapter plans ({start_chapter}-{end_chapter}): {batch_chapter_plans_text}\")\n",
        "                all_chapter_plans_successful = False\n",
        "                continue\n",
        "\n",
        "            self._parse_chapter_plans(batch_chapter_plans_text)\n",
        "\n",
        "        # Now check if we have enough chapter plans\n",
        "        if not self.chapter_plans:\n",
        "            print(\"ERROR: No chapter plans were successfully parsed from any batch.\")\n",
        "            return False\n",
        "\n",
        "        print(f\"Successfully parsed detailed plans for {len(self.chapter_plans)} chapters out of {self.num_chapters} expected.\")\n",
        "\n",
        "        # For any missing chapters, generate fallback plans\n",
        "        missing_chapters = [i for i in range(1, self.num_chapters + 1) if i not in self.chapter_plans]\n",
        "        if missing_chapters:\n",
        "            print(f\"Generating fallback plans for {len(missing_chapters)} missing chapters: {missing_chapters}\")\n",
        "            self._generate_fallback_chapter_plans(missing_chapters)\n",
        "\n",
        "        # Count chapters again after fallback generation\n",
        "        if len(self.chapter_plans) != self.num_chapters:\n",
        "            print(f\"WARNING: Still have a mismatch in parsed plans ({len(self.chapter_plans)}) and expected chapters ({self.num_chapters}).\")\n",
        "            return len(self.chapter_plans) > 0  # Continue if we have at least some plans\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _parse_chapter_plans(self, chapter_plans_text):\n",
        "        \"\"\"Parse chapter plans from the LLM's output text.\"\"\"\n",
        "        # This handles many different possible chapter heading formats\n",
        "        chapter_regex_patterns = [\n",
        "            # Standard format: \"Chapter X - Title\"\n",
        "            r\"(?:^|\\n)(?:\\*\\*)?Chapter\\s*(\\d+)\\s*-\\s*(.*?)(?:\\*\\*)?(?=\\n|$)\",\n",
        "            # Alternative format: \"Chapter X: Title\"\n",
        "            r\"(?:^|\\n)(?:\\*\\*)?Chapter\\s*(\\d+)\\s*:\\s*(.*?)(?:\\*\\*)?(?=\\n|$)\",\n",
        "            # Possible markdown: \"# Chapter X - Title\"\n",
        "            r\"(?:^|\\n)#\\s*(?:\\*\\*)?Chapter\\s*(\\d+)\\s*[-:]\\s*(.*?)(?:\\*\\*)?(?=\\n|$)\",\n",
        "            # Just chapter number: \"Chapter X\"\n",
        "            r\"(?:^|\\n)(?:\\*\\*)?Chapter\\s*(\\d+)(?:\\*\\*)?(?=\\n|$)\"\n",
        "        ]\n",
        "\n",
        "        # First, find all chapter starts and their positions in the text\n",
        "        chapter_positions = []\n",
        "        for pattern in chapter_regex_patterns:\n",
        "            for match in re.finditer(pattern, chapter_plans_text, re.MULTILINE):\n",
        "                try:\n",
        "                    chapter_num = int(match.group(1))\n",
        "                    chapter_title = match.group(2).strip() if len(match.groups()) > 1 else f\"Chapter {chapter_num}\"\n",
        "                    position = match.start()\n",
        "                    chapter_positions.append((chapter_num, chapter_title, position))\n",
        "                except (IndexError, ValueError):\n",
        "                    continue\n",
        "\n",
        "        # Sort by position in the text to preserve order\n",
        "        chapter_positions.sort(key=lambda x: x[2])\n",
        "\n",
        "        # Now extract the content between each chapter heading\n",
        "        for i, (chapter_num, chapter_title, start_pos) in enumerate(chapter_positions):\n",
        "            # Find the end position (either the next chapter start or the end of text)\n",
        "            end_pos = chapter_positions[i+1][2] if i+1 < len(chapter_positions) else len(chapter_plans_text)\n",
        "            chapter_content = chapter_plans_text[start_pos:end_pos].strip()\n",
        "\n",
        "            # Parse the chapter content\n",
        "            self._parse_single_chapter_plan(chapter_num, chapter_title, chapter_content)\n",
        "\n",
        "    def _parse_single_chapter_plan(self, chapter_num, chapter_title, chapter_content):\n",
        "        \"\"\"Parse a single chapter's plan from its content.\"\"\"\n",
        "        if chapter_num in self.chapter_plans:\n",
        "            print(f\"  Note: Chapter {chapter_num} plan already exists, skipping.\")\n",
        "            return\n",
        "\n",
        "        plan_details = {\n",
        "            \"number\": chapter_num,\n",
        "            \"title\": chapter_title,\n",
        "            \"goal\": \"N/A\",\n",
        "            \"scenes\": [],\n",
        "            \"character_development\": \"N/A\",\n",
        "            \"plot_advancement\": \"N/A\",\n",
        "            \"timeline_pacing\": \"N/A\",\n",
        "            \"emotional_tone_end\": \"N/A\",\n",
        "            \"connection_to_next\": \"N/A\"\n",
        "        }\n",
        "\n",
        "        # Extract each section using regex\n",
        "        sections = {\n",
        "            \"goal\": r\"(?:1\\.\\s*CHAPTER GOAL:|CHAPTER GOAL:)\\s*(.*?)(?=\\n\\s*(?:2\\.\\s*KEY SCENES:|KEY SCENES:|$))\",\n",
        "            \"scenes\": r\"(?:2\\.\\s*KEY SCENES:|KEY SCENES:)\\s*(.*?)(?=\\n\\s*(?:3\\.\\s*CHARACTER DEVELOPMENT|CHARACTER DEVELOPMENT|$))\",\n",
        "            \"character_development\": r\"(?:3\\.\\s*CHARACTER DEVELOPMENT FOCUS:|CHARACTER DEVELOPMENT FOCUS:)\\s*(.*?)(?=\\n\\s*(?:4\\.\\s*PLOT ADVANCEMENT|PLOT ADVANCEMENT|$))\",\n",
        "            \"plot_advancement\": r\"(?:4\\.\\s*PLOT ADVANCEMENT:|PLOT ADVANCEMENT:)\\s*(.*?)(?=\\n\\s*(?:5\\.\\s*TIMELINE|TIMELINE|$))\",\n",
        "            \"timeline_pacing\": r\"(?:5\\.\\s*TIMELINE & PACING:|TIMELINE & PACING:)\\s*(.*?)(?=\\n\\s*(?:6\\.\\s*EMOTIONAL|EMOTIONAL|$))\",\n",
        "            \"emotional_tone_end\": r\"(?:6\\.\\s*EMOTIONAL TONE \\(End of Chapter\\):|EMOTIONAL TONE:)\\s*(.*?)(?=\\n\\s*(?:7\\.\\s*CONNECTION|CONNECTION|$))\",\n",
        "            \"connection_to_next\": r\"(?:7\\.\\s*CONNECTION TO NEXT CHAPTER|CONNECTION TO NEXT CHAPTER:)\\s*(.*?)(?=$)\"\n",
        "        }\n",
        "\n",
        "        for key, pattern in sections.items():\n",
        "            match = re.search(pattern, chapter_content, re.IGNORECASE | re.DOTALL)\n",
        "            if match:\n",
        "                if key == \"scenes\":\n",
        "                    scenes_text = match.group(1).strip()\n",
        "                    # Split scenes by bullet points or scene markers\n",
        "                    scenes = re.split(r'\\n\\s*(?:-\\s*|\\*\\s*|•\\s*|\\d+\\.\\s*)', scenes_text)\n",
        "                    # Remove empty scenes and clean up\n",
        "                    scenes = [s.strip() for s in scenes if s.strip()]\n",
        "                    plan_details[key] = scenes\n",
        "                else:\n",
        "                    plan_details[key] = match.group(1).strip()\n",
        "\n",
        "        self.chapter_plans[chapter_num] = plan_details\n",
        "        print(f\"  Parsed plan for Chapter {chapter_num}: {chapter_title}\")\n",
        "\n",
        "    def _generate_fallback_chapter_plans(self, missing_chapters):\n",
        "        \"\"\"Generate fallback plans for missing chapters.\"\"\"\n",
        "        for chapter_num in missing_chapters:\n",
        "            # For chapters without plans, we'll generate a simplified plan\n",
        "            main_protagonist = next(iter(self.characters.values()))\n",
        "            main_character_name = main_protagonist.get(\"name\", \"Protagonist\")\n",
        "\n",
        "            act_structure = \"beginning\" if chapter_num <= self.num_chapters//3 else \\\n",
        "                           \"middle\" if chapter_num <= 2*self.num_chapters//3 else \"end\"\n",
        "\n",
        "            if chapter_num == 1:\n",
        "                chapter_type = \"introduction\"\n",
        "            elif chapter_num == self.num_chapters:\n",
        "                chapter_type = \"conclusion\"\n",
        "            elif chapter_num % 10 == 0:\n",
        "                chapter_type = \"pivotal\"\n",
        "            else:\n",
        "                chapter_type = \"development\"\n",
        "\n",
        "            system_prompt = f\"You are a plot architect for {self.genre} novels.\"\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Based on the following novel information, create a detailed plan for chapter {chapter_num} of {self.num_chapters}.\n",
        "            This is a {chapter_type} chapter in the {act_structure} of the story.\n",
        "\n",
        "            Novel Subject: {self.subject[:500]}...\n",
        "            Genre: {self.genre}\n",
        "            Main Character: {main_character_name}\n",
        "            World: {self.world_details.get('name', 'The world')}\n",
        "\n",
        "            Create a plan with:\n",
        "            1. Chapter title (evocative, fitting the genre and story)\n",
        "            2. Chapter goal (what this chapter accomplishes)\n",
        "            3. 3 key scenes\n",
        "            4. Character development\n",
        "            5. Plot advancement\n",
        "            6. Timeline and pacing\n",
        "            7. Emotional tone\n",
        "            8. Connection to next chapter\n",
        "\n",
        "            Format your response like this:\n",
        "            TITLE: [Chapter Title]\n",
        "            GOAL: [Chapter goal]\n",
        "            SCENES: [Scene 1], [Scene 2], [Scene 3]\n",
        "            CHARACTER_DEVELOPMENT: [Development details]\n",
        "            PLOT_ADVANCEMENT: [Plot details]\n",
        "            TIMELINE: [Timeline info]\n",
        "            EMOTIONAL_TONE: [Tone at end]\n",
        "            CONNECTION: [Hook for next chapter]\n",
        "            \"\"\"\n",
        "\n",
        "            plan_response = self._ollama_generate(prompt, system_prompt, temperature=0.7)\n",
        "\n",
        "            if \"[OLLAMA\" in plan_response:\n",
        "                print(f\"  Failed to generate fallback plan for Chapter {chapter_num}. Using minimal placeholder.\")\n",
        "                # Use absolute minimum fallback\n",
        "                self.chapter_plans[chapter_num] = {\n",
        "                    \"number\": chapter_num,\n",
        "                    \"title\": f\"Chapter {chapter_num}\",\n",
        "                    \"goal\": \"Continue the story progression\",\n",
        "                    \"scenes\": [\"Key scene in the narrative\", \"Character interaction\", \"Plot development\"],\n",
        "                    \"character_development\": f\"{main_character_name} continues their journey\",\n",
        "                    \"plot_advancement\": \"The story moves forward\",\n",
        "                    \"timeline_pacing\": \"Continues from previous chapter\",\n",
        "                    \"emotional_tone_end\": \"Mixed emotions\",\n",
        "                    \"connection_to_next\": \"Leads to next events\"\n",
        "                }\n",
        "            else:\n",
        "                # Parse the response\n",
        "                title_match = re.search(r\"TITLE:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "                goal_match = re.search(r\"GOAL:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "                scenes_match = re.search(r\"SCENES:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "                char_dev_match = re.search(r\"CHARACTER_DEVELOPMENT:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "                plot_match = re.search(r\"PLOT_ADVANCEMENT:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "                timeline_match = re.search(r\"TIMELINE:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "                tone_match = re.search(r\"EMOTIONAL_TONE:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "                connection_match = re.search(r\"CONNECTION:\\s*(.*?)(?:\\n|$)\", plan_response, re.IGNORECASE)\n",
        "\n",
        "                title = title_match.group(1).strip() if title_match else f\"Chapter {chapter_num}\"\n",
        "                goal = goal_match.group(1).strip() if goal_match else \"Continue the story\"\n",
        "                scenes_text = scenes_match.group(1).strip() if scenes_match else \"\"\n",
        "                scenes = [s.strip() for s in scenes_text.split(',') if s.strip()]\n",
        "                if not scenes:\n",
        "                    scenes = [\"Key scene in the narrative\", \"Character interaction\", \"Plot development\"]\n",
        "\n",
        "                self.chapter_plans[chapter_num] = {\n",
        "                    \"number\": chapter_num,\n",
        "                    \"title\": title,\n",
        "                    \"goal\": goal,\n",
        "                    \"scenes\": scenes,\n",
        "                    \"character_development\": char_dev_match.group(1).strip() if char_dev_match else \"Character development continues\",\n",
        "                    \"plot_advancement\": plot_match.group(1).strip() if plot_match else \"The plot advances\",\n",
        "                    \"timeline_pacing\": timeline_match.group(1).strip() if timeline_match else \"Time passes\",\n",
        "                    \"emotional_tone_end\": tone_match.group(1).strip() if tone_match else \"Mixed emotions\",\n",
        "                    \"connection_to_next\": connection_match.group(1).strip() if connection_match else \"Events lead to next chapter\"\n",
        "                }\n",
        "\n",
        "            print(f\"  Generated fallback plan for Chapter {chapter_num}: {self.chapter_plans[chapter_num]['title']}\")\n",
        "\n",
        "    # --- Phase 3: Prose Generation Loop ---\n",
        "    def _get_continuity_context_for_chapter(self, chapter_num):\n",
        "        \"\"\"\n",
        "        Gathers all relevant context from previous chapters and plans for generating the current chapter.\n",
        "        \"\"\"\n",
        "        context = f\"Overall Novel Subject: {self.subject}\\n\"\n",
        "        context += f\"Author Style: {self.author_style}, Genre: {self.genre}\\n\"\n",
        "        # Clean plot_outline from chapter count\n",
        "        cleaned_plot_outline = re.sub(r\"SUGGESTED_CHAPTER_COUNT:\\s*\\d+\", \"\", self.plot_outline, flags=re.IGNORECASE).strip()\n",
        "        context += f\"High-Level Plot Outline:\\n{cleaned_plot_outline}\\n\\n\"\n",
        "        context += f\"World Details: {json.dumps(self.world_details)}\\n\"\n",
        "        context += f\"Themes & Motifs: {json.dumps(self.themes_motifs)}\\n\\n\"\n",
        "\n",
        "        context += \"Character Profiles & Current Status (as of start of this chapter):\\n\"\n",
        "        for name, data in self.characters.items():\n",
        "            context += f\"- {name} ({data.get('role','N/A')}):\\n\"\n",
        "            context += f\"  Description: {data.get('description','N/A')}\\n\"\n",
        "            context += f\"  Motivations: {data.get('motivation','N/A')}. Initial Arc: {data.get('arc_summary','N/A')}\\n\"\n",
        "            context += f\"  Current Status: {data.get('current_status','unknown')}, Location: {data.get('current_location','unknown')}, Emotion: {data.get('emotional_state','unknown')}\\n\"\n",
        "            context += f\"  Known Facts: {', '.join(data.get('knowledge',[]))}\\n\"\n",
        "            if data.get('development_log'):\n",
        "                relevant_logs = [log for log in data['development_log'] if log['chapter'] < chapter_num]\n",
        "                if relevant_logs:\n",
        "                    last_dev = relevant_logs[-1]\n",
        "                    context += f\"  Last Noted Development (Ch {last_dev['chapter']}): {last_dev.get('summary', 'N/A')}\\n\"\n",
        "        context += \"\\n\"\n",
        "\n",
        "        if chapter_num > 1:\n",
        "            prev_chap_num = chapter_num - 1\n",
        "            prev_continuity = self.chapter_continuity_data.get(prev_chap_num, {})\n",
        "            prev_plan = self.chapter_plans.get(prev_chap_num, {})\n",
        "            context += f\"Summary of Previous Chapter ({prev_chap_num} - '{prev_plan.get('title', 'Untitled')}'):\\n\"\n",
        "            context += f\"{prev_continuity.get('summary', 'N/A')}\\n\"\n",
        "            context += f\"Ended with Emotional Tone: {prev_continuity.get('emotional_tone_end_achieved_in_summary', 'N/A')}\\n\"\n",
        "            context += f\"Timeline at end of Ch {prev_chap_num}: {prev_continuity.get('timeline_end', 'N/A')}\\n\"\n",
        "            context += f\"Hook for current chapter (from prev chapter's plan): {prev_plan.get('connection_to_next', 'N/A')}\\n\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "    def _generate_chapter_opener(self, chapter_num, current_chapter_plan):\n",
        "        \"\"\"Generates the opening paragraph(s) for the current chapter.\"\"\"\n",
        "        chapter_title_line = f\"Chapter {chapter_num} - {current_chapter_plan.get('title', 'Untitled')}\"\n",
        "\n",
        "        if chapter_num == 1:\n",
        "            return f\"{chapter_title_line}\\n\\n\" # For Ch1, prose gen starts right away\n",
        "\n",
        "        prev_chap_num = chapter_num - 1\n",
        "        prev_continuity = self.chapter_continuity_data.get(prev_chap_num, {})\n",
        "        prev_plan = self.chapter_plans.get(prev_chap_num, {})\n",
        "\n",
        "        system_prompt = f\"You are a novelist in the style of {self.author_style}, skilled at crafting chapter openings that immediately re-orient the reader and smoothly transition from the previous chapter's ending.\"\n",
        "        prompt = f\"\"\"\n",
        "        You are writing the VERY FIRST paragraph(s) for Chapter {chapter_num}, titled \"{current_chapter_plan.get('title', 'Untitled')}\".\n",
        "        This opening must seamlessly connect to the end of Chapter {prev_chap_num} and establish the immediate context for Chapter {chapter_num}.\n",
        "\n",
        "        Context from End of Chapter {prev_chap_num} ('{prev_plan.get('title', 'Untitled')}'):\n",
        "        - Summary of Ch {prev_chap_num}: {prev_continuity.get('summary', 'Previously...')[-1000:]}\n",
        "        - Actual Ending Hook/Transition Text from Ch {prev_chap_num}: \"{prev_continuity.get('ending_hook_text', 'The previous chapter ended.')}\"\n",
        "        - Emotional Tone at End of Ch {prev_chap_num}: {prev_continuity.get('emotional_tone_end_achieved_in_summary', 'Neutral')}\n",
        "        - Timeline at End of Ch {prev_chap_num}: {prev_continuity.get('timeline_end', 'Unknown')}\n",
        "        - Key Character States at End of Ch {prev_chap_num}: {json.dumps({name: {'status': data['current_status'], 'location': data['current_location'], 'emotion': data['emotional_state']} for name, data in self.characters.items()}, indent=2)}\n",
        "\n",
        "        Plan for Current Chapter ({chapter_num} - \"{current_chapter_plan.get('title', 'Untitled')}\"):\n",
        "        - Goal: {current_chapter_plan.get('goal', 'The story progresses.')}\n",
        "        - First Planned Scene Hint: {current_chapter_plan.get('scenes', ['A new scene begins.'])[0] if current_chapter_plan.get('scenes') else 'A new scene begins.'}\n",
        "        - Timeline & Pacing: {current_chapter_plan.get('timeline_pacing', 'As expected')}\n",
        "\n",
        "        Write 1-2 compelling opening paragraphs (approx 100-200 words) for Chapter {chapter_num}. These paragraphs should:\n",
        "        1. Directly acknowledge or subtly resolve the immediate hook/question left by Chapter {prev_chap_num}'s actual ending hook.\n",
        "        2. Establish the setting, characters present, and the time elapsed since the previous chapter (if any significant passage, use the Timeline Indicators from this chapter's plan).\n",
        "        3. Set the initial tone for Chapter {chapter_num}, which might be a continuation or a shift from the previous chapter's end.\n",
        "        4. Orient the reader quickly without extensive exposition. Focus on \"showing\" the new situation.\n",
        "        5. Make the transition feel natural and engaging, drawing the reader into the new chapter.\n",
        "        6. This is the *opening text* of Chapter {chapter_num}. Do NOT repeat the chapter title.\n",
        "\n",
        "        Opening paragraph(s) for Chapter {chapter_num}:\n",
        "        \"\"\"\n",
        "        opener_text = self._ollama_generate(prompt, system_prompt, temperature=0.68)\n",
        "        return f\"{chapter_title_line}\\n\\n{opener_text}\\n\\n\"\n",
        "\n",
        "\n",
        "    def _generate_scene_prose(self, chapter_num, scene_index, scene_description, current_chapter_plan, continuity_context, previous_scene_prose=\"\"):\n",
        "        \"\"\"Generates prose for a single scene within a chapter.\"\"\"\n",
        "        system_prompt = f\"You are a celebrated novelist in the style of {self.author_style}, writing a {self.genre} novel. Your prose is vivid, emotionally resonant, and drives the plot forward. You excel at 'showing, not telling' and making fantastical elements relatable.\"\n",
        "\n",
        "        motif_to_weave = \"N/A\"\n",
        "        if self.themes_motifs.get(\"motifs\") and len(self.themes_motifs[\"motifs\"]) > 0 :\n",
        "            motif_to_weave = self.themes_motifs[\"motifs\"][(chapter_num + scene_index -1) % len(self.themes_motifs[\"motifs\"])]\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        {continuity_context}\n",
        "\n",
        "        Current Chapter Plan ({chapter_num} - \"{current_chapter_plan.get('title', 'Untitled')}\"):\n",
        "        - Chapter Goal: {current_chapter_plan.get('goal', 'N/A')}\n",
        "        - Full Scene Breakdown for this chapter: {json.dumps(current_chapter_plan.get('scenes',[]))}\n",
        "        - Character Development Focus for this chapter: {current_chapter_plan.get('character_development', 'N/A')}\n",
        "        - Plot Advancement for this chapter: {current_chapter_plan.get('plot_advancement', 'N/A')}\n",
        "        - Planned Emotional Tone (End of Chapter): {current_chapter_plan.get('emotional_tone_end', 'N/A')}\n",
        "        - Timeline & Pacing for this chapter: {current_chapter_plan.get('timeline_pacing', 'N/A')}\n",
        "\n",
        "        Prose written SO FAR in THIS CHAPTER (before this scene):\n",
        "        ---\n",
        "        {previous_scene_prose[-2000:] if previous_scene_prose else \"This is the first scene of the chapter (after the chapter title and opener).\"}\n",
        "        ---\n",
        "\n",
        "        YOUR TASK: Write the narrative prose for THE FOLLOWING SPECIFIC SCENE ONLY.\n",
        "        Scene {scene_index + 1} Description (from chapter plan): \"{scene_description}\"\n",
        "\n",
        "        INSTRUCTIONS FOR THIS SCENE:\n",
        "        1.  **Narrative Focus:** Write approximately 300-700 words (adjust based on scene importance) bringing THIS SCENE to life.\n",
        "        2.  **Style & Tone:** Adhere to {self.author_style}'s style. Maintain the chapter's intended pacing and build towards its emotional goal.\n",
        "        3.  **\"Show, Don't Tell\":** Demonstrate emotions, thoughts, and plot points through actions, dialogue, sensory details, and internal monologues. Make character reactions and decisions clear through their behavior.\n",
        "        4.  **Relatability & Emotional Depth:** Even in fantastical situations, ground character experiences in relatable emotions. Describe what things *feel* like.\n",
        "        5.  **Sensory Details:** Weave in vivid sensory details (sight, sound, smell, touch, taste) consistent with the world and scene location.\n",
        "        6.  **Character Consistency:** Ensure characters act and speak consistently with their established profiles, motivations, current emotional state, and knowledge. Reflect their planned development for this chapter.\n",
        "        7.  **Dialogue:** If dialogue is part of the scene, make it natural, character-specific, and purposeful (revealing character, advancing plot, or building tension).\n",
        "        8.  **Motif Integration:** Subtly weave in the recurring motif: '{motif_to_weave}' if it fits naturally within this scene's events. Do not force it.\n",
        "        9.  **Continuity:** Ensure this scene flows logically from any previous prose in this chapter. Do NOT repeat information.\n",
        "        10. **Output:** Generate ONLY the newly written narrative paragraphs for THIS SCENE. Do not add scene numbers or headings.\n",
        "\n",
        "        Begin Scene {scene_index + 1} prose now:\n",
        "        \"\"\"\n",
        "        scene_prose = self._ollama_generate(prompt, system_prompt, temperature=0.72, top_p=0.92)\n",
        "        return scene_prose\n",
        "\n",
        "    def _analyze_inter_chapter_flow(self, previous_chapter_num, current_chapter_num, current_chapter_opening_text):\n",
        "        \"\"\"\n",
        "        Analyzes the narrative flow between the end of the previous chapter and the start of the current chapter.\n",
        "        \"\"\"\n",
        "        print(f\"  Analyzing flow from Chapter {previous_chapter_num} to Chapter {current_chapter_num}...\")\n",
        "        if previous_chapter_num not in self.chapter_continuity_data or \\\n",
        "           previous_chapter_num not in self.chapter_plans or \\\n",
        "           current_chapter_num not in self.chapter_plans:\n",
        "            print(\"    Skipping flow analysis: Missing data for previous or current chapter.\")\n",
        "            return \"Flow analysis skipped due to missing data.\"\n",
        "\n",
        "        prev_continuity = self.chapter_continuity_data[previous_chapter_num]\n",
        "        prev_plan = self.chapter_plans[previous_chapter_num]\n",
        "        current_plan = self.chapter_plans[current_chapter_num]\n",
        "\n",
        "        prev_summary = prev_continuity.get(\"summary\", \"N/A\")\n",
        "        prev_hook = prev_continuity.get(\"ending_hook_text\", \"N/A\")\n",
        "        prev_title = prev_plan.get(\"title\", \"Untitled Previous Chapter\")\n",
        "\n",
        "        current_title = current_plan.get(\"title\", \"Untitled Current Chapter\")\n",
        "        current_goal = current_plan.get(\"goal\", \"N/A\")\n",
        "\n",
        "        opening_paragraphs_only = \"\\n\".join(current_chapter_opening_text.split('\\n\\n')[1:]).strip()\n",
        "\n",
        "        system_prompt = \"You are an expert literary editor specializing in narrative coherence and flow between chapters.\"\n",
        "        prompt = f\"\"\"\n",
        "        Analyze the transition and flow from the end of Chapter {previous_chapter_num} (\"{prev_title}\") to the beginning of Chapter {current_chapter_num} (\"{current_title}\").\n",
        "\n",
        "        CONTEXT:\n",
        "        End of Chapter {previous_chapter_num} (\"{prev_title}\"):\n",
        "        - Summary: {prev_summary[-1000:]}\n",
        "        - Actual Ending Hook/Transition Text: \"{prev_hook}\"\n",
        "        - Key Character States at End (from continuity): {json.dumps({name: {'status': data['current_status'], 'location': data['current_location'], 'emotion': data['emotional_state']} for name, data in self.characters.items() if data.get('first_appearance_chapter', 0) <= previous_chapter_num and data.get('first_appearance_chapter', 0) > 0}, indent=2)}\n",
        "        - Planned Connection from Ch {previous_chapter_num} to Ch {current_chapter_num}: \"{prev_plan.get('connection_to_next', 'N/A')}\"\n",
        "\n",
        "\n",
        "        Beginning of Chapter {current_chapter_num} (\"{current_title}\"):\n",
        "        - Chapter Goal: {current_goal}\n",
        "        - Actual Opening Paragraph(s): \"{opening_paragraphs_only}\"\n",
        "\n",
        "        EVALUATION TASK:\n",
        "        Provide a brief (1-2 paragraph) analysis covering these points:\n",
        "        1.  **Hook Resolution:** How well does the opening of Chapter {current_chapter_num} address or follow up on the ending hook/transition of Chapter {previous_chapter_num}?\n",
        "        2.  **Plot Continuity:** Is there a logical and clear progression of plot events or situation from the end of the previous chapter to the start of the current one?\n",
        "        3.  **Character Consistency:** Do the characters' states (emotional, physical, location, knowledge) seem consistent and logically follow from the previous chapter's end into the current chapter's opening?\n",
        "        4.  **Tone & Pacing:** Is the transition in emotional tone and pacing smooth and appropriate, or jarring?\n",
        "        5.  **Overall Coherence:** How effective is the overall flow between these two chapters? Does it feel natural and engaging for the reader?\n",
        "\n",
        "        Be concise and constructive.\n",
        "        Flow Analysis:\n",
        "        \"\"\"\n",
        "        flow_analysis_text = self._ollama_generate(prompt, system_prompt, temperature=0.5)\n",
        "        print(f\"    Flow Analysis Result: {flow_analysis_text[:200]}...\")\n",
        "\n",
        "        if current_chapter_num not in self.chapter_continuity_data:\n",
        "            self.chapter_continuity_data[current_chapter_num] = {}\n",
        "        self.chapter_continuity_data[current_chapter_num][\"flow_analysis_from_previous\"] = flow_analysis_text\n",
        "\n",
        "        return flow_analysis_text\n",
        "\n",
        "\n",
        "    def _update_chapter_continuity_data(self, chapter_num, full_chapter_content, is_final_pass_for_chapter=False):\n",
        "        \"\"\"\n",
        "        Analyzes generated chapter content to update continuity data (summary, character states, timeline, emotion).\n",
        "        \"\"\"\n",
        "        print(f\"Updating continuity data for Chapter {chapter_num} ({'final pass' if is_final_pass_for_chapter else 'interim pass'})...\")\n",
        "        entry = self.chapter_continuity_data.get(chapter_num, {})\n",
        "\n",
        "        summary_system_prompt = \"You are a literary analyst. Your task is to summarize chapter content accurately and concisely for continuity purposes.\"\n",
        "        summary_prompt = f\"\"\"\n",
        "        Create a concise yet detailed summary of the following chapter content (Chapter {chapter_num}).\n",
        "        Focus on all key plot events, character actions and significant development, setting details, revelations, emotional shifts, and how it ends.\n",
        "        This summary will be crucial context for writing the NEXT chapter.\n",
        "        CHAPTER CONTENT (Chapter {chapter_num} - \"{self.chapter_plans.get(chapter_num, {}).get('title', 'Untitled')}\"):\n",
        "        ---\n",
        "        {full_chapter_content}\n",
        "        ---\n",
        "        Detailed Summary of Chapter {chapter_num}:\n",
        "        \"\"\"\n",
        "        entry[\"summary\"] = self._ollama_generate(summary_prompt, summary_system_prompt, temperature=0.5)\n",
        "\n",
        "        if is_final_pass_for_chapter:\n",
        "            active_chars_in_chapter = []\n",
        "            current_chapter_plan = self.chapter_plans.get(chapter_num, {})\n",
        "            if current_chapter_plan:\n",
        "                for scene_desc in current_chapter_plan.get(\"scenes\", []):\n",
        "                    char_involved_match = re.search(r\"Characters Involved:\\s*(.*?)(?:\\.\\s*Key Revelation|$)\", scene_desc, re.IGNORECASE)\n",
        "                    if char_involved_match:\n",
        "                        names_str = char_involved_match.group(1)\n",
        "                        potential_names = re.split(r'[,\\s]+and\\s+|\\s*,\\s*|[,\\s]+with\\s+', names_str)\n",
        "                        for char_name_candidate in potential_names:\n",
        "                            clean_name = char_name_candidate.strip().rstrip('.').strip()\n",
        "                            if clean_name and clean_name in self.characters and clean_name not in active_chars_in_chapter:\n",
        "                                active_chars_in_chapter.append(clean_name)\n",
        "                char_dev_focus = current_chapter_plan.get(\"character_development\", \"\")\n",
        "                for char_name in self.characters.keys():\n",
        "                    if re.search(r'\\b' + re.escape(char_name) + r'\\b', char_dev_focus, re.IGNORECASE) and char_name not in active_chars_in_chapter:\n",
        "                            active_chars_in_chapter.append(char_name)\n",
        "\n",
        "            if not active_chars_in_chapter: active_chars_in_chapter = list(self.characters.keys())\n",
        "\n",
        "            char_update_system_prompt = \"You are a narrative continuity expert. Update character states based on chapter events.\"\n",
        "            char_update_prompt = f\"\"\"\n",
        "            Based on the FULL content of Chapter {chapter_num} below, update the status for EACH listed character.\n",
        "            Chapter {chapter_num} (\"{self.chapter_plans.get(chapter_num, {}).get('title', 'Untitled')}\") Content:\n",
        "            ---\n",
        "            {full_chapter_content}\n",
        "            ---\n",
        "            For EACH of these characters who appeared or were central: {', '.join(active_chars_in_chapter) if active_chars_in_chapter else \"Summarize general impact if no specific characters listed.\"}\n",
        "            Provide the following updates. If a character did not appear or had no significant change for a field, state \"No change\" or \"Did not appear.\"\n",
        "\n",
        "            CHARACTER NAME: [Character's Name]\n",
        "            -   STATUS CHANGE: [e.g., \"Remains alive,\" \"Injured (twisted ankle),\" \"Captured,\" \"Learned X,\" \"Decided Y.\"]\n",
        "            -   LOCATION AT END OF CHAPTER: [Specific location.]\n",
        "            -   EMOTIONAL STATE AT END OF CHAPTER: [e.g., \"Hopeful,\" \"Grieving,\" \"Determined,\" \"Suspicious.\"]\n",
        "            -   KEY DEVELOPMENT/ACTION: [Significant actions, learnings, or internal changes.]\n",
        "            -   RELATIONSHIP CHANGES: [e.g., \"Strained with Z over X,\" \"New alliance with W.\"]\n",
        "            -   NEW KNOWLEDGE/SECRETS ACQUIRED: [New critical info, clues, secrets.]\n",
        "\n",
        "            Format clearly for each character.\n",
        "            \"\"\"\n",
        "            character_updates_text = self._ollama_generate(char_update_prompt, char_update_system_prompt, temperature=0.55)\n",
        "            entry[\"character_updates_text\"] = character_updates_text\n",
        "\n",
        "            current_char_name_update = None\n",
        "            parsed_updates_for_log = {}\n",
        "            for line in character_updates_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                name_match = re.match(r\"CHARACTER NAME:\\s*(.*)\", line, re.IGNORECASE)\n",
        "                if name_match:\n",
        "                    if current_char_name_update and parsed_updates_for_log and current_char_name_update in self.characters:\n",
        "                        self.characters[current_char_name_update][\"development_log\"].append(\n",
        "                            {\"chapter\": chapter_num, \"summary\": \"Updates from chapter events\", **parsed_updates_for_log}\n",
        "                        )\n",
        "                    current_char_name_update = name_match.group(1).strip()\n",
        "                    parsed_updates_for_log = {}\n",
        "                    if current_char_name_update not in self.characters:\n",
        "                        current_char_name_update = None\n",
        "                    elif self.characters[current_char_name_update].get(\"first_appearance_chapter\", 0) == 0:\n",
        "                            self.characters[current_char_name_update][\"first_appearance_chapter\"] = chapter_num\n",
        "                    continue\n",
        "\n",
        "                if current_char_name_update and current_char_name_update in self.characters:\n",
        "                    char_obj = self.characters[current_char_name_update]\n",
        "                    def get_value(text, key_phrase):\n",
        "                        # Match key phrase at start of line, possibly after \"- \"\n",
        "                        if re.match(r\"-\\s*\" + re.escape(key_phrase.upper()), text.upper()) or text.upper().startswith(key_phrase.upper()):\n",
        "                            val_part = re.split(\":\",text,1)\n",
        "                            val = val_part[1].strip() if len(val_part) > 1 else \"\"\n",
        "                            if val.lower() in [\"no change\", \"did not appear\", \"n/a\", \"none\", \"no significant change.\"]:\n",
        "                                return None\n",
        "                            return val\n",
        "                        return \"NO_MATCH\"\n",
        "\n",
        "                    status_val = get_value(line, \"STATUS CHANGE\")\n",
        "                    if status_val != \"NO_MATCH\":\n",
        "                        if status_val is not None: char_obj[\"current_status\"] = status_val\n",
        "                        parsed_updates_for_log[\"status\"] = status_val if status_val is not None else \"No change\"\n",
        "                        continue\n",
        "                    loc_val = get_value(line, \"LOCATION AT END OF CHAPTER\")\n",
        "                    if loc_val != \"NO_MATCH\":\n",
        "                        if loc_val is not None: char_obj[\"current_location\"] = loc_val\n",
        "                        parsed_updates_for_log[\"location\"] = loc_val if loc_val is not None else \"No change\"\n",
        "                        continue\n",
        "                    emo_val = get_value(line, \"EMOTIONAL STATE AT END OF CHAPTER\")\n",
        "                    if emo_val != \"NO_MATCH\":\n",
        "                        if emo_val is not None: char_obj[\"emotional_state\"] = emo_val\n",
        "                        parsed_updates_for_log[\"emotion\"] = emo_val if emo_val is not None else \"No change\"\n",
        "                        continue\n",
        "                    dev_val = get_value(line, \"KEY DEVELOPMENT/ACTION\")\n",
        "                    if dev_val != \"NO_MATCH\":\n",
        "                        parsed_updates_for_log[\"development\"] = dev_val if dev_val is not None else \"No change\"\n",
        "                        continue\n",
        "                    rel_val = get_value(line, \"RELATIONSHIP CHANGES\")\n",
        "                    if rel_val != \"NO_MATCH\":\n",
        "                        parsed_updates_for_log[\"relationships_changed\"] = rel_val if rel_val is not None else \"No change\"\n",
        "                        continue\n",
        "                    know_val = get_value(line, \"NEW KNOWLEDGE/SECRETS ACQUIRED\")\n",
        "                    if know_val != \"NO_MATCH\":\n",
        "                        if know_val is not None and know_val not in char_obj[\"knowledge\"]:\n",
        "                            char_obj[\"knowledge\"].append(know_val)\n",
        "                        parsed_updates_for_log[\"new_knowledge\"] = know_val if know_val is not None else \"No change\"\n",
        "                        continue\n",
        "            if current_char_name_update and parsed_updates_for_log and current_char_name_update in self.characters:\n",
        "                self.characters[current_char_name_update][\"development_log\"].append(\n",
        "                    {\"chapter\": chapter_num, \"summary\": \"Updates from chapter events\", **parsed_updates_for_log}\n",
        "                )\n",
        "\n",
        "        timeline_system_prompt = \"You are a temporal analyst for narratives. Extract timeline information precisely.\"\n",
        "        timeline_prompt = f\"\"\"\n",
        "        Analyze Chapter {chapter_num}'s content for timeline information:\n",
        "        Chapter {chapter_num} (\"{self.chapter_plans.get(chapter_num, {}).get('title', 'Untitled')}\") Content:\n",
        "        ---\n",
        "        {full_chapter_content}\n",
        "        ---\n",
        "        Determine:\n",
        "        1.  APPROXIMATE TIME ELAPSED DURING THIS CHAPTER: [e.g., \"Several hours,\" \"One full day,\" \"A week.\"]\n",
        "        2.  TIME OF DAY/DATE AT THE END OF THIS CHAPTER: [e.g., \"Evening of the third day,\" \"Midnight,\" \"Following morning.\"]\n",
        "        3.  ANY SPECIFIC TIME MARKERS MENTIONED: [e.g., \"After dawn,\" \"Two moons passed,\" \"Clock struck three.\"]\n",
        "        Reply in format:\n",
        "        ELAPSED: [answer]\n",
        "        END_TIME: [answer]\n",
        "        MARKERS: [answer]\n",
        "        \"\"\"\n",
        "        timeline_text = self._ollama_generate(timeline_prompt, timeline_system_prompt, temperature=0.4)\n",
        "\n",
        "        # More efficient regex use\n",
        "        elapsed_match = re.search(r\"ELAPSED:\\s*(.*?)(?:\\n|$)\", timeline_text, re.IGNORECASE)\n",
        "        entry[\"timeline_elapsed\"] = elapsed_match.group(1).strip() if elapsed_match else \"N/A\"\n",
        "\n",
        "        end_time_match = re.search(r\"END_TIME:\\s*(.*?)(?:\\n|$)\", timeline_text, re.IGNORECASE)\n",
        "        entry[\"timeline_end\"] = end_time_match.group(1).strip() if end_time_match else \"N/A\"\n",
        "\n",
        "        markers_match = re.search(r\"MARKERS:\\s*(.*?)(?:\\n|$)\", timeline_text, re.IGNORECASE)\n",
        "        entry[\"timeline_markers\"] = markers_match.group(1).strip() if markers_match else \"N/A\"\n",
        "\n",
        "        entry[\"emotional_tone_end_achieved_in_summary\"] = entry[\"summary\"][-300:]\n",
        "        if \"ending_hook_text\" not in entry:\n",
        "            entry[\"ending_hook_text\"] = \"N/A (Last chapter or hook not generated)\"\n",
        "\n",
        "\n",
        "        self.chapter_continuity_data[chapter_num] = entry\n",
        "\n",
        "    def _generate_chapter_transition_hook(self, chapter_num, current_chapter_content, current_chapter_continuity):\n",
        "        \"\"\"Generates the transition hook/paragraph(s) for the end of the current chapter.\"\"\"\n",
        "        if chapter_num >= self.num_chapters: return \"\" # No hook for the very last chapter\n",
        "\n",
        "        next_chap_num = chapter_num + 1\n",
        "        next_chapter_plan = self.chapter_plans.get(next_chap_num)\n",
        "        if not next_chapter_plan:\n",
        "            print(f\"Warning: No plan found for Chapter {next_chap_num} to generate hook from Chapter {chapter_num}.\")\n",
        "            return \"\\n\\n(The story continues...)\" # Generic fallback\n",
        "\n",
        "        system_prompt = f\"You are a master storyteller in the style of {self.author_style}, crafting suspenseful and engaging chapter endings that seamlessly lead into the next.\"\n",
        "        prompt = f\"\"\"\n",
        "        You are writing the VERY LAST paragraph(s) for Chapter {chapter_num} (\"{self.chapter_plans.get(chapter_num,{}).get('title','Untitled')}\").\n",
        "        This transition must create anticipation for Chapter {next_chap_num} (\"{next_chapter_plan.get('title','Untitled')}\").\n",
        "\n",
        "        End of Chapter {chapter_num} Context:\n",
        "        - Current Chapter Summary (focus on ending events): {current_chapter_continuity.get('summary', 'The chapter concluded.')[-1000:]}\n",
        "        - Emotional Tone at End (inferred from summary): {current_chapter_continuity.get('emotional_tone_end_achieved_in_summary', 'Neutral')}\n",
        "        - Last ~500 characters of Chapter {chapter_num} (before this hook): \"{current_chapter_content[-500:]}\"\n",
        "        - Key Character States at End of Ch {chapter_num}: {json.dumps({name: {'status': data['current_status'], 'location': data['current_location'], 'emotion': data['emotional_state']} for name, data in self.characters.items()}, indent=2)}\n",
        "\n",
        "        Plan for NEXT Chapter ({next_chap_num} - \"{next_chapter_plan.get('title', 'Untitled')}\"):\n",
        "        - Next Chapter Goal: {next_chapter_plan.get('goal', 'The story continues.')}\n",
        "        - Next Chapter Likely Opening Scene/Focus: {next_chapter_plan.get('scenes', ['A new challenge arises.'])[0] if next_chapter_plan.get('scenes') else 'A new challenge arises.'}\n",
        "        - Next Chapter Character Development Focus: {next_chapter_plan.get('character_development', 'Further growth.')}\n",
        "        - Planned connection from current Ch {chapter_num} to next Ch {next_chap_num}: \"{self.chapter_plans.get(chapter_num,{}).get('connection_to_next','N/A')}\"\n",
        "\n",
        "        Write 1-2 compelling paragraphs (approx 75-150 words) that will be the *final text* of Chapter {chapter_num}. This hook should:\n",
        "        1.  Provide a sense of immediate closure for Chapter {chapter_num}'s main events but leave the reader wanting more.\n",
        "        2.  Directly foreshadow, question, or set up the conflict, theme, or situation of Chapter {next_chap_num} based on its plan AND the planned connection.\n",
        "        3.  Maintain or slightly shift the established emotional tone to build suspense, curiosity, or dread for what's next.\n",
        "        4.  Avoid clichés. Be original and impactful. Ensure it feels like a natural continuation of the narrative, not an abrupt summary.\n",
        "        5.  This is the *final text* of Chapter {chapter_num}.\n",
        "\n",
        "        Final transition paragraph(s) for Chapter {chapter_num}:\n",
        "        \"\"\"\n",
        "        hook_text = self._ollama_generate(prompt, system_prompt, temperature=0.75)\n",
        "\n",
        "        if chapter_num in self.chapter_continuity_data:\n",
        "            self.chapter_continuity_data[chapter_num][\"ending_hook_text\"] = hook_text.strip()\n",
        "        else:\n",
        "            self.chapter_continuity_data[chapter_num] = {\"ending_hook_text\": hook_text.strip()}\n",
        "\n",
        "        return f\"\\n\\n{hook_text}\"\n",
        "\n",
        "\n",
        "    def generate_novel_content(self):\n",
        "        \"\"\"\n",
        "        Main loop to generate content for all chapters, applying coherence measures.\n",
        "        \"\"\"\n",
        "        print(\"\\n--- Generating Full Novel Content (Chapter by Chapter) ---\")\n",
        "        if not self.chapter_plans or self.num_chapters == 0:\n",
        "            print(\"ERROR: Cannot generate novel content without detailed chapter plans or chapter count.\")\n",
        "            return False\n",
        "\n",
        "        for i in range(1, self.num_chapters + 1):\n",
        "            print(f\"\\n--- Generating Chapter {i} of {self.num_chapters} ---\")\n",
        "            current_chapter_plan = self.chapter_plans.get(i)\n",
        "            if not current_chapter_plan:\n",
        "                print(f\"ERROR: No plan found for Chapter {i}. Skipping.\")\n",
        "                self.generated_chapters_content[i] = f\"[ERROR: No plan found for Chapter {i}]\"\n",
        "                self.chapter_continuity_data[i] = {\"summary\": \"Error: No plan.\", \"character_updates_text\": \"\", \"timeline_end\": \"Unknown\", \"emotional_tone_end_achieved_in_summary\": \"Error\", \"ending_hook_text\": \"\", \"flow_analysis_from_previous\": \"N/A\"}\n",
        "                continue\n",
        "\n",
        "            continuity_context = self._get_continuity_context_for_chapter(i)\n",
        "\n",
        "            chapter_opener_text_with_title = self._generate_chapter_opener(i, current_chapter_plan)\n",
        "\n",
        "            chapter_prose = chapter_opener_text_with_title\n",
        "\n",
        "            if i > 1:\n",
        "                self._analyze_inter_chapter_flow(i - 1, i, chapter_opener_text_with_title)\n",
        "\n",
        "            scenes = current_chapter_plan.get(\"scenes\", [])\n",
        "            if not scenes:\n",
        "                print(f\"Warning: No scenes defined in plan for Chapter {i}. Chapter might be short or only opener/hook.\")\n",
        "                if chapter_prose.strip() == chapter_opener_text_with_title.strip(): # If only opener was generated\n",
        "                     chapter_prose += \"\\n\\n[This chapter's plan had no specific scenes. The narrative continues based on the chapter goal.]\\n\\n\"\n",
        "            else:\n",
        "                accumulated_scene_prose_for_chapter = chapter_opener_text_with_title # Start with opener\n",
        "                for scene_idx, scene_desc in enumerate(scenes):\n",
        "                    print(f\"  Generating Scene {scene_idx + 1} of {len(scenes)} for Chapter {i}: {scene_desc[:80]}...\")\n",
        "                    scene_specific_prose = self._generate_scene_prose(i, scene_idx, scene_desc, current_chapter_plan, continuity_context, accumulated_scene_prose_for_chapter)\n",
        "                    if \"[OLLAMA\" in scene_specific_prose:\n",
        "                        print(f\"    ERROR generating scene {scene_idx+1}: {scene_specific_prose}\")\n",
        "                        scene_specific_prose = f\"\\n\\n[Error generating scene: {scene_desc[:50]}...]\\n\\n\"\n",
        "\n",
        "                    chapter_prose += scene_specific_prose + \"\\n\\n\" # Append scene to overall chapter prose\n",
        "                    accumulated_scene_prose_for_chapter += scene_specific_prose + \"\\n\\n\" # Update context for next scene in this chapter\n",
        "                    time.sleep(0.2)\n",
        "\n",
        "            # Interim continuity update (based on content BEFORE the hook for this chapter)\n",
        "            # This is useful for the hook generation itself, if it needs summary of current chapter.\n",
        "            self._update_chapter_continuity_data(i, chapter_prose.strip(), is_final_pass_for_chapter=False)\n",
        "\n",
        "            if i < self.num_chapters:\n",
        "                print(f\"  Generating transition hook for Chapter {i}...\")\n",
        "                hook_text = self._generate_chapter_transition_hook(i, chapter_prose.strip(), self.chapter_continuity_data[i])\n",
        "                chapter_prose += hook_text\n",
        "\n",
        "            self.generated_chapters_content[i] = chapter_prose.strip()\n",
        "            print(f\"  Chapter {i} ('{current_chapter_plan.get('title', 'Untitled')}') content generated (approx length: {len(chapter_prose)} chars).\")\n",
        "\n",
        "            # FINAL continuity update for the chapter (with opener, scenes, and hook included)\n",
        "            self._update_chapter_continuity_data(i, self.generated_chapters_content[i], is_final_pass_for_chapter=True)\n",
        "\n",
        "            if i < self.num_chapters:\n",
        "                print(\"Pausing briefly before next chapter...\")\n",
        "                time.sleep(0.5)\n",
        "\n",
        "        return True\n",
        "\n",
        "    # --- Transition Checking Phase ---\n",
        "    def _check_and_improve_transition(self, prev_chapter_num, current_chapter_num):\n",
        "        \"\"\"Checks transition from prev to current chapter and improves if needed.\"\"\"\n",
        "        print(f\"\\n--- Checking transition from Chapter {prev_chapter_num} to {current_chapter_num} ---\")\n",
        "\n",
        "        prev_chapter_content = self.generated_chapters_content.get(prev_chapter_num)\n",
        "        current_chapter_content = self.generated_chapters_content.get(current_chapter_num)\n",
        "\n",
        "        if not prev_chapter_content or not current_chapter_content:\n",
        "            print(\"  Skipping transition check: Missing content for one or both chapters.\")\n",
        "            return\n",
        "\n",
        "        system_prompt = \"\"\"You are a professional editor specializing in narrative flow and chapter transitions.\"\"\"\n",
        "        prompt = f\"\"\"Analyze the transition between the end of the previous chapter and the beginning of the current chapter.\n",
        "\n",
        "        END OF PREVIOUS CHAPTER ({prev_chapter_num}):\n",
        "        ---\n",
        "        {prev_chapter_content[-1000:]}\n",
        "        ---\n",
        "\n",
        "        BEGINNING OF CURRENT CHAPTER ({current_chapter_num}):\n",
        "        ---\n",
        "        {current_chapter_content[:1000]}\n",
        "        ---\n",
        "\n",
        "        If the transition is already smooth and logical, respond ONLY with the exact text:\n",
        "        TRANSITION: SMOOTH\n",
        "\n",
        "        Otherwise, provide an improved beginning for the current chapter (first 1-3 paragraphs, approx 100-250 words) that:\n",
        "        1. Creates a smoother, more logical connection with the previous chapter's ending hook/state.\n",
        "        2. Avoids repeating information already established.\n",
        "        3. Maintains character and plot consistency.\n",
        "        4. Progresses the timeline naturally.\n",
        "        5. Matches the established author style ({self.author_style}).\n",
        "\n",
        "        Start your response with the exact text \"TRANSITION: REVISED\" followed by the revised beginning paragraphs. Do NOT include the chapter title in the revised text.\n",
        "        \"\"\"\n",
        "        transition_check_result = self._ollama_generate(prompt, system_prompt, temperature=0.6)\n",
        "\n",
        "        if \"[OLLAMA\" in transition_check_result:\n",
        "            print(f\"  Error during transition check: {transition_check_result}\")\n",
        "        elif \"TRANSITION: REVISED\" in transition_check_result:\n",
        "            try:\n",
        "                revised_beginning = transition_check_result.split(\"TRANSITION: REVISED\", 1)[1].strip()\n",
        "\n",
        "                if revised_beginning:\n",
        "                    print(f\"  Transition needs improvement. Applying revised opening to Chapter {current_chapter_num}.\")\n",
        "                    original_lines = current_chapter_content.split('\\n', 1) # Split only the first line (title)\n",
        "                    original_title_line = original_lines[0]\n",
        "\n",
        "                    # Find where the original opener text effectively ends.\n",
        "                    # This is a heuristic. We assume the opener is before the first \"scene\" content.\n",
        "                    # A simple way is to replace the first few paragraphs.\n",
        "                    # Let's find the end of the original opener by looking for the second double newline after the title.\n",
        "\n",
        "                    body_after_title = original_lines[1] if len(original_lines) > 1 else \"\"\n",
        "                    # Split the body into paragraphs, keeping double newlines as separators\n",
        "                    # The opener is usually the first paragraph block after the title line\n",
        "                    # For robustness, we find the first distinct section of the original chapter body after the title.\n",
        "                    # The title itself is `Chapter X - YYY\\n\\nActual Opener Text...`\n",
        "                    # So, current_chapter_content has Title\\n\\nOpener\\n\\nScene1...\n",
        "\n",
        "                    # Split after the first double newline (which is after the title)\n",
        "                    parts_after_title_line = current_chapter_content.split('\\n\\n', 1)\n",
        "                    if len(parts_after_title_line) > 1:\n",
        "                        original_opener_and_rest = parts_after_title_line[1]\n",
        "                        # Now split the original_opener_and_rest to separate the opener from scenes\n",
        "                        # Assuming opener is one block of text followed by \\n\\n\n",
        "                        original_opener_parts = original_opener_and_rest.split('\\n\\n', 1)\n",
        "                        original_rest_of_chapter = original_opener_parts[1] if len(original_opener_parts) > 1 else \"\"\n",
        "\n",
        "                        self.generated_chapters_content[current_chapter_num] = f\"{original_title_line}\\n\\n{revised_beginning}\\n\\n{original_rest_of_chapter}\".strip()\n",
        "                        print(f\"  Chapter {current_chapter_num} opening revised successfully.\")\n",
        "                    else: # Chapter content was just the title line or title + one block\n",
        "                         self.generated_chapters_content[current_chapter_num] = f\"{original_title_line}\\n\\n{revised_beginning}\".strip()\n",
        "                         print(f\"  Chapter {current_chapter_num} (short) opening revised successfully.\")\n",
        "\n",
        "                else:\n",
        "                    print(\"  Transition check indicated revision needed, but no revised text was provided by LLM.\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error applying revised transition for Chapter {current_chapter_num}: {e}\")\n",
        "        elif \"TRANSITION: SMOOTH\" in transition_check_result:\n",
        "            print(\"  Transition is smooth. No changes needed.\")\n",
        "        else:\n",
        "            print(f\"  Transition check response was unclear: {transition_check_result[:200]}... No changes applied.\")\n",
        "\n",
        "\n",
        "    def _perform_final_transition_checks(self):\n",
        "        \"\"\"Loops through all chapters to check and improve transitions.\"\"\"\n",
        "        print(\"\\n--- Performing Final Pass: Checking Chapter Transitions ---\")\n",
        "        if len(self.generated_chapters_content) < 2:\n",
        "            print(\"  Skipping transition checks (less than 2 chapters generated).\")\n",
        "            return\n",
        "\n",
        "        for i in range(2, self.num_chapters + 1):\n",
        "            if i in self.generated_chapters_content and (i - 1) in self.generated_chapters_content:\n",
        "                self._check_and_improve_transition(i - 1, i)\n",
        "                time.sleep(0.5)\n",
        "            else:\n",
        "                print(f\"  Skipping transition check for Chapter {i} (missing previous or current chapter content).\")\n",
        "        print(\"--- Finished Final Transition Checks ---\")\n",
        "\n",
        "\n",
        "    # --- Phase 4: Compilation & Output Methods ---\n",
        "    def generate_novel_title(self):\n",
        "        \"\"\"Generates a compelling title for the novel.\"\"\"\n",
        "        print(\"\\n--- Generating Novel Title ---\")\n",
        "        if not self.subject or not self.characters or not self.themes_motifs:\n",
        "            self.novel_title = f\"A {self.genre.replace('/', ' ')} Story\"\n",
        "            print(f\"Warning: Insufficient data for title generation. Using placeholder: {self.novel_title}\")\n",
        "            return\n",
        "\n",
        "        system_prompt = f\"You are a creative book title generator, expert in {self.genre} and the style of {self.author_style}.\"\n",
        "        prompt = f\"\"\"\n",
        "        Generate ONE compelling and marketable novel title based on the following details.\n",
        "        The title must be highly consistent with the genre, author's style, subject, main character(s), world, and core themes.\n",
        "        It should be intriguing, memorable, and not overly generic.\n",
        "\n",
        "        Novel Subject: {self.subject}\n",
        "        Genre: {self.genre}\n",
        "        Author's Style Inspiration: {self.author_style}\n",
        "        Main Character(s): {', '.join([f'{name} ({data.get(\"role\")})' for name, data in self.characters.items()])}\n",
        "        World Name/Atmosphere: {self.world_details.get('name', 'N/A')} / {self.world_details.get('atmosphere', 'N/A')}\n",
        "        Core Themes: {', '.join(self.themes_motifs.get('themes', []))}\n",
        "        Recurring Motifs: {', '.join(self.themes_motifs.get('motifs', []))}\n",
        "\n",
        "        Return ONLY the generated title itself, without any quotation marks, labels (like \"Title:\"), or explanatory text.\n",
        "        Novel Title:\n",
        "        \"\"\"\n",
        "        title_text = self._ollama_generate(prompt, system_prompt, temperature=0.8)\n",
        "        if \"[OLLAMA\" in title_text or not title_text.strip():\n",
        "            print(f\"ERROR generating title: {title_text}. Using placeholder.\")\n",
        "            main_char_name = list(self.characters.keys())[0] if self.characters else 'Adventure'\n",
        "            self.novel_title = f\"A {self.genre.replace('/', ' ')} Tale of {main_char_name}\"\n",
        "        else:\n",
        "            title_text = re.sub(r'^(title|novel title):?\\s*', '', title_text, flags=re.IGNORECASE).strip()\n",
        "            self.novel_title = title_text.strip('\"\\'')\n",
        "        print(f\"Generated Novel Title: {self.novel_title}\")\n",
        "\n",
        "\n",
        "    def compile_and_save_novel(self):\n",
        "        \"\"\"Compiles the generated content into a .docx file and saves it.\"\"\"\n",
        "        print(\"\\n--- Compiling and Saving Novel ---\")\n",
        "        if not self.generated_chapters_content:\n",
        "            print(\"ERROR: No chapter content generated. Cannot save novel.\")\n",
        "            return\n",
        "\n",
        "        self.generate_novel_title()\n",
        "\n",
        "        doc = Document()\n",
        "        try:\n",
        "            title_style = doc.styles['Title']\n",
        "            title_style.font.name = 'Garamond'\n",
        "            title_style.font.size = Pt(28)\n",
        "        except KeyError:\n",
        "            print(\"Warning: 'Title' style not found. Using default.\")\n",
        "            title_style = 'Title'\n",
        "\n",
        "        try:\n",
        "            # In python-docx, 'Heading 1' corresponds to level 1 heading.\n",
        "            # If you want to style it, you access it via doc.styles and modify.\n",
        "            # Adding a heading uses doc.add_heading('Text', level=1)\n",
        "            # We will apply style to paragraphs identified as headings later.\n",
        "            # For now, ensure a base normal style.\n",
        "            normal_style = doc.styles['Normal']\n",
        "            normal_style.font.name = 'Garamond'\n",
        "            normal_style.font.size = Pt(12)\n",
        "            normal_style.paragraph_format.line_spacing = 1.5\n",
        "            normal_style.paragraph_format.space_after = Pt(0)\n",
        "            normal_style.paragraph_format.first_line_indent = Pt(24)\n",
        "        except KeyError:\n",
        "            print(\"Warning: 'Normal' style not found. Using default.\")\n",
        "            normal_style = 'Normal'\n",
        "\n",
        "\n",
        "        doc.add_paragraph(self.novel_title, style=title_style).alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "        author_para_style = doc.styles['Normal'].font # Get a copy\n",
        "        author_para_style.name = 'Garamond'\n",
        "        author_para_style.size = Pt(12)\n",
        "        author_line = doc.add_paragraph(style='Normal')\n",
        "        author_line.add_run(f\"Inspired by the style of {self.author_style}\").font.name = 'Garamond'\n",
        "        author_line.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "        author_line.paragraph_format.first_line_indent = None\n",
        "\n",
        "\n",
        "        genre_line = doc.add_paragraph(style='Normal')\n",
        "        genre_line.add_run(f\"Genre: {self.genre}\").font.name = 'Garamond'\n",
        "        genre_line.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "        genre_line.paragraph_format.first_line_indent = None\n",
        "        doc.add_page_break()\n",
        "\n",
        "        for i in sorted(self.generated_chapters_content.keys()): # Ensure chapters are in order\n",
        "            chapter_content = self.generated_chapters_content.get(i, f\"[ERROR: Content for Chapter {i} not found]\")\n",
        "\n",
        "            paragraphs = chapter_content.split('\\n\\n')\n",
        "\n",
        "            if paragraphs:\n",
        "                ch_title_line_full = paragraphs[0].strip()\n",
        "\n",
        "                # Default heading text is the full first line\n",
        "                heading_text_for_doc = ch_title_line_full\n",
        "\n",
        "                # Try to extract a cleaner title for the heading\n",
        "                # Expected format: \"Chapter X - Title Text\"\n",
        "                title_match_for_heading = re.match(r\"Chapter\\s*\\d+\\s*[:*-]?\\s*(.*)\", ch_title_line_full, re.IGNORECASE)\n",
        "                if title_match_for_heading and title_match_for_heading.group(1).strip():\n",
        "                    heading_text_for_doc = title_match_for_heading.group(1).strip() # Use just the title part\n",
        "\n",
        "                # If what we extracted as \"title\" is very short or empty, revert to full line for safety\n",
        "                if not heading_text_for_doc or len(heading_text_for_doc) < 3:\n",
        "                    heading_text_for_doc = ch_title_line_full\n",
        "\n",
        "\n",
        "                ch_heading_para = doc.add_heading(heading_text_for_doc, level=1)\n",
        "                ch_heading_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "                # Accessing style for heading directly to modify if needed (python-docx limitation)\n",
        "                # For more control, create custom style based on 'Heading 1'\n",
        "                # For now, assume default 'Heading 1' style is acceptable or modify 'Heading 1' in styles\n",
        "                # ch_heading_para.style.font.name = 'Garamond' # This would require ensuring style object is not string\n",
        "                # ch_heading_para.style.font.size = Pt(18)\n",
        "\n",
        "                # Add the \"Chapter X\" part if it was separated, or if the title line didn't include it for some reason\n",
        "                if not ch_title_line_full.lower().startswith(\"chapter\"):\n",
        "                    sub_heading_para = doc.add_paragraph(f\"Chapter {i}\")\n",
        "                    sub_heading_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "                    sub_heading_para.paragraph_format.space_before = Pt(0)\n",
        "                    sub_heading_para.paragraph_format.space_after = Pt(6)\n",
        "                    if hasattr(sub_heading_para.style.font, 'name'):\n",
        "                         sub_heading_para.style.font.name = 'Garamond'\n",
        "                         sub_heading_para.style.font.size = Pt(14)\n",
        "\n",
        "\n",
        "                for para_block in paragraphs[1:]: # Start from second block for content\n",
        "                    if para_block.strip():\n",
        "                        p = doc.add_paragraph(para_block.strip(), style=normal_style)\n",
        "            else:\n",
        "                doc.add_paragraph(chapter_content, style=normal_style)\n",
        "\n",
        "            if i < self.num_chapters:\n",
        "                doc.add_page_break()\n",
        "\n",
        "        safe_title = re.sub(r'[^\\w\\s-]', '', self.novel_title).strip().replace(' ', '_')\n",
        "        safe_genre = self.genre.replace('/','-').replace(' ','')\n",
        "        filename = f\"{safe_title[:50]}_Novel_{safe_genre}.docx\"\n",
        "        filepath = os.path.join(OUTPUT_DIR, filename)\n",
        "\n",
        "        try:\n",
        "            doc.save(filepath)\n",
        "            print(f\"Novel successfully saved to: {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR saving .docx file: {e}\")\n",
        "\n",
        "        # Safely serialize metadata\n",
        "        def serialize_for_json(obj):\n",
        "            \"\"\"Helper to make complex objects JSON serializable\"\"\"\n",
        "            if isinstance(obj, dict):\n",
        "                return {k: serialize_for_json(v) for k, v in obj.items()}\n",
        "            elif isinstance(obj, list):\n",
        "                return [serialize_for_json(i) for i in obj]\n",
        "            elif isinstance(obj, (int, float, str, bool, type(None))):\n",
        "                return obj\n",
        "            else:\n",
        "                return str(obj)  # Convert any other types to strings\n",
        "\n",
        "        # Prepare metadata with serialization for safety\n",
        "        metadata = {\n",
        "            \"title\": self.novel_title,\n",
        "            \"subject\": self.subject,\n",
        "            \"author_style\": self.author_style,\n",
        "            \"genre\": self.genre,\n",
        "            \"num_chapters_determined\": self.num_chapters,\n",
        "            \"ollama_model_used\": OLLAMA_MODEL,\n",
        "            \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"characters_final\": serialize_for_json(self.characters),\n",
        "            \"world_details\": serialize_for_json(self.world_details),\n",
        "            \"themes_motifs\": serialize_for_json(self.themes_motifs),\n",
        "            \"plot_outline\": self.plot_outline,\n",
        "            \"chapter_plans\": serialize_for_json(self.chapter_plans),\n",
        "            \"chapter_continuity_data\": serialize_for_json(self.chapter_continuity_data),\n",
        "        }\n",
        "\n",
        "        meta_filename = f\"{safe_title[:50]}_Novel_METADATA.json\"\n",
        "        meta_filepath = os.path.join(OUTPUT_DIR, meta_filename)\n",
        "        try:\n",
        "            with open(meta_filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"Metadata saved to: {meta_filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR saving metadata JSON: {e}\")\n",
        "\n",
        "\n",
        "    def orchestrate_generation(self):\n",
        "        \"\"\"\n",
        "        Main public method to run the entire novel generation pipeline.\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        print(\"--- Starting Novel Generation Pipeline ---\")\n",
        "\n",
        "        if not self.generate_foundational_elements():\n",
        "            # Error message already printed in generate_foundational_elements\n",
        "            return\n",
        "\n",
        "        if not self.generate_detailed_chapter_plans():\n",
        "            # Error message already printed in generate_detailed_chapter_plans\n",
        "            return\n",
        "\n",
        "        if not self.generate_novel_content():\n",
        "            print(\"Halting: Novel content generation failed.\")\n",
        "            return\n",
        "\n",
        "        self._perform_final_transition_checks()\n",
        "\n",
        "        self.compile_and_save_novel()\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_time_minutes = (end_time - start_time) / 60\n",
        "        print(f\"--- Novel Generation Pipeline Finished ---\")\n",
        "        print(f\"Total time taken: {total_time_minutes:.2f} minutes.\")\n",
        "\n",
        "\n",
        "def get_user_input_multiline(prompt_message):\n",
        "    print(prompt_message + \" (Type 'ENDINPUT' on a new line when done, or just press Enter if input is short):\")\n",
        "    lines = []\n",
        "    first_line = input()\n",
        "    if not first_line.strip() and not lines: # Handle immediate Enter press for short input\n",
        "        return first_line\n",
        "\n",
        "    if first_line.strip().upper() == 'ENDINPUT':\n",
        "        return \"\" # Empty if ENDINPUT is the first thing\n",
        "\n",
        "    lines.append(first_line)\n",
        "\n",
        "    # If first line is short and no explicit ENDINPUT, assume it's a single line input\n",
        "    if len(first_line) < 70 and \"ENDINPUT\" not in first_line.strip().upper() :\n",
        "        is_multiline_intent = False # Heuristic: assume single line if short\n",
        "        # Check if user might still want multiline\n",
        "        if any(kw in first_line for kw in [\"\\n\", \"\\\\n\"]): # A bit of a guess\n",
        "            is_multiline_intent = True\n",
        "        if not is_multiline_intent: # If it looks like a single line, return it.\n",
        "             # Check if there's an accidental ENDINPUT at the end of a short first line.\n",
        "            if first_line.strip().upper().endswith(\"ENDINPUT\"):\n",
        "                return first_line.strip()[:-(len(\"ENDINPUT\"))].strip()\n",
        "            return first_line # Return as is\n",
        "\n",
        "    # Proceed to read more lines if it seems like multiline input was intended\n",
        "    while True:\n",
        "        try:\n",
        "            line = input()\n",
        "            if line.strip().upper() == 'ENDINPUT':\n",
        "                break\n",
        "            lines.append(line)\n",
        "        except EOFError: # Handle Ctrl+D or unexpected end of input stream\n",
        "            print(\"INFO: EOF reached while reading multiline input.\")\n",
        "            break\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def load_resume_text(file_path):\n",
        "    \"\"\"Loads text from a file, attempting PDF extraction if it's a .pdf file.\"\"\"\n",
        "    if not file_path:\n",
        "        return \"\"\n",
        "\n",
        "    resume_text = \"\"\n",
        "    try:\n",
        "        if file_path.lower().endswith(\".pdf\"):\n",
        "            try:\n",
        "                with open(file_path, 'rb') as f:\n",
        "                    reader = pypdf.PdfReader(f)\n",
        "                    # Handle encryption in a version-agnostic way\n",
        "                    try:\n",
        "                        if hasattr(reader, \"is_encrypted\") and reader.is_encrypted:\n",
        "                            # Try decrypting with empty password\n",
        "                            reader.decrypt('')\n",
        "                    except:\n",
        "                        print(f\"Warning: PDF file '{file_path}' appears encrypted. Cannot extract text.\")\n",
        "                        return \"\"\n",
        "\n",
        "                    for page in reader.pages:\n",
        "                        page_text = page.extract_text()\n",
        "                        if page_text:\n",
        "                            resume_text += page_text + \"\\n\"\n",
        "                if resume_text.strip():\n",
        "                    print(f\"Successfully extracted text from PDF: {file_path}\")\n",
        "                else:\n",
        "                    print(f\"Warning: No text could be extracted from PDF: {file_path}. It might be an image-based PDF, scanned, or corrupted.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error processing PDF file '{file_path}': {e}. Proceeding without resume content from this file.\")\n",
        "                resume_text = \"\"\n",
        "        else:\n",
        "            encodings_to_try = ['utf-8', 'latin-1', 'cp1252']\n",
        "            loaded_successfully = False\n",
        "            for enc in encodings_to_try:\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding=enc) as f:\n",
        "                        resume_text = f.read()\n",
        "                    print(f\"Resume loaded from text file: {file_path} (using {enc})\")\n",
        "                    loaded_successfully = True\n",
        "                    break\n",
        "                except UnicodeDecodeError:\n",
        "                    continue\n",
        "                except Exception as e_text:\n",
        "                    print(f\"Warning: Error loading text file '{file_path}' with {enc}: {e_text}.\")\n",
        "                    break\n",
        "            if not loaded_successfully and not resume_text:\n",
        "                print(f\"Warning: Could not load resume from text file '{file_path}' after trying multiple encodings. Proceeding without it.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: Resume file not found at '{file_path}'. Proceeding without resume.\")\n",
        "    except Exception as e_general:\n",
        "        print(f\"Warning: An unexpected error occurred while trying to load '{file_path}': {e_general}. Proceeding without resume.\")\n",
        "\n",
        "    return resume_text.strip()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Welcome to the AI Novel Generator!\")\n",
        "    print(\"Please ensure your Ollama server is running and the model is available.\")\n",
        "    # OLLAMA_MODEL can be overridden by user input if desired, or set here.\n",
        "    user_ollama_model = input(f\"Enter Ollama model name (default: {OLLAMA_MODEL}): \").strip()\n",
        "    if user_ollama_model:\n",
        "        OLLAMA_MODEL = user_ollama_model\n",
        "    print(f\"Using Ollama Model: {OLLAMA_MODEL} at {OLLAMA_BASE_URL}\")\n",
        "    print(\"----------------------------------------------------\")\n",
        "\n",
        "    resume_file_path_input = input(\"Enter path to resume file (text or PDF) (or press Enter to skip): \").strip()\n",
        "    resume_text_content = load_resume_text(resume_file_path_input)\n",
        "\n",
        "    novel_subject_input = get_user_input_multiline(\"Enter the novel's subject/premise\")\n",
        "    author_style_input_str = input(\"Enter the desired author style (e.g., 'Stephen King', 'Jane Austen'): \").strip()\n",
        "    genre_input_str = input(\"Enter the genre(s) (e.g., 'Sci-Fi/Thriller', 'Historical Romance'): \").strip()\n",
        "\n",
        "    # Basic input validation\n",
        "    if not novel_subject_input:\n",
        "        print(\"Novel subject/premise cannot be empty. Exiting.\")\n",
        "        exit()\n",
        "    if not author_style_input_str:\n",
        "        print(\"Author style cannot be empty. Using 'Generic'.\")\n",
        "        author_style_input_str = \"Generic\"\n",
        "    if not genre_input_str:\n",
        "        print(\"Genre cannot be empty. Using 'Fiction'.\")\n",
        "        genre_input_str = \"Fiction\"\n",
        "\n",
        "\n",
        "    generator = NovelGenerator(\n",
        "        resume_content=resume_text_content,\n",
        "        subject=novel_subject_input,\n",
        "        author_style=author_style_input_str,\n",
        "        genre=genre_input_str\n",
        "    )\n",
        "    generator.orchestrate_generation()\n",
        "    print(\"----------------------------------------------------\")\n",
        "    print(\"Novel generation process completed. Check the output directory for your novel and metadata files.\")\n",
        "    print(\"Thank you for using the AI Novel Generator!\")\n",
        "    print(\"----------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHeOmn5E-Qgc",
        "outputId": "8925eb57-73de-40fe-be58-df205eb0fd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the AI Novel Generator!\n",
            "Please ensure your Ollama server is running and the model is available.\n",
            "Enter Ollama model name (default: gemma3:12b): gemma3:12b\n",
            "Using Ollama Model: gemma3:12b at http://localhost:11434/api/generate\n",
            "----------------------------------------------------\n",
            "Enter path to resume file (text or PDF) (or press Enter to skip): /content/Jessica_Holdens_resume.pdf\n",
            "Successfully extracted text from PDF: /content/Jessica_Holdens_resume.pdf\n",
            "Enter the novel's subject/premise (Type 'ENDINPUT' on a new line when done, or just press Enter if input is short):\n",
            "The salt-laced air of Los Angeles had always felt like a distant cousin to Jessica's soul, a mere whisper of the vast, blue heart she felt beating within her. Eighteen years had etched a quiet yearning onto her spirit, a pull towards the ocean that went deeper than simple admiration. It was a recognition, a silent conversation held across the sandy divide.    Then came the dreams. At first, they were fleeting glimpses – the shimmer of unseen depths, the murmur of voices she couldn't quite grasp, a profound sense of belonging to a place she'd never seen. But since her eighteenth birthday, the whispers had grown insistent, the glimmers brighter, each nocturnal voyage tugging her further into a reality that felt both alien and intimately familiar. A world veiled in a sapphire haze, humming with an ancient magic, was calling her home.    One ordinary Sunday morning, the call shattered the fragile membrane of her waking life. An overwhelming vision flooded her senses – a swirling vortex of turquoise, the mournful cry of unseen creatures – followed by a blinding flash, and then… nothing.    She awoke to a world reborn. Gone was the familiar clutter of her bedroom, replaced by an endless expanse of ocean, its surface alive with a shimmering, sentient energy. The Blueward Deep. A name that echoed in the deepest chambers of her heart, a forgotten world whispered about only in the faintest of myths, had claimed her entirely.    The revelation that she was more than a visitor struck her with the force of a tidal wave. Heir. The word resonated with the ocean's hum, a legacy woven into the very currents. Tideborn. Endowed with a rare and potent gift called Soulcurrent, she could feel the ocean's pulse, a symphony of ebb and flow she instinctively understood. The waters responded to her, currents bending at her unspoken will, and within their depths, she could almost hear the echoes of ancient memories.    But this homecoming was shadowed by peril. Selmyra was not at peace. A malevolent force, the Drowned Court, clawed at the ocean's magic, their hunger for power twisting the once-harmonious currents into weapons of destruction. Monstrous sea beasts, their eyes gleaming with unnatural malice, patrolled the depths. Dark rifts scarred the ocean's surface, spewing forth chaotic energies. And a chilling dread hung in the water – the slow, insidious awakening of The Abyss, a slumbering, god-like entity whose stirring threatened to swallow Selmyra whole.    Amidst this breathtaking yet terrifying reality, Jessica’s innate empathy for the ocean became her unexpected strength. The silent suffering of the corrupted waters resonated within her, fueling a fierce protectiveness. And then there was Kaelen.    He moved with the fluid grace of the tides, his eyes the deep, calming blue of a twilight sea. A Tideborn himself, his connection to Selmyra was profound, yet it was the unexpected resonance with Jessica’s Soulcurrent that sparked a different kind of current between them perhaps romance. In his steady gaze, she found not just an ally, but a silent understanding that mirrored her own deep connection to the ocean. His presence was a comforting anchor in this bewildering world, a warmth that spread through her like sunlight on the water’s surface.    Guided by fragmented visions – a girl lost to the churning waves, cryptic flashbacks that felt both alien and achingly familiar – Jessica knew her arrival was no mere chance. The mysterious rescue on a beach years ago, a memory that flickered at the edges of her awareness, seemed to hold a key. And the truth of the Tideborn lineage, the ancient magic that pulsed within her veins, was a mystery she desperately needed to unravel.    Could she, a dreamer pulled from a world she barely knew she'd left, become the anchor of Selmyra against the rising tide of madness? And could the tentative warmth and feelings she felt for Kaelen blossom amidst the looming war, a fragile bloom in a world teetering on the brink?    Her journey would plunge her into the heart of Selmyra’s deepest secrets – where trust was as treacherous as a hidden reef, alliances shifted with the currents of hidden agendas, and the ocean itself seemed to hold its breath, waiting. As a Tideborn wielding the rare Soulcurrent, Jessica would have to awaken the full extent of her power, to face the shadows that lurked beneath the waves, and to choose: would she rise with the tide, or be swallowed by the depths? The fate of Selmyra, and perhaps her own heart, hung in the balance.\n",
            "ENDINPUT\n",
            "Enter the desired author style (e.g., 'Stephen King', 'Jane Austen'): Victoria Aveyard \\n Genre: ROMANCE,FANTASY,DYSTOPIAN,YOUNG ADULT,HOT,SEXY\n",
            "Enter the genre(s) (e.g., 'Sci-Fi/Thriller', 'Historical Romance'): ROMANCE,FANTASY,DYSTOPIAN,YOUNG ADULT,HOT,SEXY\n",
            "NovelGenerator initialized.\n",
            "  Subject: The salt-laced air of Los Angeles had always felt like a distant cousin to Jessica's soul, a mere wh...\n",
            "  Author Style: Victoria Aveyard \\n\n",
            "  Genre: ROMANCE,FANTASY,DYSTOPIAN,YOUNG ADULT,HOT,SEXY\n",
            "  Resume provided: Yes\n",
            "  Number of chapters will be determined automatically.\n",
            "--- Starting Novel Generation Pipeline ---\n",
            "\n",
            "--- Generating Foundational Elements ---\n",
            "Step 1.1: Generating Character Profiles...\n",
            "Generated 3 character profiles: Jessica Maris, Kaelen Rhys, Morwen Blackwood\n",
            "\n",
            "Step 1.2: Generating World Details...\n",
            "Generated World Details for 'Selmyra'.\n",
            "\n",
            "Step 1.3: Generating Themes and Motifs...\n",
            "Generated Themes: [\"Legacy and Destiny: The story examines the weight of inherited responsibility and the struggle to reconcile personal desires with predetermined roles, as seen in Jessica's Tideborn heritage and Kaelen’s past.\", 'Corruption vs. Purity: The narrative explores the battle between preserving the natural beauty and integrity of Selmyra and the insidious spread of the Drowned Court’s influence, mirroring a broader struggle between good and evil.', \"Identity and Belonging: Jessica's journey centers on finding her place in a world that is both alien and strangely familiar, highlighting the universal human need for connection and acceptance.\", 'RECURRING MOTIFS:', 'Shimmering Water/Sapphire Haze: Represents the veil between worlds, illusion, and hidden truths.', 'The Phrase \"Shadows Remember\": Symbolizes the persistence of the past and the way it shapes the present, hinting at buried secrets and forgotten histories.', \"Coral (both healthy and decaying): Represents life, beauty, and the fragility of Selmyra's ecosystem, juxtaposed with the destructive power of the Drowned Court.\", \"The Color Blue (various shades): A pervasive symbol of Selmyra's ocean, representing both tranquility and immense power, as well as the emotional depths of the characters.\", \"Fragmented Memories/Visions: Reflect Jessica's incomplete understanding of her past and the larger mysteries surrounding Selmyra’s fate.\"]\n",
            "Generated Motifs: ['Shimmering Water/Sapphire Haze: Represents the veil between worlds, illusion, and hidden truths.', 'The Phrase \"Shadows Remember\": Symbolizes the persistence of the past and the way it shapes the present, hinting at buried secrets and forgotten histories.', \"Coral (both healthy and decaying): Represents life, beauty, and the fragility of Selmyra's ecosystem, juxtaposed with the destructive power of the Drowned Court.\", \"The Color Blue (various shades): A pervasive symbol of Selmyra's ocean, representing both tranquility and immense power, as well as the emotional depths of the characters.\", \"Fragmented Memories/Visions: Reflect Jessica's incomplete understanding of her past and the larger mysteries surrounding Selmyra’s fate.\"]\n",
            "\n",
            "Step 1.4: Generating High-Level Plot Outline and Determining Chapter Count...\n",
            "Generated High-Level Plot Outline:\n",
            "**Act I (Setup):** Jessica’s seemingly ordinary life is shattered when she’s pulled from her world and thrust into the breathtaking, yet perilous, realm of Selmyra. The sudden arrival and burgeoning Soulcurrent abilities mark her as a Tideborn heir, immediately placing her in the crosshairs of the Drowned Court and revealing a fragmented past linked to Selmyra’s ancient prophecies. Guided by the stoic Kaelen, she begins to understand her destiny and the urgent need to protect Selmyra from a growing darkness, while grappling with the unsettling visions plaguing her.\n",
            "\n",
            "**Act II (Confrontation):** Jessica and Kaelen embark on a perilous journey across Selmyra, seeking answers to her past and uncovering the Drowned Court’s insidious plot to awaken The Abyss. Facing trials that test her burgeoning abilities and challenging her self-doubt, she forges alliances with unexpected figures and confronts Morwen Blackwood, the cunning leader of the Drowned Court, revealing a complex web of betrayals and hidden agendas. A significant turning point occurs when a recovered memory unlocks a vital clue to defeating The Abyss, but also exposes a painful truth about Kaelen’s past and a potential link to the Drowned Court.\n",
            "\n",
            "**Act III (Resolution):** Jessica, now embracing her Tideborn heritage and mastering her Soulcurrent abilities, leads a final confrontation against Morwen and the Drowned Court, culminating in a desperate attempt to seal The Abyss. Through sacrifice and strategic alliance, Jessica confronts her own inner demons and utilizes the recovered memory to exploit a weakness in Morwen’s plan, ultimately restoring balance to Selmyra and forging a new path for the Tideborn. The narrative concludes with Jessica accepting her role as a guardian of Selmyra, forever bound to its fate and embracing a future filled with both hope and responsibility.\n",
            "LLM suggested 35 chapters for the novel.\n",
            "Foundational elements generated successfully.\n",
            "\n",
            "--- Generating Detailed Chapter-by-Chapter Plans ---\n",
            "Generating detailed plan text for chapters 1-12 (batch 1/3)...\n",
            "  Parsed plan for Chapter 1: Whispers of the Deep:\n",
            "  Parsed plan for Chapter 2: Currents of Understanding:\n",
            "  Parsed plan for Chapter 3: Echoes of the Past:\n",
            "  Parsed plan for Chapter 4: Whispers in the Current:\n",
            "  Parsed plan for Chapter 5: The Shifting Sands:\n",
            "  Parsed plan for Chapter 6: Echoes in the Ruins:\n",
            "  Parsed plan for Chapter 7: Shadows in the Deep:\n",
            "  Parsed plan for Chapter 8: The Tide Turns:\n",
            "  Parsed plan for Chapter 9: Confrontation:\n",
            "  Parsed plan for Chapter 10: Epilogue:\n",
            "Generating detailed plan text for chapters 13-24 (batch 2/3)...\n",
            "  Parsed plan for Chapter 13: Echoes in the Kelp\n",
            "  Parsed plan for Chapter 14: Whispers of the Deep\n",
            "  Parsed plan for Chapter 15: The Sunken Shrine\n",
            "  Parsed plan for Chapter 16: Echoes of Aerion\n",
            "  Parsed plan for Chapter 17: Shadows of Doubt\n",
            "  Parsed plan for Chapter 18: Whispers in the Dark\n",
            "  Parsed plan for Chapter 19: Escape from the Citadel\n",
            "  Parsed plan for Chapter 20: The Path Ahead\n",
            "Generating detailed plan text for chapters 25-35 (batch 3/3)...\n",
            "  Parsed plan for Chapter 25: Echoes in the Kelp\n",
            "  Parsed plan for Chapter 26: The Pearl Weaver's Riddle\n",
            "  Parsed plan for Chapter 27: The Sunken City of Xylos\n",
            "  Parsed plan for Chapter 28: The Binding Ritual\n",
            "  Parsed plan for Chapter 29: The Shifting Depths\n",
            "  Parsed plan for Chapter 30: The Obsidian Heart\n",
            "Successfully parsed detailed plans for 24 chapters out of 35 expected.\n",
            "Generating fallback plans for 11 missing chapters: [11, 12, 21, 22, 23, 24, 31, 32, 33, 34, 35]\n",
            "  Generated fallback plan for Chapter 11: Echoes of the Tide-Singer\n",
            "  Generated fallback plan for Chapter 12: Echoes in the Coral Bloom\n",
            "  Generated fallback plan for Chapter 21: Echoes in the Coral Bloom\n",
            "  Generated fallback plan for Chapter 22: Echoes of the Tide\n",
            "  Generated fallback plan for Chapter 23: Echoes of the Deepwood\n",
            "  Generated fallback plan for Chapter 24: ** Echoes of the Deep\n",
            "  Generated fallback plan for Chapter 31: **Echoes of the Deep Bloom**\n",
            "  Generated fallback plan for Chapter 32: Echoes of the Deep\n",
            "  Generated fallback plan for Chapter 33: Echoes of the Deep\n",
            "  Generated fallback plan for Chapter 34: Echoes of the Deep\n",
            "  Generated fallback plan for Chapter 35: ** *Echoes of the Blue Heart*\n",
            "\n",
            "--- Generating Full Novel Content (Chapter by Chapter) ---\n",
            "\n",
            "--- Generating Chapter 1 of 35 ---\n",
            "  Generating Scene 1 of 4 for Chapter 1: - Scene 1: Jessica sketches the ocean from her bedroom window, feeling a deep, i...\n",
            "  Generating Scene 2 of 4 for Chapter 1: Scene 2: The vision intensifies, accompanied by a blinding flash, knocking Jessi...\n",
            "  Generating Scene 3 of 4 for Chapter 1: Scene 3: Jessica awakens disoriented, surrounded by endless ocean, the water shi...\n",
            "  Generating Scene 4 of 4 for Chapter 1: Scene 4: A voice echoes in Jessica’s mind, uttering the word “Tideborn.” Locatio...\n",
            "Updating continuity data for Chapter 1 (interim pass)...\n",
            "  Generating transition hook for Chapter 1...\n",
            "  Chapter 1 ('Whispers of the Deep:') content generated (approx length: 10983 chars).\n",
            "Updating continuity data for Chapter 1 (final pass)...\n",
            "Pausing briefly before next chapter...\n",
            "\n",
            "--- Generating Chapter 2 of 35 ---\n",
            "  Analyzing flow from Chapter 1 to Chapter 2...\n",
            "    Flow Analysis Result: The transition from Chapter 1 to Chapter 2 is remarkably strong and effectively leverages the established hook. The opening paragraph directly resolves the suspense built by the approaching presence –...\n",
            "  Generating Scene 1 of 4 for Chapter 2: - Scene 1: Jessica is rescued from the ocean by Kaelen, a stern but compassionat...\n",
            "  Generating Scene 2 of 4 for Chapter 2: Scene 2: Kaelen explains the basics of Selmyra - its history, the Tideborn, and ...\n",
            "  Generating Scene 3 of 4 for Chapter 2: Scene 3: Jessica struggles to accept her situation, questioning her memories and...\n",
            "  Generating Scene 4 of 4 for Chapter 2: Scene 4: Kaelen shows Jessica a Remembrance Pearl, triggering fragmented memorie...\n",
            "Updating continuity data for Chapter 2 (interim pass)...\n",
            "  Generating transition hook for Chapter 2...\n",
            "  Chapter 2 ('Currents of Understanding:') content generated (approx length: 14722 chars).\n",
            "Updating continuity data for Chapter 2 (final pass)...\n",
            "Pausing briefly before next chapter...\n",
            "\n",
            "--- Generating Chapter 3 of 35 ---\n",
            "  Analyzing flow from Chapter 2 to Chapter 3...\n",
            "    Flow Analysis Result: The transition from Chapter 2 to Chapter 3 is remarkably strong and effectively resolves the cliffhanger established at the end of \"Currents of Understanding.\" The opening paragraph of Chapter 3 direc...\n",
            "  Generating Scene 1 of 4 for Chapter 3: - Scene 1: Jessica, with Kaelen’s reluctant guidance, focuses on the Remembrance...\n",
            "  Generating Scene 2 of 4 for Chapter 3: Scene 2: The memory shows a young girl (presumably Jessica) interacting with a r...\n",
            "  Generating Scene 3 of 4 for Chapter 3: Scene 3: Kaelen interrupts the memory session, sensing a disturbance in the curr...\n",
            "  Generating Scene 4 of 4 for Chapter 3: Scene 4: A brief, shadowy figure is seen lurking near the cove, disappearing qui...\n",
            "Updating continuity data for Chapter 3 (interim pass)...\n",
            "  Generating transition hook for Chapter 3...\n",
            "  Chapter 3 ('Echoes of the Past:') content generated (approx length: 15015 chars).\n",
            "Updating continuity data for Chapter 3 (final pass)...\n",
            "Pausing briefly before next chapter...\n",
            "\n",
            "--- Generating Chapter 4 of 35 ---\n",
            "  Analyzing flow from Chapter 3 to Chapter 4...\n",
            "    Flow Analysis Result: Here's an analysis of the transition and flow from Chapter 3 to Chapter 4, addressing your requested points:\n",
            "\n",
            "The transition from Chapter 3 to Chapter 4 is quite strong, effectively building on the es...\n",
            "  Generating Scene 1 of 4 for Chapter 4: - Scene 1: Jessica, feigning sleep, secretly observes Kaelen while he tends to t...\n",
            "  Generating Scene 2 of 4 for Chapter 4: Scene 2: Jessica discovers a hidden compartment containing old scrolls detailing...\n",
            "  Generating Scene 3 of 4 for Chapter 4: Scene 3: Kaelen confronts Jessica about her actions, expressing his concern for ...\n",
            "  Generating Scene 4 of 4 for Chapter 4: Scene 4: Jessica overhears a conversation between Kaelen and another Tideborn me...\n",
            "Updating continuity data for Chapter 4 (interim pass)...\n",
            "  Generating transition hook for Chapter 4...\n",
            "  Chapter 4 ('Whispers in the Current:') content generated (approx length: 15464 chars).\n",
            "Updating continuity data for Chapter 4 (final pass)...\n",
            "Pausing briefly before next chapter...\n",
            "\n",
            "--- Generating Chapter 5 of 35 ---\n",
            "  Analyzing flow from Chapter 4 to Chapter 5...\n",
            "    Flow Analysis Result: The transition from Chapter 4 to Chapter 5 is remarkably strong and demonstrates a keen awareness of narrative flow. The opening paragraph of Chapter 5 directly and effectively resolves the ending hoo...\n",
            "  Generating Scene 1 of 4 for Chapter 5: - Scene 1: Jessica confronts Kaelen about the lost artifact, insisting they sear...\n",
            "  Generating Scene 2 of 4 for Chapter 5: Scene 2: Kaelen guides Jessica through a treacherous, shifting sand region known...\n",
            "  Generating Scene 3 of 4 for Chapter 5: Scene 3: They encounter a hostile marine creature, forcing them to work together...\n",
            "  Generating Scene 4 of 4 for Chapter 5: Scene 4: They discover a partially submerged ruin, hinting at the artifact's pos...\n",
            "Updating continuity data for Chapter 5 (interim pass)...\n",
            "  Generating transition hook for Chapter 5...\n",
            "  Chapter 5 ('The Shifting Sands:') content generated (approx length: 15478 chars).\n",
            "Updating continuity data for Chapter 5 (final pass)...\n",
            "Pausing briefly before next chapter...\n",
            "\n",
            "--- Generating Chapter 6 of 35 ---\n",
            "  Analyzing flow from Chapter 5 to Chapter 6...\n",
            "    Flow Analysis Result: The transition from Chapter 5 to Chapter 6 is largely successful, though with a few areas for minor refinement. The opening of Chapter 6 directly addresses the hook established at the end of Chapter 5...\n",
            "  Generating Scene 1 of 4 for Chapter 6: - Scene 1: Jessica and Kaelen cautiously explore the submerged ruins, decipherin...\n",
            "  Generating Scene 2 of 4 for Chapter 6: Scene 2: They trigger a hidden trap, separating them and forcing Jessica to navi...\n",
            "  Generating Scene 3 of 4 for Chapter 6: Scene 3: Jessica discovers a mural depicting the Drowned Court using the artifac...\n",
            "  Generating Scene 4 of 4 for Chapter 6: Scene 4: Jessica and Kaelen are reunited, but they realize they are being watche...\n",
            "Updating continuity data for Chapter 6 (interim pass)...\n",
            "  Generating transition hook for Chapter 6...\n",
            "  Chapter 6 ('Echoes in the Ruins:') content generated (approx length: 14789 chars).\n",
            "Updating continuity data for Chapter 6 (final pass)...\n",
            "Pausing briefly before next chapter...\n",
            "\n",
            "--- Generating Chapter 7 of 35 ---\n",
            "  Analyzing flow from Chapter 6 to Chapter 7...\n",
            "    Flow Analysis Result: ## Flow Analysis: Chapter 6 to Chapter 7\n",
            "\n",
            "The transition from Chapter 6 to Chapter 7 is generally well-executed, successfully building on the established tension. The opening paragraph of Chapter 7 di...\n",
            "  Generating Scene 1 of 4 for Chapter 7: - Scene 1: Jessica and Kaelen are ambushed by a shadowy figure, revealing themse...\n",
            "  Generating Scene 2 of 4 for Chapter 7: Scene 2: The corrupted Tideborn reveals that they are guarding the artifact and ...\n",
            "  Generating Scene 3 of 4 for Chapter 7: Scene 3: A brief struggle ensues, allowing Jessica and Kaelen to escape, but the...\n",
            "  Generating Scene 4 of 4 for Chapter 7: Scene 4: Jessica and Kaelen reflect on their encounter, realizing that the Drown...\n",
            "Updating continuity data for Chapter 7 (interim pass)...\n",
            "  Generating transition hook for Chapter 7...\n",
            "  Chapter 7 ('Shadows in the Deep:') content generated (approx length: 14784 chars).\n",
            "Updating continuity data for Chapter 7 (final pass)...\n",
            "Pausing briefly before next chapter...\n",
            "\n",
            "--- Generating Chapter 8 of 35 ---\n",
            "  Analyzing flow from Chapter 7 to Chapter 8...\n",
            "    Flow Analysis Result: The transition from Chapter 7 to Chapter 8 is largely successful in maintaining reader engagement and establishing a clear direction for the next stage of the narrative. The opening paragraph of Chapt...\n",
            "  Generating Scene 1 of 4 for Chapter 8: - Scene 1: Jessica and Kaelen travel to a secluded sanctuary, seeking guidance f...\n",
            "  Generating Scene 2 of 4 for Chapter 8: Scene 2: The elder Tideborn explains the artifact’s true purpose: to maintain th...\n",
            "  Generating Scene 3 of 4 for Chapter 8: Scene 3: The elder Tideborn reveals a hidden prophecy, suggesting that Jessica m...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEW"
      ],
      "metadata": {
        "id": "l6c7GFS6WFYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "import pypdf # Added for PDF processing\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# --- OpenRouter Configuration ---\n",
        "# !!! IMPORTANT: Load API Key securely, e.g., from environment variables !!!\n",
        "# OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")\n",
        "# For demonstration, using the provided key directly:\n",
        "# Use your actual key or load from env\n",
        "# ---\n",
        "\n",
        "if not OPENROUTER_API_KEY:\n",
        "    raise ValueError(\"OPENROUTER_API_KEY is not set.\")\n",
        "\n",
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "# Model specified by user, free tier Llama 3 8B Instruct\n",
        "# Consider more powerful models for potentially better quality (e.g., \"openai/gpt-4o\", \"anthropic/claude-3-opus\")\n",
        "OPENROUTER_MODEL = \"meta-llama/llama-3-8b-instruct:free\" # Switched to Llama 3 free tier as per user context\n",
        "\n",
        "# Optional: Set Your App's URL and Name for OpenRouter identification\n",
        "SITE_URL = \"http://localhost\" # Replace with your app's URL if applicable\n",
        "APP_TITLE = \"Flow-Focused Novel Generator\" # Updated app name\n",
        "\n",
        "# Timeout for API calls (seconds) - increased for potentially long generations\n",
        "API_TIMEOUT = 360 # 6 minutes\n",
        "\n",
        "# Output directory for the generated novel\n",
        "OUTPUT_DIR = \"generated_novel_output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "class NovelGenerator:\n",
        "    def __init__(self, resume_content, subject, author_style, genre):\n",
        "        # Clean up author_style input\n",
        "        self.author_style = author_style.split(\"\\n\")[0].strip()\n",
        "        self.author_style = re.sub(r\"Genre:.*$\", \"\", self.author_style, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        self.resume_content = resume_content\n",
        "        self.subject = subject\n",
        "        self.genre = genre\n",
        "        self.num_chapters = 0 # Will be determined by the AI\n",
        "\n",
        "        # --- OpenRouter API Key ---\n",
        "        self.api_key = OPENROUTER_API_KEY # Store the key\n",
        "\n",
        "        # Core story elements\n",
        "        self.characters = {}\n",
        "        self.world_details = {\"name\": \"\", \"key_locations\": [], \"cultural_elements\": [], \"rules\": [], \"atmosphere\": \"\"}\n",
        "        self.themes_motifs = {\"themes\": [], \"motifs\": []}\n",
        "        self.plot_outline = \"\"\n",
        "        self.novel_title = \"Untitled Novel\"\n",
        "\n",
        "        # Detailed chapter-by-chapter plan\n",
        "        self.chapter_plans = {} # Key: chapter_num, Value: dict with plan details\n",
        "\n",
        "        # Generated content and continuity data\n",
        "        self.generated_chapters_content = {} # Key: chapter_num, Value: full chapter text\n",
        "        self.chapter_continuity_data = {} # Key: chapter_num, Value: dict with summary, char updates, timeline, emotional arc, flow_analysis\n",
        "\n",
        "        print(\"NovelGenerator initialized.\")\n",
        "        print(f\"  Subject: {self.subject[:100]}...\")\n",
        "        print(f\"  Author Style: {self.author_style}\")\n",
        "        print(f\"  Genre: {self.genre}\")\n",
        "        print(f\"  Resume provided: {'Yes' if self.resume_content else 'No'}\")\n",
        "        print(f\"  Using OpenRouter Model: {OPENROUTER_MODEL}\")\n",
        "        print(f\"  Number of chapters will be determined automatically.\")\n",
        "\n",
        "    def _openrouter_generate(self, prompt, system_prompt=\"You are a helpful AI assistant.\", temperature=0.7, top_p=0.9):\n",
        "        \"\"\"\n",
        "        Helper function to make API calls to the OpenRouter server.\n",
        "        Includes error handling and basic retry logic.\n",
        "        \"\"\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"HTTP-Referer\": SITE_URL,\n",
        "            \"X-Title\": APP_TITLE,\n",
        "        }\n",
        "        messages = []\n",
        "        if system_prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        data = {\n",
        "            \"model\": OPENROUTER_MODEL,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": temperature,\n",
        "            \"top_p\": top_p,\n",
        "            # Add other parameters like max_tokens if needed, check model compatibility\n",
        "            # \"max_tokens\": 4000\n",
        "        }\n",
        "\n",
        "        max_retries = 3\n",
        "        base_delay = 5 # seconds\n",
        "\n",
        "        # Debug: Print prompt snippet before sending\n",
        "        # print(f\"\\n--- Sending Prompt to OpenRouter ({OPENROUTER_MODEL}) ---\\n{prompt[:300]}...\\n---\")\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = requests.post(OPENROUTER_BASE_URL, headers=headers, json=data, timeout=API_TIMEOUT)\n",
        "                response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "                response_data = response.json()\n",
        "\n",
        "                # Check for errors in the response body itself\n",
        "                if \"error\" in response_data:\n",
        "                    error_msg = response_data['error'].get('message', str(response_data['error']))\n",
        "                    print(f\"ERROR from OpenRouter API: {error_msg}\")\n",
        "                    # Check for rate limiting specifically\n",
        "                    if response.status_code == 429 or 'rate limit' in error_msg.lower():\n",
        "                         delay = base_delay * (2 ** attempt)\n",
        "                         print(f\"Rate limit likely hit. Retrying in {delay} seconds...\")\n",
        "                         time.sleep(delay)\n",
        "                         continue # Retry the request\n",
        "                    else:\n",
        "                         return f\"[OPENROUTER API ERROR: {error_msg}]\" # Return error message\n",
        "\n",
        "                # Extract the generated text\n",
        "                if \"choices\" in response_data and len(response_data[\"choices\"]) > 0:\n",
        "                    message = response_data[\"choices\"][0].get(\"message\", {})\n",
        "                    content = message.get(\"content\")\n",
        "                    if content:\n",
        "                        # Debug: Print response snippet\n",
        "                        # print(f\"--- OpenRouter Response Received ---\\n{content[:300]}...\\n---\")\n",
        "                        return content.strip()\n",
        "                    else:\n",
        "                        print(\"Warning: 'content' key missing in response choice message.\")\n",
        "                        print(f\"Full Response Choice: {response_data['choices'][0]}\")\n",
        "                        return \"[OPENROUTER RESPONSE FORMAT ERROR: Missing content]\"\n",
        "                else:\n",
        "                    print(\"Warning: 'choices' key missing or empty in OpenRouter response.\")\n",
        "                    print(f\"Full Response: {response_data}\")\n",
        "                    return \"[OPENROUTER RESPONSE FORMAT ERROR: Missing choices]\"\n",
        "\n",
        "            except requests.exceptions.Timeout:\n",
        "                 print(f\"ERROR: OpenRouter request timed out after {API_TIMEOUT} seconds (Attempt {attempt+1}/{max_retries}).\")\n",
        "                 if attempt < max_retries - 1:\n",
        "                     delay = base_delay * (2 ** attempt)\n",
        "                     print(f\"Retrying in {delay} seconds...\")\n",
        "                     time.sleep(delay)\n",
        "                     continue\n",
        "                 else:\n",
        "                     return f\"[OPENROUTER TIMEOUT ERROR after {max_retries} attempts]\"\n",
        "\n",
        "            except requests.exceptions.HTTPError as e:\n",
        "                print(f\"ERROR: OpenRouter HTTP Error: {e} (Status: {e.response.status_code}) (Attempt {attempt+1}/{max_retries})\")\n",
        "                error_details = \"Could not decode error response.\"\n",
        "                try:\n",
        "                    error_details = e.response.json()\n",
        "                    print(f\"Error details: {error_details}\")\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"Raw error response: {e.response.text}\")\n",
        "\n",
        "                # Check for rate limits or specific errors for retry\n",
        "                should_retry = False\n",
        "                if e.response.status_code == 429: # Rate limit\n",
        "                    should_retry = True\n",
        "                    print(\"Rate limit detected (HTTP 429).\")\n",
        "                elif e.response.status_code >= 500: # Server errors\n",
        "                     should_retry = True\n",
        "                     print(\"Server error detected.\")\n",
        "\n",
        "                if should_retry and attempt < max_retries - 1:\n",
        "                     delay = base_delay * (2 ** attempt)\n",
        "                     print(f\"Retrying in {delay} seconds...\")\n",
        "                     time.sleep(delay)\n",
        "                     continue\n",
        "                else: # Max retries reached or non-retryable error\n",
        "                    return f\"[OPENROUTER HTTP ERROR: {e.response.status_code} - {error_details}]\"\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"ERROR: OpenRouter request failed: {e} (Attempt {attempt+1}/{max_retries})\")\n",
        "                # Generally non-retryable network/connection errors\n",
        "                return f\"[OPENROUTER REQUEST ERROR: {e}]\"\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                # This usually means the response from the server wasn't valid JSON\n",
        "                print(f\"ERROR: Failed to decode JSON response from OpenRouter: {e}\")\n",
        "                print(f\"Raw response text: {response.text if 'response' in locals() else 'Response object not available'}\")\n",
        "                return f\"[OPENROUTER JSON DECODE ERROR]\"\n",
        "\n",
        "            except Exception as e: # Catch any other unexpected errors\n",
        "                 print(f\"ERROR: An unexpected error occurred during API call: {e}\")\n",
        "                 import traceback\n",
        "                 traceback.print_exc()\n",
        "                 return f\"[UNEXPECTED API CALL ERROR: {e}]\"\n",
        "\n",
        "        # If all retries fail\n",
        "        print(f\"API call failed permanently after {max_retries} retries.\")\n",
        "        return \"[OPENROUTER API CALL FAILED AFTER RETRIES]\"\n",
        "\n",
        "    def _parse_character_profiles(self, text_block):\n",
        "        \"\"\" Parses character profiles, enhanced for robustness. \"\"\"\n",
        "        characters = {}\n",
        "        # Split by double newline, assuming each character is a block\n",
        "        char_blocks = re.split(r'\\n\\s*\\n', text_block.strip())\n",
        "        current_char_data = {}\n",
        "        current_char_name = None\n",
        "\n",
        "        for block in char_blocks:\n",
        "            block = block.strip()\n",
        "            if not block:\n",
        "                continue\n",
        "\n",
        "            current_char_data = {} # Reset for each block initially\n",
        "\n",
        "            # Try to find the name first\n",
        "            name_match = re.match(r\"CHARACTER NAME:\\s*(.*)\", block, re.IGNORECASE)\n",
        "            if name_match:\n",
        "                current_char_name = name_match.group(1).strip()\n",
        "            else:\n",
        "                 # If no explicit NAME line, maybe the block *is* the name?\n",
        "                 # Or maybe it's a continuation? For now, we need the marker.\n",
        "                 # Heuristic: If a line *looks like* a name at the start of block, use it.\n",
        "                 first_line = block.split('\\n')[0].strip()\n",
        "                 if len(first_line.split()) < 4 and first_line.isupper(): # Simple guess for name-like line\n",
        "                      current_char_name = first_line\n",
        "                 else:\n",
        "                      print(f\"Warning: Skipping character block due to missing 'CHARACTER NAME:' marker:\\n{block[:100]}...\")\n",
        "                      continue # Skip block if no name found\n",
        "\n",
        "            # Defined keys and variations\n",
        "            keys_to_check = {\n",
        "                \"ROLE\": [\"ROLE\"],\n",
        "                \"DESCRIPTION\": [\"DESCRIPTION\"],\n",
        "                \"MOTIVATION\": [\"MOTIVATION(S)\", \"MOTIVATION\"],\n",
        "                \"INITIAL_ARC_SUMMARY\": [\"INITIAL_ARC_SUMMARY\", \"ARC SUMMARY\", \"ARC\"],\n",
        "                \"FLAWS\": [\"FLAWS/WEAKNESSES\", \"FLAWS\", \"WEAKNESSES\"],\n",
        "                \"STRENGTHS\": [\"STRENGTHS/SKILLS\", \"STRENGTHS\", \"SKILLS\"]\n",
        "            }\n",
        "\n",
        "            lines = block.split('\\n')\n",
        "            last_key_found = None\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line: continue\n",
        "\n",
        "                found_key = False\n",
        "                for internal_key, possible_llm_keys in keys_to_check.items():\n",
        "                    for llm_key in possible_llm_keys:\n",
        "                        # Match key at start, possibly after bullet point, followed by colon\n",
        "                        match = re.match(r\"^(?:\\s*[-\\*•]?\\s*)?\" + re.escape(llm_key) + r\":\\s*(.*)\", line, re.IGNORECASE)\n",
        "                        if match:\n",
        "                            value = match.group(1).strip()\n",
        "                            current_char_data[internal_key] = value\n",
        "                            last_key_found = internal_key # Track the last key matched\n",
        "                            found_key = True\n",
        "                            break # Found a match for this line\n",
        "                    if found_key: break # Move to next line\n",
        "\n",
        "                # Handle potential multiline values (append to last matched key if no new key found)\n",
        "                if not found_key and last_key_found and current_char_data.get(last_key_found):\n",
        "                    current_char_data[last_key_found] += \"\\n\" + line\n",
        "\n",
        "            # Store the parsed character\n",
        "            if current_char_name:\n",
        "                 # Use .get with defaults for safety\n",
        "                 characters[current_char_name] = {\n",
        "                     \"name\": current_char_name,\n",
        "                     \"role\": current_char_data.get(\"ROLE\", \"N/A\"),\n",
        "                     \"description\": current_char_data.get(\"DESCRIPTION\", \"N/A\"),\n",
        "                     \"motivation\": current_char_data.get(\"MOTIVATION\", \"N/A\"),\n",
        "                     \"arc_summary\": current_char_data.get(\"INITIAL_ARC_SUMMARY\", \"N/A\"),\n",
        "                     \"flaws\": current_char_data.get(\"FLAWS\", \"N/A\"),\n",
        "                     \"strengths\": current_char_data.get(\"STRENGTHS\", \"N/A\"),\n",
        "                     \"current_status\": \"alive\",\n",
        "                     \"current_location\": \"unknown\",\n",
        "                     \"emotional_state\": \"neutral\",\n",
        "                     \"knowledge\": [],\n",
        "                     \"relationships\": {},\n",
        "                     \"first_appearance_chapter\": 0,\n",
        "                     \"development_log\": []\n",
        "                 }\n",
        "                 current_char_name = None # Reset for next block\n",
        "            else:\n",
        "                 print(f\"Warning: Could not associate parsed data with a character name for block:\\n{block[:100]}...\")\n",
        "\n",
        "        return characters\n",
        "\n",
        "\n",
        "    # --- Phase 1: Foundation Methods ---\n",
        "    def generate_foundational_elements(self):\n",
        "        \"\"\" Generates initial characters, world, themes, plot, chapter count with enhanced prompts. \"\"\"\n",
        "        print(\"\\n--- Generating Foundational Elements ---\")\n",
        "\n",
        "        # 1. Character Conception (Enhanced Prompt)\n",
        "        print(\"Step 1.1: Generating Character Profiles...\")\n",
        "        char_system_prompt = f\"You are a master character creator specializing in deep, believable characters for {self.genre} novels, inspired by {self.author_style}.\"\n",
        "        char_prompt = f\"\"\"\n",
        "Based on the novel's subject, genre, author style, and the provided resume snippet (if any), create detailed, psychologically plausible profiles for the main protagonist and 1-2 key supporting characters (e.g., antagonist, mentor, confidante). Ensure characters have clear motivations and potential for compelling arcs.\n",
        "\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "Author Style Influence: {self.author_style}\n",
        "Resume Snippet (use this to inspire the protagonist's background, potential skills, personality traits, and perhaps core conflicts or motivations):\n",
        "---\n",
        "{self.resume_content if self.resume_content else \"No resume provided. Create protagonist primarily based on subject and genre.\"}\n",
        "---\n",
        "IMPORTANT: Structure the ENTIRE response as a list of character profiles using the EXACT format below. Start EACH profile with 'CHARACTER NAME:'. Do NOT add introductory/summary text outside this structure.\n",
        "\n",
        "Format for each character:\n",
        "CHARACTER NAME: [Suggest a fitting and memorable name]\n",
        "ROLE: [Protagonist, Antagonist, Key Supporting - specify type (e.g., Mentor, Rival, Love Interest)]\n",
        "DESCRIPTION: [Detailed physical appearance, key personality traits (positive and negative), mannerisms, vocal quality, background summary linked to subject/resume]\n",
        "MOTIVATION(S): [Primary conscious goal AND deeper underlying psychological need/fear driving them. What do they fundamentally want/avoid?]\n",
        "INITIAL_ARC_SUMMARY: [Their starting point (flaws, beliefs, situation) and potential trajectory. How might they change by the end? What core internal conflict will they grapple with?]\n",
        "FLAWS/WEAKNESSES: [Specific, impactful character flaws, blind spots, vulnerabilities, or past traumas that hinder them.]\n",
        "STRENGTHS/SKILLS: [Tangible skills, positive personality traits, unique abilities relevant to the plot/world.]\n",
        "\n",
        "Focus on creating characters that feel real and have clear potential for development within the story's context.\n",
        "\"\"\"\n",
        "        character_profiles_text = self._openrouter_generate(char_prompt, char_system_prompt, temperature=0.75)\n",
        "        if \"[OPENROUTER\" in character_profiles_text:\n",
        "            print(f\"ERROR generating character profiles: {character_profiles_text}\")\n",
        "            return False # Halt if core element fails\n",
        "        else:\n",
        "            self.characters = self._parse_character_profiles(character_profiles_text)\n",
        "            if not self.characters:\n",
        "                print(\"Critical Warning: Failed to parse character profiles from LLM output. Check LLM response format. Raw output (first 1000 chars):\")\n",
        "                print(character_profiles_text[:1000] + \"...\" if len(character_profiles_text) > 1000 else character_profiles_text)\n",
        "                return False # Halt if core element fails\n",
        "            print(f\"Generated {len(self.characters)} character profiles: {', '.join(self.characters.keys())}\")\n",
        "\n",
        "\n",
        "        # 2. Worldbuilding (Enhanced Prompt)\n",
        "        print(\"\\nStep 1.2: Generating World Details...\")\n",
        "        world_system_prompt = f\"You are an expert world-builder for {self.genre} fiction, crafting immersive, coherent, and evocative settings inspired by {self.author_style}.\"\n",
        "        world_prompt = f\"\"\"\n",
        "Based on the novel's subject and genre, describe the primary world/setting with DEPTH and COHERENCE. Focus on details relevant to the subject and potential conflicts.\n",
        "\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "Character Concepts (for context): {json.dumps({name: data.get('role', '') for name, data in self.characters.items()})}\n",
        "\n",
        "IMPORTANT: Provide ONLY the following details, using the exact numbered headers. Do not add plot points or external commentary.\n",
        "\n",
        "1.  WORLD NAME: [A unique, evocative, and genre-appropriate name for the main setting/world/city.]\n",
        "2.  KEY LOCATIONS (3-5): [List significant recurring locations. For each: \"- [Location Name] - [Brief description focusing on its sensory details, atmosphere, and relevance to the plot/characters (e.g., seat of power, place of danger, source of knowledge)].\"]\n",
        "3.  CULTURAL/SOCIETAL ELEMENTS (2-4): [Describe unique customs, social structures, beliefs, technologies, or magical systems crucial to the story. For each: \"- [Element Name/Concept] - [Explanation of how it works and its impact on daily life or the central conflict].\"]\n",
        "4.  ATMOSPHERE/TONE: [Describe the prevailing mood (e.g., oppressive gothic, wondrous high fantasy, gritty cyberpunk, nostalgic historical). Use evocative adjectives.]\n",
        "5.  KEY RULES/LAWS (2-3, if applicable): [Fundamental rules governing magic, physics, society, or technology that will impact the plot. Make them clear and consistent. e.g., \"- Magic drains life force,\" \"- Only the nobility can pilot mechs,\" \"- Time travel creates paradoxes.\"]\n",
        "\"\"\"\n",
        "        world_details_text = self._openrouter_generate(world_prompt, world_system_prompt, temperature=0.65)\n",
        "        if \"[OPENROUTER\" in world_details_text:\n",
        "            print(f\"ERROR generating world details: {world_details_text}\")\n",
        "            return False # Halt\n",
        "        else:\n",
        "             # Use improved parsing logic similar to character parsing (more robust)\n",
        "             lines = world_details_text.split('\\n')\n",
        "             current_section = None\n",
        "             parsed_details = {\"key_locations\": [], \"cultural_elements\": [], \"rules\": []}\n",
        "\n",
        "             for line in lines:\n",
        "                  line = line.strip()\n",
        "                  if not line: continue\n",
        "\n",
        "                  if re.match(r\"1\\.\\s*WORLD NAME:\", line, re.IGNORECASE):\n",
        "                      parsed_details[\"name\"] = re.split(r\":\", line, 1)[1].strip().strip('\"\\'*`#')\n",
        "                      current_section = \"name\"\n",
        "                  elif re.match(r\"2\\.\\s*KEY LOCATIONS:\", line, re.IGNORECASE):\n",
        "                      current_section = \"key_locations\"\n",
        "                  elif re.match(r\"3\\.\\s*CULTURAL/SOCIETAL ELEMENTS:\", line, re.IGNORECASE):\n",
        "                      current_section = \"cultural_elements\"\n",
        "                  elif re.match(r\"4\\.\\s*ATMOSPHERE/TONE:\", line, re.IGNORECASE):\n",
        "                      parsed_details[\"atmosphere\"] = re.split(r\":\", line, 1)[1].strip()\n",
        "                      current_section = \"atmosphere\"\n",
        "                  elif re.match(r\"5\\.\\s*KEY RULES/LAWS:\", line, re.IGNORECASE):\n",
        "                      current_section = \"rules\"\n",
        "                  elif current_section and line.startswith((\"-\",\"*\",\"•\")) or re.match(r\"\\d+\\.\", line):\n",
        "                      item_text = line.strip(\"-*• \").lstrip(\"123456789. \")\n",
        "                      if item_text and current_section in [\"key_locations\", \"cultural_elements\", \"rules\"]:\n",
        "                          parsed_details[current_section].append(item_text)\n",
        "                  elif current_section and current_section in parsed_details and isinstance(parsed_details[current_section], list) and parsed_details[current_section]:\n",
        "                      # Append to the last item in the list if it's a continuation\n",
        "                      parsed_details[current_section][-1] += \"\\n\" + line\n",
        "                  elif current_section == \"name\" and \"name\" in parsed_details: # Continuation of world name? Unlikely but possible\n",
        "                      parsed_details[\"name\"] += \" \" + line\n",
        "                  elif current_section == \"atmosphere\" and \"atmosphere\" in parsed_details:\n",
        "                      parsed_details[\"atmosphere\"] += \" \" + line\n",
        "\n",
        "\n",
        "             self.world_details.update(parsed_details) # Merge parsed data\n",
        "             print(f\"Generated World Details for '{self.world_details.get('name', 'Unnamed World')}'.\")\n",
        "             if not self.world_details.get(\"name\"):\n",
        "                 print(\"Critical Warning: Failed to parse World Name. Check LLM response format.\")\n",
        "                 print(world_details_text[:1000])\n",
        "                 return False # Halt\n",
        "\n",
        "\n",
        "        # 3. Themes and Motifs (Enhanced Prompt)\n",
        "        print(\"\\nStep 1.3: Generating Themes and Motifs...\")\n",
        "        themes_system_prompt = f\"You are a literary analyst identifying profound themes and resonant motifs for {self.genre} novels, reflecting the depth of {self.author_style}.\"\n",
        "        themes_prompt = f\"\"\"\n",
        "Based on the novel's subject, genre, characters, and world, identify potential core themes and recurring motifs.\n",
        "\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "Characters: {json.dumps({name: data.get('role', '') + ': ' + data.get('motivation','').split('.')[0] for name, data in self.characters.items()}, indent=2)}\n",
        "World: {self.world_details.get('name','N/A')} ({self.world_details.get('atmosphere','N/A')})\n",
        "\n",
        "IMPORTANT: Structure the response ONLY as lists under the exact headers '1. CORE THEMES:' and '2. RECURRING MOTIFS:'. Do not add external commentary.\n",
        "\n",
        "1.  CORE THEMES (2-4): [List the central abstract ideas the story will explore (e.g., Identity, Betrayal, Sacrifice, Progress vs Tradition). For each theme, provide a 1-2 sentence explanation linking it specifically to the novel's subject, characters, or world context.]\n",
        "2.  RECURRING MOTIFS (3-5): [List specific, concrete symbols, objects, recurring phrases, colors, or imagery that can visually or conceptually reinforce the core themes throughout the narrative (e.g., \"A locked music box,\" \"Mirrors showing distorted reflections,\" \"The scent of rain on metal\").]\n",
        "\"\"\"\n",
        "        themes_motifs_text = self._openrouter_generate(themes_prompt, themes_system_prompt, temperature=0.6)\n",
        "        if \"[OPENROUTER\" in themes_motifs_text:\n",
        "            print(f\"ERROR generating themes/motifs: {themes_motifs_text}\")\n",
        "            return False # Halt\n",
        "        else:\n",
        "            # Use similar parsing logic as world details\n",
        "            themes = []\n",
        "            motifs = []\n",
        "            current_section = None\n",
        "            for line in themes_motifs_text.split('\\n'):\n",
        "                 line = line.strip()\n",
        "                 if not line: continue\n",
        "                 if re.match(r\"1\\.\\s*CORE THEMES:\", line, re.IGNORECASE):\n",
        "                      current_section = \"themes\"\n",
        "                 elif re.match(r\"2\\.\\s*RECURRING MOTIFS:\", line, re.IGNORECASE):\n",
        "                      current_section = \"motifs\"\n",
        "                 elif current_section and line.startswith((\"-\",\"*\",\"•\")) or re.match(r\"\\d+\\.\", line):\n",
        "                      item_text = line.strip(\"-*• \").lstrip(\"123456789. \")\n",
        "                      if item_text:\n",
        "                           if current_section == \"themes\": themes.append(item_text)\n",
        "                           elif current_section == \"motifs\": motifs.append(item_text)\n",
        "                 elif current_section and ((current_section == \"themes\" and themes) or (current_section == \"motifs\" and motifs)):\n",
        "                     # Append to last item if continuation\n",
        "                      if current_section == \"themes\": themes[-1] += \"\\n\" + line\n",
        "                      elif current_section == \"motifs\": motifs[-1] += \"\\n\" + line\n",
        "\n",
        "\n",
        "            self.themes_motifs[\"themes\"] = themes\n",
        "            self.themes_motifs[\"motifs\"] = motifs\n",
        "\n",
        "            if not self.themes_motifs[\"themes\"] and not self.themes_motifs[\"motifs\"]:\n",
        "                print(\"Warning: Failed to parse Themes and Motifs. Check LLM response format.\")\n",
        "                print(themes_motifs_text[:1000])\n",
        "                # Don't halt for this, but quality may be lower\n",
        "            print(f\"Generated Themes: {self.themes_motifs['themes']}\")\n",
        "            print(f\"Generated Motifs: {self.themes_motifs['motifs']}\")\n",
        "\n",
        "        # 4. High-Level Plot Outline & Chapter Count (Enhanced Prompt)\n",
        "        print(\"\\nStep 1.4: Generating High-Level Plot Outline and Determining Chapter Count...\")\n",
        "        plot_system_prompt = f\"You are a master storyteller outlining gripping, logically structured plots for {self.genre} novels, echoing the narrative drive of {self.author_style}.\"\n",
        "        plot_prompt = f\"\"\"\n",
        "Create a concise high-level plot outline (e.g., Three-Act Structure) for a novel based on the established elements. Focus on logical progression, rising stakes, and character arc integration.\n",
        "\n",
        "Novel Subject: {self.subject}\n",
        "Genre: {self.genre}\n",
        "Characters: {json.dumps({name: {'role': data.get('role'), 'arc': data.get('arc_summary')} for name, data in self.characters.items()}, indent=2)}\n",
        "World: {self.world_details.get('name','N/A')} ({self.world_details.get('atmosphere','N/A')})\n",
        "Core Themes: {', '.join(self.themes_motifs.get('themes', []))}\n",
        "\n",
        "Outline Structure:\n",
        "-   **Act I (Setup - Approx 20-25%):** Introduce the protagonist in their 'normal world', establish core relationships and desires/flaws. Introduce the inciting incident that disrupts this world and launches the main conflict. Define the initial stakes and the protagonist's immediate goal.\n",
        "-   **Act II (Confrontation - Approx 50-60%):** Rising action. Protagonist faces escalating obstacles, makes allies/enemies, learns new skills/truths. Key turning points (e.g., midpoint reversal, point of no return) challenge their beliefs/methods. Stakes increase significantly. Show character development through choices made under pressure.\n",
        "-   **Act III (Resolution - Approx 20-25%):** Protagonist confronts the main antagonist/obstacle in the climax, utilizing their developed strengths/learnings. Falling action deals with the immediate aftermath. Resolution provides closure for the main plot and character arc, reflecting on the core themes.\n",
        "\n",
        "For each Act, provide a 3-5 sentence summary focusing on the key narrative movements and character arc milestones within that act.\n",
        "IMPORTANT: After the Act summaries, provide a reasonable chapter count estimation based on the plot complexity, using the EXACT format 'SUGGESTED_CHAPTER_COUNT: [Number]'. This number should ideally be between 10 and 50 for a standard novel structure.\n",
        "\n",
        "Your response MUST contain ONLY the summaries for Act I, Act II, and Act III, followed by the SUGGESTED_CHAPTER_COUNT line. Do not add external commentary. Start with Act I.\n",
        "\"\"\"\n",
        "        self.plot_outline = self._openrouter_generate(plot_prompt, plot_system_prompt, temperature=0.7)\n",
        "\n",
        "        if \"[OPENROUTER\" in self.plot_outline:\n",
        "            print(f\"ERROR generating plot outline: {self.plot_outline}\")\n",
        "            print(\"Defaulting number of chapters to 15 due to API error.\")\n",
        "            self.num_chapters = 15 # Default if API error\n",
        "            return False # Halt as plot is essential\n",
        "        else:\n",
        "            # Extract and display plot, remove chapter count for display\n",
        "            plot_display = re.sub(r\"SUGGESTED_CHAPTER_COUNT:\\s*\\d+\", \"\", self.plot_outline, flags=re.IGNORECASE).strip()\n",
        "            print(\"Generated High-Level Plot Outline:\")\n",
        "            print(plot_display)\n",
        "\n",
        "            # Parse chapter count\n",
        "            suggested_chapters_match = re.search(r\"SUGGESTED_CHAPTER_COUNT:\\s*(\\d+)\", self.plot_outline, re.IGNORECASE)\n",
        "            if suggested_chapters_match:\n",
        "                try:\n",
        "                    self.num_chapters = int(suggested_chapters_match.group(1))\n",
        "                    # Wider reasonable range, but clamp extremes\n",
        "                    min_ch, max_ch = 10, 60\n",
        "                    if not (min_ch <= self.num_chapters <= max_ch):\n",
        "                        print(f\"Warning: LLM suggested {self.num_chapters} chapters. Clamping to a range of {min_ch}-{max_ch}. Setting to {max(min_ch, min(self.num_chapters, max_ch))}.\")\n",
        "                        self.num_chapters = max(min_ch, min(self.num_chapters, max_ch))\n",
        "                    else:\n",
        "                        print(f\"LLM suggested {self.num_chapters} chapters.\")\n",
        "                except ValueError:\n",
        "                    print(\"Warning: Could not parse suggested chapter count. Defaulting to 15.\")\n",
        "                    self.num_chapters = 15\n",
        "            else:\n",
        "                print(\"Warning: Could not find 'SUGGESTED_CHAPTER_COUNT:' in plot outline. Defaulting to 15.\")\n",
        "                self.num_chapters = 15\n",
        "\n",
        "\n",
        "        print(\"Foundational elements generation phase complete.\")\n",
        "        return True # Indicate success\n",
        "\n",
        "\n",
        "    # --- Phase 2: Detailed Planning Method ---\n",
        "    def generate_detailed_chapter_plans(self):\n",
        "        \"\"\" Generates detailed plans for each chapter using enhanced prompts and batching. \"\"\"\n",
        "        print(\"\\n--- Generating Detailed Chapter-by-Chapter Plans ---\")\n",
        "        if not self.plot_outline or not self.characters or not self.world_details.get(\"name\") or self.num_chapters == 0:\n",
        "             print(\"ERROR: Cannot generate chapter plans - missing essential foundational elements generated earlier.\")\n",
        "             return False\n",
        "\n",
        "        system_prompt = f\"You are a meticulous plot architect, breaking down a high-level outline into detailed, coherent chapter plans for a {self.genre} novel in the style of {self.author_style}. Focus on cause-and-effect, character consistency, and narrative momentum.\"\n",
        "        # Prepare context summaries once\n",
        "        character_summary_for_prompt = \"\\n\".join([f\"- {name} ({data.get('role', 'N/A')}): Motivations: {data.get('motivation', 'N/A')}. Arc Summary: {data.get('arc_summary', 'N/A')}\" for name, data in self.characters.items()])\n",
        "        world_summary_for_prompt = f\"World: {self.world_details.get('name', 'N/A')} ({self.world_details.get('atmosphere', 'N/A')})\\nKey Locations: {', '.join(self.world_details.get('key_locations',[]))}\\nCultural Elements: {', '.join(self.world_details.get('cultural_elements',[]))}\\nRules: {', '.join(self.world_details.get('rules',[]))}\"\n",
        "        themes_for_prompt = f\"Core Themes: {', '.join(self.themes_motifs.get('themes',[]))}\\nRecurring Motifs: {', '.join(self.themes_motifs.get('motifs',[]))}\"\n",
        "        clean_plot_outline_for_detailed_plan = re.sub(r\"SUGGESTED_CHAPTER_COUNT:\\s*\\d+\", \"\", self.plot_outline, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        # Batching logic (adjust batch size based on model context window and plan detail)\n",
        "        # Smaller batches might be safer for smaller context models like Llama 3 8B\n",
        "        max_chapters_per_batch = 8\n",
        "        num_batches = (self.num_chapters + max_chapters_per_batch - 1) // max_chapters_per_batch\n",
        "\n",
        "        all_batches_successful = True\n",
        "        parsed_chapters_count = 0\n",
        "\n",
        "        for batch_idx in range(num_batches):\n",
        "            start_chapter = batch_idx * max_chapters_per_batch + 1\n",
        "            end_chapter = min((batch_idx + 1) * max_chapters_per_batch, self.num_chapters)\n",
        "\n",
        "            print(f\"\\nGenerating detailed plan text for chapters {start_chapter}-{end_chapter} (batch {batch_idx+1}/{num_batches})...\")\n",
        "\n",
        "            # Add context about previous batch's ending if not the first batch\n",
        "            previous_batch_context = \"\"\n",
        "            if batch_idx > 0:\n",
        "                 prev_batch_end_chap = start_chapter - 1\n",
        "                 if prev_batch_end_chap in self.chapter_plans:\n",
        "                      prev_plan = self.chapter_plans[prev_batch_end_chap]\n",
        "                      previous_batch_context = f\"\"\"\n",
        "CONTEXT FROM END OF PREVIOUS BATCH (Chapter {prev_batch_end_chap} - '{prev_plan.get('title', 'Untitled')}'):\n",
        "- End Emotional Tone: {prev_plan.get('emotional_tone_end', 'N/A')}\n",
        "- Connection/Hook Planned for Chapter {start_chapter}: {prev_plan.get('connection_to_next', 'N/A')}\n",
        "\"\"\"\n",
        "                 else:\n",
        "                      previous_batch_context = f\"\\nCONTEXT FROM PREVIOUS BATCH: (Plan for Chapter {prev_batch_end_chap} was missing or failed)\\n\"\n",
        "\n",
        "\n",
        "            batch_prompt = f\"\"\"\n",
        "CONTEXT FOR NOVEL PLANNING:\n",
        "- Novel Subject: {self.subject}\n",
        "- High-Level Plot Outline: {clean_plot_outline_for_detailed_plan}\n",
        "- Character Summaries: {character_summary_for_prompt}\n",
        "- World Summary: {world_summary_for_prompt}\n",
        "- Themes & Motifs: {themes_for_prompt}\n",
        "- Total Chapters in Novel: {self.num_chapters}\n",
        "{previous_batch_context}\n",
        "TASK: Create DETAILED PLANS for chapters {start_chapter} through {end_chapter} ONLY.\n",
        "Ensure logical flow and consistency between these chapters and build upon the previous context/hook if provided.\n",
        "\n",
        "REQUIRED FORMAT FOR EACH CHAPTER:\n",
        "(Use the exact labels and structure below)\n",
        "\n",
        "Chapter [Number] - [Evocative Title reflecting chapter's core event/theme]:\n",
        "1.  CHAPTER GOAL: [1-2 sentences: What must this chapter achieve for the plot/character arc? e.g., \"Introduce the antagonist's methods,\" \"Force protagonist to make a difficult choice,\" \"Reveal a key piece of the world's history.\"]\n",
        "2.  KEY SCENES (3-6 scenes): [Bulleted list. Each scene MUST include: \"- Scene X: [Action/Dialogue/Internal Monologue Summary], Location: [Specific location], Characters: [Active characters], Key Outcome/Revelation: [How does this specific scene advance plot/character? What changes?]]\n",
        "3.  CHARACTER DEVELOPMENT FOCUS: [Which characters develop? How? Note specific changes in beliefs, motivations, relationships, skills, or emotional state based on scene outcomes. Link to their overall arc.]\n",
        "4.  PLOT ADVANCEMENT: [How do the main plot and subplots progress? What new questions/obstacles arise? How does it build towards the Act's goals?]\n",
        "5.  TIMELINE & PACING: [Estimated time covered (e.g., \"Afternoon and evening of Day 5\"). Describe pacing (e.g., \"Slow burn tension building to frantic action\").]\n",
        "6.  EMOTIONAL TONE (End of Chapter): [The dominant feeling intended for the reader at the chapter's end (e.g., \"Hope mixed with dread,\" \"Suspenseful uncertainty,\" \"Tragic resolve\").]\n",
        "7.  CONNECTION TO NEXT CHAPTER (Setup/Hook): [Specific event, decision, question, or cliffhanger that directly sets up Chapter {{{{Number + 1}}}}. Must be actionable for the next chapter's writer.]\n",
        "\n",
        "CRITICAL INSTRUCTIONS: Maintain strict continuity. Character states (location, knowledge, emotion) must flow logically from the end of one chapter's plan to the start of the next. Integrate themes/motifs subtly where appropriate.\n",
        "\n",
        "Begin your response directly with \"Chapter {start_chapter} - \".\n",
        "\"\"\"\n",
        "            batch_chapter_plans_text = self._openrouter_generate(batch_prompt, system_prompt, temperature=0.65)\n",
        "\n",
        "            if \"[OPENROUTER\" in batch_chapter_plans_text:\n",
        "                print(f\"ERROR generating batch of chapter plans ({start_chapter}-{end_chapter}): {batch_chapter_plans_text}\")\n",
        "                all_batches_successful = False\n",
        "                continue # Try next batch if possible\n",
        "\n",
        "            # Parse the generated text for this batch\n",
        "            newly_parsed_count = self._parse_chapter_plans(batch_chapter_plans_text, expected_range=(start_chapter, end_chapter))\n",
        "            parsed_chapters_count += newly_parsed_count\n",
        "            if newly_parsed_count < (end_chapter - start_chapter + 1):\n",
        "                 print(f\"Warning: Parsed fewer plans ({newly_parsed_count}) than expected for batch {start_chapter}-{end_chapter}. Check LLM output.\")\n",
        "                 all_batches_successful = False # Mark as potentially problematic\n",
        "\n",
        "        # --- Final Check and Fallback ---\n",
        "        if parsed_chapters_count == 0 and not all_batches_successful:\n",
        "             print(\"CRITICAL ERROR: No chapter plans were successfully generated or parsed from any batch. Cannot proceed.\")\n",
        "             return False\n",
        "\n",
        "        missing_chapters = [i for i in range(1, self.num_chapters + 1) if i not in self.chapter_plans]\n",
        "        if missing_chapters:\n",
        "             print(f\"\\nAttempting to generate fallback plans for {len(missing_chapters)} missing chapters: {missing_chapters}\")\n",
        "             # Implement a fallback generation if needed (similar to _generate_fallback_chapter_plans, using OpenRouter)\n",
        "             # self._generate_fallback_chapter_plans_openrouter(missing_chapters) # Assuming this method exists\n",
        "             print(\"Warning: Fallback plan generation is not fully implemented in this refactor. Missing chapters will cause errors later.\")\n",
        "             # For now, just warn and potentially fail later. A robust implementation would generate fallbacks here.\n",
        "             all_batches_successful = False # Mark failure if fallbacks needed but not generated\n",
        "\n",
        "        if len(self.chapter_plans) != self.num_chapters:\n",
        "            print(f\"WARNING: Final plan count ({len(self.chapter_plans)}) does not match expected chapter count ({self.num_chapters}). Some chapters may be skipped during content generation.\")\n",
        "            # Decide whether to proceed; proceed if we have *some* plans\n",
        "            return len(self.chapter_plans) > 0\n",
        "        else:\n",
        "             print(f\"\\nSuccessfully generated and parsed detailed plans for all {self.num_chapters} chapters.\")\n",
        "             return True\n",
        "\n",
        "    def _parse_chapter_plans(self, chapter_plans_text, expected_range=None):\n",
        "        \"\"\" Parse chapter plans, improved for robustness and batch context. Returns count of newly parsed chapters.\"\"\"\n",
        "        parsed_count = 0\n",
        "        # Use regex to split the text into potential chapter blocks first\n",
        "        # Look for lines starting with \"Chapter [Num] -\" or similar variations\n",
        "        chapter_starts = list(re.finditer(r\"(?:^|\\n)(Chapter\\s+(\\d+)\\s*[-:]\\s*(.*?))(?=\\n\\s*1\\.\\s*CHAPTER GOAL:|\\n\\s*Chapter\\s+\\d+\\s*[-:]|$)\", chapter_plans_text, re.MULTILINE | re.IGNORECASE))\n",
        "\n",
        "        for i, start_match in enumerate(chapter_starts):\n",
        "            try:\n",
        "                full_heading = start_match.group(1).strip()\n",
        "                chapter_num = int(start_match.group(2))\n",
        "                chapter_title = start_match.group(3).strip() if start_match.group(3) else f\"Chapter {chapter_num}\"\n",
        "                start_pos = start_match.end() # Content starts after the heading line\n",
        "\n",
        "                # Check if chapter number is within the expected range for this batch\n",
        "                if expected_range and not (expected_range[0] <= chapter_num <= expected_range[1]):\n",
        "                    print(f\"  Note: Found plan for Chapter {chapter_num} outside expected batch range {expected_range}. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                if chapter_num in self.chapter_plans:\n",
        "                    print(f\"  Note: Plan for Chapter {chapter_num} already exists. Skipping duplicate.\")\n",
        "                    continue\n",
        "\n",
        "                # Determine end position\n",
        "                end_pos = chapter_starts[i+1].start() if i+1 < len(chapter_starts) else len(chapter_plans_text)\n",
        "                chapter_content_block = chapter_plans_text[start_pos:end_pos].strip()\n",
        "\n",
        "                # Parse the content block for this chapter\n",
        "                plan_details = self._parse_single_chapter_plan_content(chapter_content_block)\n",
        "                if plan_details: # Check if parsing yielded anything meaningful\n",
        "                     plan_details[\"number\"] = chapter_num\n",
        "                     plan_details[\"title\"] = chapter_title\n",
        "                     self.chapter_plans[chapter_num] = plan_details\n",
        "                     print(f\"  Parsed plan for Chapter {chapter_num}: {chapter_title}\")\n",
        "                     parsed_count += 1\n",
        "                else:\n",
        "                     print(f\"Warning: Failed to parse details for Chapter {chapter_num} from its content block.\")\n",
        "\n",
        "            except (IndexError, ValueError) as e:\n",
        "                print(f\"Warning: Error parsing chapter heading or number near '{start_match.group(0)}': {e}\")\n",
        "                continue\n",
        "        return parsed_count\n",
        "\n",
        "    def _parse_single_chapter_plan_content(self, chapter_content_block):\n",
        "        \"\"\"Parses the structured content of a single chapter plan block.\"\"\"\n",
        "        plan_details = {\n",
        "            \"goal\": \"N/A\", \"scenes\": [], \"character_development\": \"N/A\",\n",
        "            \"plot_advancement\": \"N/A\", \"timeline_pacing\": \"N/A\",\n",
        "            \"emotional_tone_end\": \"N/A\", \"connection_to_next\": \"N/A\"\n",
        "        }\n",
        "        # Define patterns for each section, matching the prompt structure\n",
        "        patterns = {\n",
        "             \"goal\": r\"(?:1\\.\\s*CHAPTER GOAL:|CHAPTER GOAL:)\\s*(.*?)(?=\\n\\s*\\d+\\.\\s*|\\Z)\",\n",
        "             \"scenes\": r\"(?:2\\.\\s*KEY SCENES:|KEY SCENES:)\\s*(.*?)(?=\\n\\s*\\d+\\.\\s*|\\Z)\",\n",
        "             \"character_development\": r\"(?:3\\.\\s*CHARACTER DEVELOPMENT FOCUS:|CHARACTER DEVELOPMENT FOCUS:)\\s*(.*?)(?=\\n\\s*\\d+\\.\\s*|\\Z)\",\n",
        "             \"plot_advancement\": r\"(?:4\\.\\s*PLOT ADVANCEMENT:|PLOT ADVANCEMENT:)\\s*(.*?)(?=\\n\\s*\\d+\\.\\s*|\\Z)\",\n",
        "             \"timeline_pacing\": r\"(?:5\\.\\s*TIMELINE & PACING:|TIMELINE & PACING:)\\s*(.*?)(?=\\n\\s*\\d+\\.\\s*|\\Z)\",\n",
        "             \"emotional_tone_end\": r\"(?:6\\.\\s*EMOTIONAL TONE \\(End of Chapter\\):|EMOTIONAL TONE.*:)\\s*(.*?)(?=\\n\\s*\\d+\\.\\s*|\\Z)\",\n",
        "             \"connection_to_next\": r\"(?:7\\.\\s*CONNECTION TO NEXT CHAPTER|CONNECTION TO NEXT.*:)\\s*(.*?)(?=\\n\\s*\\d+\\.\\s*|\\Z)\"\n",
        "         }\n",
        "\n",
        "        found_anything = False\n",
        "        for key, pattern in patterns.items():\n",
        "            match = re.search(pattern, chapter_content_block, re.IGNORECASE | re.DOTALL | re.MULTILINE)\n",
        "            if match:\n",
        "                value = match.group(1).strip()\n",
        "                if key == \"scenes\":\n",
        "                    # Split scenes carefully, handling multiline descriptions within a scene\n",
        "                    scene_lines = [line.strip() for line in value.split('\\n') if line.strip()]\n",
        "                    scenes_list = []\n",
        "                    current_scene = \"\"\n",
        "                    for line in scene_lines:\n",
        "                        # If line starts like a new scene marker (bullet, number, \"Scene X:\")\n",
        "                        if line.startswith((\"-\",\"*\",\"•\")) or re.match(r\"Scene \\d+:\", line, re.IGNORECASE):\n",
        "                            if current_scene: # Save the previous scene\n",
        "                                scenes_list.append(current_scene.strip())\n",
        "                            current_scene = line.strip(\"-*• \") # Start the new scene text\n",
        "                        elif current_scene: # Append to the current scene description\n",
        "                            current_scene += \"\\n\" + line\n",
        "                        else: # Handle text before the first explicit scene marker if any\n",
        "                             current_scene += line # Treat as part of the first scene\n",
        "                    if current_scene: # Add the last scene\n",
        "                        scenes_list.append(current_scene.strip())\n",
        "                    plan_details[key] = scenes_list if scenes_list else [\"Scene description missing or malformed.\"]\n",
        "                else:\n",
        "                    plan_details[key] = value\n",
        "                found_anything = True # Mark that we parsed at least one field\n",
        "\n",
        "        return plan_details if found_anything else None\n",
        "\n",
        "    # --- Phase 3: Prose Generation Loop ---\n",
        "    def _get_continuity_context_for_chapter(self, chapter_num):\n",
        "        \"\"\" Gathers essential context for generating the current chapter, focusing on flow. \"\"\"\n",
        "        context = f\"--- CONTEXT FOR GENERATING CHAPTER {chapter_num} ---\\n\"\n",
        "        context += f\"Overall Novel Subject: {self.subject}\\n\"\n",
        "        context += f\"Author Style Influence: {self.author_style}, Genre: {self.genre}\\n\"\n",
        "        # Clean plot_outline from chapter count\n",
        "        cleaned_plot_outline = re.sub(r\"SUGGESTED_CHAPTER_COUNT:\\s*\\d+\", \"\", self.plot_outline, flags=re.IGNORECASE).strip()\n",
        "        context += f\"High-Level Plot Outline:\\n{cleaned_plot_outline}\\n\\n\"\n",
        "        context += f\"World: {self.world_details.get('name','N/A')} ({self.world_details.get('atmosphere','N/A')}). Rules: {self.world_details.get('rules',[])}\\n\"\n",
        "        context += f\"Core Themes: {self.themes_motifs.get('themes',[])}. Motifs: {self.themes_motifs.get('motifs',[])}\\n\\n\"\n",
        "\n",
        "        context += \"**Character States (Start of Chapter {chapter_num}):**\\n\"\n",
        "        for name, data in self.characters.items():\n",
        "            # Only include characters expected to be relevant soon or already appeared\n",
        "            if data.get('first_appearance_chapter', 0) == 0 or data.get('first_appearance_chapter', 0) <= chapter_num + 1: # Look ahead slightly\n",
        "                 context += f\"- **{name}** ({data.get('role','N/A')}):\\n\"\n",
        "                 context += f\"  Status: {data.get('current_status','unknown')}\\n\"\n",
        "                 context += f\"  Location: {data.get('current_location','unknown')}\\n\"\n",
        "                 context += f\"  Emotion: {data.get('emotional_state','unknown')}\\n\"\n",
        "                 context += f\"  Motivation: {data.get('motivation','N/A')}\\n\"\n",
        "                 context += f\"  Knowledge Summary: {', '.join(data.get('knowledge',[]))}\\n\"\n",
        "                 # Show last 1-2 development logs for recent context\n",
        "                 relevant_logs = [log for log in data.get('development_log', []) if log['chapter'] < chapter_num]\n",
        "                 if relevant_logs:\n",
        "                     context += \"  Recent Development Hints:\\n\"\n",
        "                     for log in relevant_logs[-2:]: # Last two logs\n",
        "                          log_summary = log.get('summary', json.dumps(log)) # Provide full log if summary missing\n",
        "                          context += f\"    (Ch {log['chapter']}): {log_summary[:150]}...\\n\"\n",
        "        context += \"\\n\"\n",
        "\n",
        "        if chapter_num > 1:\n",
        "            prev_chap_num = chapter_num - 1\n",
        "            prev_continuity = self.chapter_continuity_data.get(prev_chap_num, {})\n",
        "            prev_plan = self.chapter_plans.get(prev_chap_num, {})\n",
        "            context += f\"**End of Previous Chapter ({prev_chap_num} - '{prev_plan.get('title', 'Untitled')}'):**\\n\"\n",
        "            # Include a more substantial part of the summary for better context\n",
        "            context += f\"- Summary Snippet: ...{prev_continuity.get('summary', 'N/A')[-1500:]}\\n\"\n",
        "            context += f\"- Actual Ending Hook Text: \\\"{prev_continuity.get('ending_hook_text', 'N/A')}\\\"\\n\"\n",
        "            context += f\"- Timeline at End: {prev_continuity.get('timeline_end', 'N/A')}\\n\"\n",
        "            # Include the analysis of the flow from the previous step\n",
        "            context += f\"- Analysis of Flow into This Chapter: {prev_continuity.get('flow_analysis_from_previous', 'N/A')}\\n\\n\"\n",
        "\n",
        "        context += \"--- END CONTEXT ---\\n\"\n",
        "        return context\n",
        "\n",
        "    def _generate_chapter_opener(self, chapter_num, current_chapter_plan):\n",
        "        \"\"\" Generates chapter title line and opening paragraph(s) focusing on smooth transition. \"\"\"\n",
        "        chapter_title_line = f\"Chapter {chapter_num} - {current_chapter_plan.get('title', 'Untitled')}\"\n",
        "\n",
        "        if chapter_num == 1:\n",
        "            # For Chapter 1, the \"opener\" is just the title, the first scene prompt handles the actual start.\n",
        "            # However, we can generate a compelling initial paragraph here based on the premise.\n",
        "            print(\"  Generating introductory paragraph for Chapter 1...\")\n",
        "            system_prompt = f\"You are a novelist in the style of {self.author_style}, skilled at crafting compelling beginnings that immediately immerse the reader in the world and introduce the protagonist.\"\n",
        "            prompt = f\"\"\"\n",
        "Based on the novel's premise, genre, world, and protagonist, write the compelling OPENING PARAGRAPH (approx 75-150 words) for Chapter 1.\n",
        "This paragraph should:\n",
        "1. Establish the initial setting and atmosphere ({self.world_details.get('name','N/A')}, {self.world_details.get('atmosphere','N/A')}).\n",
        "2. Introduce the protagonist ({list(self.characters.keys())[0] if self.characters else 'the main character'}) in their 'normal world' before the inciting incident. Hint at their core traits or situation.\n",
        "3. Set the tone ({self.genre}, inspired by {self.author_style}).\n",
        "4. Use evocative language and sensory details.\n",
        "5. Draw the reader in immediately.\n",
        "\n",
        "Novel Subject: {self.subject}\n",
        "Protagonist Hint: {json.dumps(list(self.characters.values())[0], indent=2) if self.characters else 'N/A'}\n",
        "\n",
        "Opening Paragraph for Chapter 1:\n",
        "\"\"\"\n",
        "            opener_text = self._openrouter_generate(prompt, system_prompt, temperature=0.7)\n",
        "            if \"[OPENROUTER\" in opener_text: opener_text = \"[Error generating Chapter 1 opener]\"\n",
        "            return f\"{chapter_title_line}\\n\\n{opener_text.strip()}\\n\\n\"\n",
        "\n",
        "        # --- For Chapters 2+ ---\n",
        "        print(f\"  Generating opener for Chapter {chapter_num}...\")\n",
        "        prev_chap_num = chapter_num - 1\n",
        "        prev_continuity = self.chapter_continuity_data.get(prev_chap_num, {})\n",
        "        prev_plan = self.chapter_plans.get(prev_chap_num, {})\n",
        "\n",
        "        # Extract key character states at the end of the PREVIOUS chapter for the prompt\n",
        "        prev_char_states_summary = \"\"\n",
        "        if prev_continuity.get(\"character_updates_text\"):\n",
        "            # Try to extract just the final states for the prompt\n",
        "            updates_text = prev_continuity[\"character_updates_text\"]\n",
        "            prev_char_states_summary = \"\\n\".join(line for line in updates_text.split('\\n') if 'STATUS CHANGE:' not in line and 'KEY DEVELOPMENT/ACTION:' not in line and 'RELATIONSHIP CHANGES:' not in line and 'NEW KNOWLEDGE:' not in line) # Keep Name, Loc, Emotion\n",
        "            if not prev_char_states_summary: # Fallback\n",
        "                 prev_char_states_summary = \"Refer to previous chapter's continuity data for detailed character states.\"\n",
        "        else:\n",
        "             prev_char_states_summary = \"Character states from previous chapter not available.\"\n",
        "\n",
        "\n",
        "        system_prompt = f\"You are a novelist in the style of {self.author_style}, ensuring seamless transitions. Write ONLY the opening paragraph(s) for the specified chapter.\"\n",
        "        prompt = f\"\"\"\n",
        "CONTEXT FOR CHAPTER {chapter_num} OPENING:\n",
        "- End of Chapter {prev_chap_num} (\"{prev_plan.get('title', 'Untitled')}\") Summary Snippet: ...{prev_continuity.get('summary', 'N/A')[-1000:]}\n",
        "- Actual Ending Hook Text from Ch {prev_chap_num}: \"{prev_continuity.get('ending_hook_text', 'The story continued.')}\"\n",
        "- Timeline at End of Ch {prev_chap_num}: {prev_continuity.get('timeline_end', 'Unknown')}\n",
        "- Character States at End of Ch {prev_chap_num} (Location/Emotion): {prev_char_states_summary}\n",
        "- Flow Analysis into Ch {chapter_num}: {prev_continuity.get('flow_analysis_from_previous', 'N/A')}\n",
        "\n",
        "PLAN FOR CURRENT Chapter {chapter_num} (\"{current_chapter_plan.get('title', 'Untitled')}\"):\n",
        "- Goal: {current_chapter_plan.get('goal', 'N/A')}\n",
        "- First Scene Hint: {current_chapter_plan.get('scenes', ['N/A'])[0]}\n",
        "- Timeline & Pacing: {current_chapter_plan.get('timeline_pacing', 'N/A')}\n",
        "\n",
        "TASK: Write 1-2 compelling opening paragraphs (approx 100-200 words) for Chapter {chapter_num}. These MUST:\n",
        "1. Directly connect to the PREVIOUS chapter's ending hook/state (\"{prev_continuity.get('ending_hook_text', '')}\").\n",
        "2. Smoothly establish the time jump (if any, guided by timeline info) and the setting/situation for the FIRST scene of Chapter {chapter_num}.\n",
        "3. Re-center the reader on the relevant character(s) and their immediate emotional/physical state, consistent with the end of Chapter {prev_chap_num}.\n",
        "4. Reflect the flow analysis - if flow was weak, make this transition stronger.\n",
        "5. Use {self.author_style} voice and {self.genre} tone. Show, don't just summarize.\n",
        "\n",
        "Generate ONLY the opening paragraph(s). Do NOT include the chapter title line.\n",
        "Opening Paragraphs for Chapter {chapter_num}:\n",
        "\"\"\"\n",
        "        opener_text = self._openrouter_generate(prompt, system_prompt, temperature=0.68)\n",
        "        if \"[OPENROUTER\" in opener_text: opener_text = f\"[Error generating opener for Chapter {chapter_num}]\"\n",
        "\n",
        "        # Ensure double newline after opener\n",
        "        return f\"{chapter_title_line}\\n\\n{opener_text.strip()}\\n\\n\"\n",
        "\n",
        "    def _generate_scene_prose(self, chapter_num, scene_index, scene_description, current_chapter_plan, continuity_context, previous_prose_in_chapter):\n",
        "        \"\"\" Generates prose for a single scene, enhanced for flow and character depth. \"\"\"\n",
        "        system_prompt = f\"You are a celebrated novelist writing a {self.genre} novel in the style of {self.author_style}. Your prose is vivid, emotionally resonant, drives the plot, 'shows' character development, and flows logically from the previous text.\"\n",
        "\n",
        "        motif_to_weave = \"N/A\"\n",
        "        if self.themes_motifs.get(\"motifs\"):\n",
        "            motif_index = (chapter_num * 10 + scene_index) % len(self.themes_motifs[\"motifs\"]) # Simple distribution\n",
        "            motif_to_weave = self.themes_motifs[\"motifs\"][motif_index]\n",
        "\n",
        "        # Extract planned details for THIS scene from the description string\n",
        "        scene_location = re.search(r\"Location:\\s*(.*?)(?:\\.\\s*Characters|,\\s*Characters|$)\", scene_description, re.IGNORECASE)\n",
        "        scene_chars = re.search(r\"Characters Involved:\\s*(.*?)(?:\\.\\s*Key Revelation|,\\s*Key Outcome|$)\", scene_description, re.IGNORECASE)\n",
        "        scene_outcome = re.search(r\"Key Revelation/Turning Point/Outcome:\\s*(.*)\", scene_description, re.IGNORECASE)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "{continuity_context}\n",
        "\n",
        "Current Chapter Plan ({chapter_num} - \"{current_chapter_plan.get('title', 'Untitled')}\"):\n",
        "- Chapter Goal: {current_chapter_plan.get('goal', 'N/A')}\n",
        "- Character Development Focus for Chapter: {current_chapter_plan.get('character_development', 'N/A')}\n",
        "- Planned Emotional Tone (End of Chapter): {current_chapter_plan.get('emotional_tone_end', 'N/A')}\n",
        "- Planned Timeline & Pacing for Chapter: {current_chapter_plan.get('timeline_pacing', 'N/A')}\n",
        "\n",
        "Prose Written SO FAR in Chapter {chapter_num} (immediately preceding this scene):\n",
        "---\n",
        "...{previous_prose_in_chapter[-2500:]}\n",
        "---\n",
        "\n",
        "YOUR TASK: Write engaging narrative prose for THE FOLLOWING SCENE ONLY (Scene {scene_index + 1}).\n",
        "Scene Description from Plan: \"{scene_description}\"\n",
        "- Planned Location: {scene_location.group(1).strip() if scene_location else 'See description'}\n",
        "- Planned Characters: {scene_chars.group(1).strip() if scene_chars else 'See description'}\n",
        "- Planned Outcome/Revelation: {scene_outcome.group(1).strip() if scene_outcome else 'See description'}\n",
        "\n",
        "INSTRUCTIONS FOR THIS SCENE'S PROSE (approx 400-800 words):\n",
        "1.  **Narrative Drive:** Execute the planned action/dialogue/revelation of THIS scene description effectively.\n",
        "2.  **Seamless Flow:** Ensure this scene begins logically and smoothly from the end of the PREVIOUS prose snippet provided above.\n",
        "3.  **Style & Tone:** Maintain {self.author_style}'s voice and the chapter's intended {self.genre} tone/pacing.\n",
        "4.  **Show, Don't Tell:** Crucial. Demonstrate character emotions via actions, body language, dialogue tone, internal thoughts. Reveal plot points through events/interactions, not exposition dumps.\n",
        "5.  **Character Depth & Consistency:** Portray characters acting/thinking according to their established profiles, motivations, flaws, and current emotional state (from context). Show their reactions to events in this scene. If development is planned for them in this chapter, hint at or show that change occurring *because* of this scene's events.\n",
        "6.  **Sensory Immersion:** Use vivid sensory details (sight, sound, smell, touch) relevant to the scene's location ({scene_location.group(1).strip() if scene_location else 'planned location'}) and events.\n",
        "7.  **Dialogue:** Make dialogue sound natural, character-specific, and serve a purpose (reveal character, advance plot, build tension). Use standard dialogue formatting.\n",
        "8.  **Motif Integration (Subtle):** If appropriate and natural, weave in the motif: '{motif_to_weave}'. Do not force it.\n",
        "9.  **Output:** Generate ONLY the narrative paragraphs for THIS SCENE. Do not repeat scene numbers/descriptions. Ensure clear paragraph breaks.\n",
        "\n",
        "Begin Scene {scene_index + 1} prose now:\n",
        "\"\"\"\n",
        "        scene_prose = self._openrouter_generate(prompt, system_prompt, temperature=0.72, top_p=0.92)\n",
        "        # Basic cleanup of potential AI preamble\n",
        "        scene_prose = re.sub(r\"^(Okay, here's the prose for Scene \\d+:|Scene \\d+ Prose:|Here is the scene:)\\s*\", \"\", scene_prose, flags=re.IGNORECASE | re.MULTILINE).strip()\n",
        "        return scene_prose\n",
        "\n",
        "    def _analyze_intra_chapter_flow(self, chapter_num, full_chapter_content_before_hook):\n",
        "        \"\"\" Analyzes the flow and coherence *within* a single generated chapter. \"\"\"\n",
        "        print(f\"  Analyzing internal flow for Chapter {chapter_num}...\")\n",
        "        current_chapter_plan = self.chapter_plans.get(chapter_num, {})\n",
        "        if not current_chapter_plan:\n",
        "            return \"Intra-chapter flow analysis skipped: No plan found.\"\n",
        "\n",
        "        system_prompt = \"You are a literary editor evaluating the internal coherence, pacing, and character consistency within a single chapter draft.\"\n",
        "        prompt = f\"\"\"\n",
        "CONTEXT:\n",
        "- Chapter Number: {chapter_num}\n",
        "- Title: \"{current_chapter_plan.get('title', 'Untitled')}\"\n",
        "- Genre: {self.genre}\n",
        "- Author Style: {self.author_style}\n",
        "- Planned Chapter Goal: {current_chapter_plan.get('goal', 'N/A')}\n",
        "- Planned Scene Breakdown: {json.dumps(current_chapter_plan.get('scenes',[]))}\n",
        "- Planned Character Development Focus: {current_chapter_plan.get('character_development', 'N/A')}\n",
        "- Planned Pacing: {current_chapter_plan.get('timeline_pacing', 'N/A')}\n",
        "\n",
        "CHAPTER DRAFT CONTENT (Opener + All Scenes, Before Final Hook):\n",
        "---\n",
        "{full_chapter_content_before_hook}\n",
        "---\n",
        "\n",
        "TASK: Evaluate the INTERNAL flow and coherence of this chapter draft. Provide a brief (2-3 paragraph) analysis covering:\n",
        "1.  **Scene Transitions:** How smooth and logical are the transitions *between* the scenes within this chapter? Are there abrupt jumps in time, location, or focus?\n",
        "2.  **Pacing Consistency:** Does the chapter's pacing match the plan? Does it build appropriately towards the chapter's goal or climax? Are there parts that drag or feel rushed relative to the scene descriptions?\n",
        "3.  **Character Arc Progression:** Do the characters' actions, reactions, and emotional states evolve *believably* throughout the chapter based on the events? Is the planned character development evident and well-integrated?\n",
        "4.  **Narrative Cohesion:** Does the chapter feel like a unified whole working towards its goal, or more like a collection of disconnected scenes?\n",
        "5.  **Overall Readability:** Does the chapter flow well for the reader?\n",
        "\n",
        "Focus on identifying specific areas (if any) where the internal flow, pacing, or consistency could be stronger. Be constructive.\n",
        "\n",
        "Internal Flow Analysis for Chapter {chapter_num}:\n",
        "\"\"\"\n",
        "        analysis_text = self._openrouter_generate(prompt, system_prompt, temperature=0.55)\n",
        "        print(f\"    Internal Flow Analysis Result: {analysis_text[:200]}...\")\n",
        "\n",
        "        # Store the analysis\n",
        "        if chapter_num not in self.chapter_continuity_data: self.chapter_continuity_data[chapter_num] = {}\n",
        "        self.chapter_continuity_data[chapter_num][\"intra_chapter_flow_analysis\"] = analysis_text\n",
        "        return analysis_text\n",
        "\n",
        "    def _analyze_inter_chapter_flow(self, previous_chapter_num, current_chapter_num, current_chapter_opening_text):\n",
        "        \"\"\" Analyzes flow BETWEEN chapters, enhanced prompt. \"\"\"\n",
        "        print(f\"  Analyzing flow from Chapter {previous_chapter_num} to Chapter {current_chapter_num}...\")\n",
        "        # Ensure necessary data exists\n",
        "        prev_continuity = self.chapter_continuity_data.get(previous_chapter_num)\n",
        "        prev_plan = self.chapter_plans.get(previous_chapter_num)\n",
        "        current_plan = self.chapter_plans.get(current_chapter_num)\n",
        "        if not prev_continuity or not prev_plan or not current_plan:\n",
        "             print(\"    Skipping inter-chapter flow analysis: Missing continuity/plan data.\")\n",
        "             analysis_text = \"Flow analysis skipped due to missing data.\"\n",
        "        else:\n",
        "            prev_summary = prev_continuity.get(\"summary\", \"N/A\")\n",
        "            prev_hook = prev_continuity.get(\"ending_hook_text\", \"N/A\")\n",
        "            prev_title = prev_plan.get(\"title\", \"Untitled\")\n",
        "            current_title = current_plan.get(\"title\", \"Untitled\")\n",
        "            current_goal = current_plan.get(\"goal\", \"N/A\")\n",
        "            # Extract just the opener text, removing title line\n",
        "            opening_paragraphs_only = \"\\n\".join(current_chapter_opening_text.split('\\n\\n')[1:]).strip()\n",
        "\n",
        "\n",
        "            system_prompt = \"You are an expert literary editor analyzing narrative coherence and flow between chapters. Focus on clarity, consistency, and reader engagement.\"\n",
        "            prompt = f\"\"\"\n",
        "Analyze the transition effectiveness from the end of Chapter {previous_chapter_num} (\"{prev_title}\") to the beginning of Chapter {current_chapter_num} (\"{current_title}\").\n",
        "\n",
        "CONTEXT:\n",
        "End of Chapter {previous_chapter_num} (\"{prev_title}\"):\n",
        "- Final Hook/Transition Text: \"{prev_hook}\"\n",
        "- Summary Snippet: ...{prev_summary[-1000:]}\n",
        "- Key Character States at End (Location/Emotion - from continuity): {json.dumps({name: {'loc': data.get('current_location'), 'emo': data.get('emotional_state')} for name, data in self.characters.items() if data.get('first_appearance_chapter', 0) <= previous_chapter_num and data.get('first_appearance_chapter', 0) > 0}, indent=2)}\n",
        "- Planned Connection from Ch {previous_chapter_num}: \"{prev_plan.get('connection_to_next', 'N/A')}\"\n",
        "\n",
        "Beginning of Chapter {current_chapter_num} (\"{current_title}\"):\n",
        "- Chapter Goal: {current_goal}\n",
        "- Actual Opening Paragraph(s): \"{opening_paragraphs_only}\"\n",
        "\n",
        "EVALUATION (Provide 2-3 paragraphs):\n",
        "1.  **Hook Follow-Through:** How effectively does the opening of Chapter {current_chapter_num} resolve, address, or build upon the specific ending hook/state of Chapter {previous_chapter_num}? Is the connection explicit or implicit, and is it clear?\n",
        "2.  **Continuity Check:** Are there any jarring inconsistencies in character location, emotional state, knowledge, or the overall situation between the end of the previous chapter and the start of the current one?\n",
        "3.  **Pacing/Tone Shift:** How well is the transition in pacing and emotional tone handled? Does it feel natural or abrupt? Does it match the intended shift (if any)?\n",
        "4.  **Reader Orientation:** Does the opening quickly and clearly orient the reader to the new time/place/focus of Chapter {current_chapter_num}?\n",
        "5.  **Overall Flow:** Assess the overall effectiveness. Does it pull the reader smoothly into the new chapter, or does it create confusion or require rereading? Suggest specific improvements if weaknesses are found (e.g., \"Could benefit from clarifying time jump,\" \"Character X's reaction seems inconsistent\").\n",
        "\n",
        "Inter-Chapter Flow Analysis:\n",
        "\"\"\"\n",
        "            analysis_text = self._openrouter_generate(prompt, system_prompt, temperature=0.5)\n",
        "            print(f\"    Inter-Chapter Flow Analysis Result: {analysis_text[:200]}...\")\n",
        "\n",
        "        # Store analysis regardless of success/failure to indicate it was attempted\n",
        "        if current_chapter_num not in self.chapter_continuity_data: self.chapter_continuity_data[current_chapter_num] = {}\n",
        "        self.chapter_continuity_data[current_chapter_num][\"flow_analysis_from_previous\"] = analysis_text\n",
        "        return analysis_text\n",
        "\n",
        "\n",
        "    def _update_chapter_continuity_data(self, chapter_num, full_chapter_content, is_final_pass_for_chapter=False):\n",
        "        \"\"\" Analyzes chapter to update continuity: summary, character states, timeline, emotion. Enhanced prompt. \"\"\"\n",
        "        print(f\"  Updating continuity data for Chapter {chapter_num} ({'final' if is_final_pass_for_chapter else 'interim'})...\")\n",
        "        entry = self.chapter_continuity_data.get(chapter_num, {}) # Get existing or new dict\n",
        "        current_chapter_plan = self.chapter_plans.get(chapter_num, {})\n",
        "        chapter_title = current_chapter_plan.get('title', 'Untitled')\n",
        "\n",
        "        # 1. Generate Summary\n",
        "        summary_system_prompt = \"You are a literary analyst specializing in precise chapter summarization for continuity tracking.\"\n",
        "        summary_prompt = f\"\"\"\n",
        "Create a detailed summary (200-300 words) of Chapter {chapter_num} (\"{chapter_title}\"). Focus ONLY on information crucial for maintaining continuity into the next chapter. Capture:\n",
        "- ALL key plot events and their immediate outcomes.\n",
        "- ALL characters present, their significant actions, decisions, dialogue highlights, and changes in status/knowledge/relationships.\n",
        "- Any new items, locations, or minor characters introduced.\n",
        "- The state of the central conflict(s) at the chapter's end.\n",
        "- The final emotional tone and lingering questions.\n",
        "\n",
        "CHAPTER {chapter_num} CONTENT:\n",
        "---\n",
        "{full_chapter_content}\n",
        "---\n",
        "Detailed Continuity Summary:\n",
        "\"\"\"\n",
        "        entry[\"summary\"] = self._openrouter_generate(summary_prompt, summary_system_prompt, temperature=0.5)\n",
        "        if \"[OPENROUTER\" in entry[\"summary\"]: print(f\"    Warning: Error generating summary for Ch {chapter_num}.\")\n",
        "\n",
        "        # Only perform detailed character/timeline updates on the FINAL pass for the chapter\n",
        "        if is_final_pass_for_chapter:\n",
        "            # 2. Update Character States (More rigorous prompt)\n",
        "            # Determine characters likely present/important in the chapter\n",
        "            active_chars_in_chapter = set()\n",
        "            # From plan scenes\n",
        "            for scene_desc in current_chapter_plan.get(\"scenes\", []):\n",
        "                 char_involved_match = re.search(r\"Characters.*:\\s*(.*?)(?:\\.\\s*Key|,\\s*Key|$)\", scene_desc, re.IGNORECASE)\n",
        "                 if char_involved_match:\n",
        "                     names_str = char_involved_match.group(1)\n",
        "                     potential_names = re.split(r'[,\\s]+and\\s+|\\s*,\\s*|[,\\s]+with\\s+', names_str)\n",
        "                     for name in potential_names:\n",
        "                          clean_name = name.strip().rstrip('.').strip()\n",
        "                          if clean_name and clean_name in self.characters:\n",
        "                              active_chars_in_chapter.add(clean_name)\n",
        "            # From plan development focus\n",
        "            char_dev_focus = current_chapter_plan.get(\"character_development\", \"\")\n",
        "            for char_name in self.characters.keys():\n",
        "                if re.search(r'\\b' + re.escape(char_name) + r'\\b', char_dev_focus, re.IGNORECASE):\n",
        "                     active_chars_in_chapter.add(char_name)\n",
        "            # From chapter text (basic check)\n",
        "            for char_name in self.characters.keys():\n",
        "                if re.search(r'\\b' + re.escape(char_name) + r'\\b', full_chapter_content):\n",
        "                    active_chars_in_chapter.add(char_name)\n",
        "\n",
        "            active_chars_list = list(active_chars_in_chapter) if active_chars_in_chapter else list(self.characters.keys()) # Fallback to all if none found\n",
        "\n",
        "            char_update_system_prompt = \"You are a meticulous narrative continuity tracker. Update character states based *only* on the events within the provided chapter text.\"\n",
        "            char_update_prompt = f\"\"\"\n",
        "Analyze the FULL content of Chapter {chapter_num} (\"{chapter_title}\") below to update character states for continuity.\n",
        "CHAPTER CONTENT:\n",
        "---\n",
        "{full_chapter_content}\n",
        "---\n",
        "Previous Known States (Start of Chapter):\n",
        "{json.dumps({name: {'status': data['current_status'], 'location': data['current_location'], 'emotion': data['emotional_state']} for name, data in self.characters.items()}, indent=2)}\n",
        "\n",
        "TASK: For EACH character listed below who appeared or was significantly impacted IN THIS CHAPTER, provide precise updates based ONLY on the chapter text. Use the specified format. If no change for a field, state \"No significant change.\" If character inactive, note that.\n",
        "\n",
        "Characters to Update: {', '.join(active_chars_list)}\n",
        "\n",
        "Format for EACH updated character:\n",
        "CHARACTER NAME: [Name]\n",
        "- STATUS/PHYSICAL_STATE: [e.g., \"Unharmed,\" \"Slightly injured (cut arm),\" \"Exhausted,\" \"Captured.\"]\n",
        "- LOCATION_AT_CHAPTER_END: [Specific location name.]\n",
        "- EMOTIONAL_STATE_AT_CHAPTER_END: [Dominant emotion based on final scenes/thoughts. e.g., \"Relieved but anxious,\" \"Furious,\" \"Conflicted,\" \"Resigned.\"]\n",
        "- KEY_DEVELOPMENT_OR_ACTION: [Most significant action, decision, learning, or change in perspective *within this chapter*.]\n",
        "- RELATIONSHIP_CHANGES: [Note specific changes with other characters. e.g., \"Strengthened bond with Y after rescue,\" \"Conflict with Z worsened.\"]\n",
        "- NEW_KNOWLEDGE: [Any critical new information, secrets, or clues learned *in this chapter*.]\n",
        "\"\"\"\n",
        "            character_updates_text = self._openrouter_generate(char_update_prompt, char_update_system_prompt, temperature=0.55)\n",
        "            entry[\"character_updates_text\"] = character_updates_text # Store the raw text for reference\n",
        "\n",
        "            # Parse updates and apply to self.characters\n",
        "            current_char_name_update = None\n",
        "            parsed_updates_for_log = {}\n",
        "            for line in character_updates_text.split('\\n'):\n",
        "                 line = line.strip()\n",
        "                 name_match = re.match(r\"CHARACTER NAME:\\s*(.*)\", line, re.IGNORECASE)\n",
        "                 if name_match:\n",
        "                      # Save previous character's log before starting new one\n",
        "                      if current_char_name_update and parsed_updates_for_log and current_char_name_update in self.characters:\n",
        "                           self.characters[current_char_name_update][\"development_log\"].append(\n",
        "                               {\"chapter\": chapter_num, \"summary\": \"Updates from chapter analysis\", **parsed_updates_for_log}\n",
        "                           )\n",
        "                      # Start new character\n",
        "                      current_char_name_update = name_match.group(1).strip()\n",
        "                      parsed_updates_for_log = {} # Reset log data\n",
        "                      # Validate name and set first appearance\n",
        "                      if current_char_name_update not in self.characters:\n",
        "                           print(f\"    Warning: Update received for unknown character '{current_char_name_update}' in Ch {chapter_num}.\")\n",
        "                           current_char_name_update = None # Ignore updates for this unknown char\n",
        "                      elif self.characters[current_char_name_update].get(\"first_appearance_chapter\", 0) == 0:\n",
        "                           self.characters[current_char_name_update][\"first_appearance_chapter\"] = chapter_num\n",
        "                      continue\n",
        "\n",
        "                 if current_char_name_update: # If we are tracking a valid character\n",
        "                      # Define keys and corresponding character object fields\n",
        "                      update_map = {\n",
        "                         \"STATUS/PHYSICAL_STATE\": \"current_status\",\n",
        "                         \"LOCATION_AT_CHAPTER_END\": \"current_location\",\n",
        "                         \"EMOTIONAL_STATE_AT_CHAPTER_END\": \"emotional_state\",\n",
        "                         \"KEY_DEVELOPMENT_OR_ACTION\": \"development\", # Store in log only\n",
        "                         \"RELATIONSHIP_CHANGES\": \"relationships\", # Store in log only\n",
        "                         \"NEW_KNOWLEDGE\": \"knowledge\" # Add to list\n",
        "                      }\n",
        "                      found_match = False\n",
        "                      for key_phrase, field_name in update_map.items():\n",
        "                           # Match key phrase at start of line (allow bullet points)\n",
        "                           if re.match(r\"^(?:[-\\*•\\s]*)?\" + re.escape(key_phrase) + r\":\\s*\", line, re.IGNORECASE):\n",
        "                                value_part = re.split(\":\", line, 1)[1].strip()\n",
        "                                # Check if value indicates no change\n",
        "                                if value_part.lower() in [\"no change\", \"no significant change\", \"n/a\", \"none\", \"did not appear.\"]:\n",
        "                                     value_to_store = \"No change\"\n",
        "                                     value_to_apply = None # Don't update the main character state\n",
        "                                else:\n",
        "                                     value_to_store = value_part\n",
        "                                     value_to_apply = value_part\n",
        "\n",
        "                                # Update log data\n",
        "                                parsed_updates_for_log[field_name] = value_to_store\n",
        "\n",
        "                                # Update character object directly for state fields\n",
        "                                if value_to_apply is not None:\n",
        "                                     if field_name in [\"current_status\", \"current_location\", \"emotional_state\"]:\n",
        "                                         self.characters[current_char_name_update][field_name] = value_to_apply\n",
        "                                     elif field_name == \"knowledge\":\n",
        "                                          if value_to_apply not in self.characters[current_char_name_update][\"knowledge\"]:\n",
        "                                               self.characters[current_char_name_update][\"knowledge\"].append(value_to_apply)\n",
        "                                found_match = True\n",
        "                                break # Move to next line once a key is matched\n",
        "                      # If no specific key matched, potentially append to last development/action detail? (Handle with care)\n",
        "                      # else: print(f\"    Debug: Unmatched line in char update: {line}\")\n",
        "\n",
        "            # Save the last character's log entry after the loop\n",
        "            if current_char_name_update and parsed_updates_for_log and current_char_name_update in self.characters:\n",
        "                 self.characters[current_char_name_update][\"development_log\"].append(\n",
        "                     {\"chapter\": chapter_num, \"summary\": \"Updates from chapter analysis\", **parsed_updates_for_log}\n",
        "                 )\n",
        "            print(f\"    Character states updated based on Chapter {chapter_num}.\")\n",
        "\n",
        "\n",
        "            # 3. Update Timeline\n",
        "            timeline_system_prompt = \"You are a temporal analyst for narratives. Extract time information accurately.\"\n",
        "            timeline_prompt = f\"\"\"\n",
        "Analyze Chapter {chapter_num} (\"{chapter_title}\") for timeline information based ONLY on the text.\n",
        "CHAPTER CONTENT:\n",
        "---\n",
        "{full_chapter_content}\n",
        "---\n",
        "Determine:\n",
        "1.  APPROXIMATE TIME ELAPSED DURING THIS CHAPTER: [e.g., \"A single evening,\" \"Two days,\" \"Indeterminate.\"]\n",
        "2.  TIME OF DAY/DATE AT THE END OF THIS CHAPTER: [e.g., \"Just after midnight,\" \"Morning of the festival,\" \"Winter Solstice.\"]\n",
        "3.  ANY SPECIFIC TIME MARKERS MENTIONED: [List phrases like \"three hours passed,\" \"at sunset,\" \"when the bells tolled.\" Use \"None mentioned\" if applicable.]\n",
        "Reply ONLY in the format:\n",
        "ELAPSED: [answer]\n",
        "END_TIME: [answer]\n",
        "MARKERS: [answer]\n",
        "\"\"\"\n",
        "            timeline_text = self._openrouter_generate(timeline_prompt, timeline_system_prompt, temperature=0.4)\n",
        "\n",
        "            elapsed_match = re.search(r\"ELAPSED:\\s*(.*?)(?:\\n|$)\", timeline_text, re.IGNORECASE)\n",
        "            entry[\"timeline_elapsed\"] = elapsed_match.group(1).strip() if elapsed_match else \"N/A\"\n",
        "            end_time_match = re.search(r\"END_TIME:\\s*(.*?)(?:\\n|$)\", timeline_text, re.IGNORECASE)\n",
        "            entry[\"timeline_end\"] = end_time_match.group(1).strip() if end_time_match else \"N/A\"\n",
        "            markers_match = re.search(r\"MARKERS:\\s*(.*?)(?:\\n|$)\", timeline_text, re.IGNORECASE)\n",
        "            entry[\"timeline_markers\"] = markers_match.group(1).strip() if markers_match else \"N/A\"\n",
        "            print(f\"    Timeline updated for Chapter {chapter_num}.\")\n",
        "\n",
        "        # 4. Store Final Emotional Tone (from summary/plan) and Hook\n",
        "        entry[\"emotional_tone_end_achieved_in_summary\"] = self._extract_final_emotion(entry[\"summary\"]) # Helper to get emotion from summary\n",
        "        if \"ending_hook_text\" not in entry: # Ensure hook text exists, even if empty\n",
        "             entry[\"ending_hook_text\"] = \"N/A (Hook not generated or last chapter)\"\n",
        "\n",
        "\n",
        "        self.chapter_continuity_data[chapter_num] = entry # Save all updates\n",
        "\n",
        "    def _extract_final_emotion(self, summary_text):\n",
        "        \"\"\" Helper to guess final emotion from summary text \"\"\"\n",
        "        if not summary_text or \"[OPENROUTER\" in summary_text: return \"Unknown\"\n",
        "        # Look for keywords near the end of the summary\n",
        "        last_sentences = \". \".join(summary_text.split(\". \")[-3:]).lower() # Last few sentences\n",
        "        emotions = {\n",
        "            \"hopeful\": [\"hope\", \"optimism\", \"resolve\", \"possibility\"],\n",
        "            \"suspenseful\": [\"suspense\", \"tension\", \"uncertainty\", \"cliffhanger\", \"question\", \"danger\"],\n",
        "            \"dread\": [\"dread\", \"fear\", \"ominous\", \"foreboding\", \"doom\", \"threat\"],\n",
        "            \"sad\": [\"sadness\", \"grief\", \"loss\", \"melancholy\", \"despair\"],\n",
        "            \"relieved\": [\"relief\", \"safety\", \"calm\", \"respite\"],\n",
        "            \"conflicted\": [\"conflict\", \"doubt\", \"ambivalence\", \"torn\"],\n",
        "            \"determined\": [\"determined\", \"resolve\", \"focused\", \"ready\"],\n",
        "            \"anxious\": [\"anxiety\", \"worry\", \"nervousness\", \"apprehension\"],\n",
        "        }\n",
        "        found_emotions = []\n",
        "        for emotion, keywords in emotions.items():\n",
        "            if any(keyword in last_sentences for keyword in keywords):\n",
        "                found_emotions.append(emotion)\n",
        "\n",
        "        if len(found_emotions) == 1: return found_emotions[0].capitalize()\n",
        "        if len(found_emotions) > 1: return \"Mixed (\" + \", \".join(found_emotions) + \")\"\n",
        "        # Fallback: Check plan if available (less reliable for actual generated tone)\n",
        "        # planned_tone = self.chapter_plans.get(chapter_num, {}).get('emotional_tone_end', 'Neutral')\n",
        "        # return f\"Unknown (Plan: {planned_tone})\"\n",
        "        return \"Neutral/Unclear\"\n",
        "\n",
        "\n",
        "    def _generate_chapter_transition_hook(self, chapter_num, current_chapter_content, current_chapter_continuity):\n",
        "        \"\"\" Generates the transition hook, enhanced prompt. \"\"\"\n",
        "        if chapter_num >= self.num_chapters: return \"\"\n",
        "\n",
        "        next_chap_num = chapter_num + 1\n",
        "        next_chapter_plan = self.chapter_plans.get(next_chap_num)\n",
        "        if not next_chapter_plan:\n",
        "             print(f\"  Warning: No plan for Chapter {next_chap_num}. Using generic hook for Chapter {chapter_num}.\")\n",
        "             hook_text = \"\\n\\n(The consequences of these actions remained to be seen...)\"\n",
        "        else:\n",
        "            system_prompt = f\"You are a master storyteller ({self.author_style} style), crafting impactful chapter endings ({self.genre}) that create strong anticipation.\"\n",
        "            prompt = f\"\"\"\n",
        "CONTEXT FOR CHAPTER {chapter_num} ENDING HOOK:\n",
        "- End of Chapter {chapter_num} Summary: ...{current_chapter_continuity.get('summary', 'N/A')[-1000:]}\n",
        "- Final Emotional Tone (from Chapter {chapter_num}): {current_chapter_continuity.get('emotional_tone_end_achieved_in_summary', 'Neutral')}\n",
        "- Last ~500 characters of Chapter {chapter_num} (before this hook): \"{current_chapter_content[-500:]}\"\n",
        "- Key Character States (End of Ch {chapter_num}): {json.dumps({name: {'loc': data['current_location'], 'emo': data['emotional_state']} for name, data in self.characters.items()}, indent=2)}\n",
        "\n",
        "PLAN FOR NEXT Chapter {next_chap_num} (\"{next_chapter_plan.get('title', 'Untitled')}\"):\n",
        "- Next Chapter Goal: {next_chapter_plan.get('goal', 'N/A')}\n",
        "- Next Chapter Opening Scene Hint: {next_chapter_plan.get('scenes', ['N/A'])[0]}\n",
        "- Planned connection from Ch {chapter_num} to {next_chap_num}: \"{self.chapter_plans.get(chapter_num,{}).get('connection_to_next','N/A')}\"\n",
        "\n",
        "TASK: Write 1-2 compelling final paragraphs (75-175 words total) for Chapter {chapter_num}. This text MUST:\n",
        "1.  Provide immediate closure for the chapter's action while leaving key questions/tensions unresolved.\n",
        "2.  Directly set up the planned connection/hook for Chapter {next_chap_num}, creating specific anticipation for its opening events or core conflict.\n",
        "3.  Amplify or shift the final emotional tone effectively to make the reader NEED to turn the page.\n",
        "4.  Use evocative language consistent with {self.author_style} and {self.genre}. Avoid summarizing.\n",
        "5.  Be the *final text* of Chapter {chapter_num}.\n",
        "\n",
        "Final transition paragraph(s) for Chapter {chapter_num}:\n",
        "\"\"\"\n",
        "            hook_text = self._openrouter_generate(prompt, system_prompt, temperature=0.75)\n",
        "            if \"[OPENROUTER\" in hook_text: hook_text = \"\\n\\n[Error generating transition hook...]\"\n",
        "\n",
        "        # Store the generated hook text\n",
        "        if chapter_num in self.chapter_continuity_data:\n",
        "             self.chapter_continuity_data[chapter_num][\"ending_hook_text\"] = hook_text.strip()\n",
        "        else:\n",
        "             self.chapter_continuity_data[chapter_num] = {\"ending_hook_text\": hook_text.strip()}\n",
        "\n",
        "        return f\"\\n\\n{hook_text.strip()}\" # Add spacing before appending\n",
        "\n",
        "\n",
        "    def generate_novel_content(self):\n",
        "        \"\"\" Main loop to generate content, including intra-chapter flow checks. \"\"\"\n",
        "        print(\"\\n--- Generating Full Novel Content (Chapter by Chapter) ---\")\n",
        "        if not self.chapter_plans or self.num_chapters == 0:\n",
        "            print(\"ERROR: Cannot generate content - missing chapter plans or chapter count.\")\n",
        "            return False\n",
        "\n",
        "        generation_successful = True\n",
        "        for i in range(1, self.num_chapters + 1):\n",
        "            start_time_ch = time.time()\n",
        "            print(f\"\\n--- Generating Chapter {i} of {self.num_chapters} ---\")\n",
        "            current_chapter_plan = self.chapter_plans.get(i)\n",
        "            if not current_chapter_plan:\n",
        "                print(f\"ERROR: No plan found for Chapter {i}. Skipping.\")\n",
        "                self.generated_chapters_content[i] = f\"[ERROR: SKIPPED - No plan found for Chapter {i}]\"\n",
        "                self.chapter_continuity_data[i] = {\"summary\": \"Error: No plan.\", \"character_updates_text\": \"N/A\", \"timeline_end\": \"N/A\", \"emotional_tone_end_achieved_in_summary\": \"Error\", \"ending_hook_text\": \"N/A\", \"flow_analysis_from_previous\": \"N/A\", \"intra_chapter_flow_analysis\": \"N/A\"}\n",
        "                generation_successful = False\n",
        "                continue # Move to next chapter\n",
        "\n",
        "            # 1. Get Context\n",
        "            continuity_context = self._get_continuity_context_for_chapter(i)\n",
        "\n",
        "            # 2. Generate Opener (includes title line)\n",
        "            chapter_opener_text_with_title = self._generate_chapter_opener(i, current_chapter_plan)\n",
        "            if \"[OPENROUTER\" in chapter_opener_text_with_title:\n",
        "                 print(f\"ERROR: Failed to generate opener for Chapter {i}. Using fallback.\")\n",
        "                 chapter_opener_text_with_title = f\"Chapter {i} - {current_chapter_plan.get('title', 'Untitled')}\\n\\n[Error in opener generation. The chapter begins...]\\n\\n\"\n",
        "                 generation_successful = False # Mark potential issue\n",
        "\n",
        "            accumulated_prose_for_chapter = chapter_opener_text_with_title\n",
        "\n",
        "            # 3. Analyze Flow from Previous Chapter (using the generated opener)\n",
        "            if i > 1:\n",
        "                self._analyze_inter_chapter_flow(i - 1, i, chapter_opener_text_with_title)\n",
        "\n",
        "            # 4. Generate Scenes\n",
        "            scenes = current_chapter_plan.get(\"scenes\", [])\n",
        "            if not scenes:\n",
        "                print(f\"Warning: No scenes in plan for Chapter {i}. Chapter will be short.\")\n",
        "                accumulated_prose_for_chapter += \"\\n[Chapter plan provided no specific scenes.]\\n\"\n",
        "            else:\n",
        "                for scene_idx, scene_desc in enumerate(scenes):\n",
        "                    print(f\"  Generating Scene {scene_idx + 1}/{len(scenes)}: {scene_desc[:80]}...\")\n",
        "                    scene_specific_prose = self._generate_scene_prose(\n",
        "                        i, scene_idx, scene_desc, current_chapter_plan,\n",
        "                        continuity_context, accumulated_prose_for_chapter # Pass accumulated text\n",
        "                    )\n",
        "                    if \"[OPENROUTER\" in scene_specific_prose:\n",
        "                        print(f\"    ERROR generating scene {scene_idx+1}: {scene_specific_prose}\")\n",
        "                        accumulated_prose_for_chapter += f\"\\n\\n[Error generating scene: {scene_desc[:50]}...]\\n\\n\"\n",
        "                        generation_successful = False # Mark failure\n",
        "                    else:\n",
        "                         accumulated_prose_for_chapter += scene_specific_prose + \"\\n\\n\" # Append with spacing\n",
        "                    time.sleep(0.2) # Small pause between scene generations\n",
        "\n",
        "            # 5. Analyze Intra-Chapter Flow (using content before hook)\n",
        "            content_before_hook = accumulated_prose_for_chapter.strip()\n",
        "            self._analyze_intra_chapter_flow(i, content_before_hook)\n",
        "\n",
        "            # 6. Generate Transition Hook (if not last chapter)\n",
        "            final_hook_text = \"\"\n",
        "            if i < self.num_chapters:\n",
        "                print(f\"  Generating transition hook for Chapter {i}...\")\n",
        "                final_hook_text = self._generate_chapter_transition_hook(i, content_before_hook, self.chapter_continuity_data.get(i, {}))\n",
        "                if \"[OPENROUTER\" in final_hook_text:\n",
        "                     print(f\"    Warning: Error generating hook for Ch {i}.\")\n",
        "                     final_hook_text = \"\\n\\n[Error generating transition hook...]\"\n",
        "                     generation_successful = False\n",
        "            else:\n",
        "                print(f\"  Skipping hook generation (last chapter).\")\n",
        "\n",
        "\n",
        "            # 7. Finalize Chapter Content & Update Continuity\n",
        "            final_chapter_content = content_before_hook + final_hook_text # Add hook if generated\n",
        "            self.generated_chapters_content[i] = final_chapter_content.strip()\n",
        "            print(f\"  Chapter {i} ('{current_chapter_plan.get('title', 'Untitled')}') content generated (Length: ~{len(final_chapter_content)} chars).\")\n",
        "\n",
        "            # Update continuity data based on the *final* content (including hook)\n",
        "            self._update_chapter_continuity_data(i, self.generated_chapters_content[i], is_final_pass_for_chapter=True)\n",
        "\n",
        "            end_time_ch = time.time()\n",
        "            print(f\"--- Chapter {i} finished in {end_time_ch - start_time_ch:.2f} seconds ---\")\n",
        "\n",
        "            if i < self.num_chapters: print(\"Pausing briefly...\") ; time.sleep(0.5)\n",
        "\n",
        "        return generation_successful\n",
        "\n",
        "\n",
        "    # --- Transition Checking Phase (Optional but Recommended) ---\n",
        "    # This phase re-evaluates transitions AFTER all chapters are initially drafted.\n",
        "    def _check_and_improve_transition(self, prev_chapter_num, current_chapter_num):\n",
        "        \"\"\" Checks transition and *attempts* to improve the current chapter's opening if needed. \"\"\"\n",
        "        print(f\"\\n--- Checking transition from Chapter {prev_chapter_num} to {current_chapter_num} ---\")\n",
        "\n",
        "        prev_chapter_content = self.generated_chapters_content.get(prev_chapter_num)\n",
        "        current_chapter_content = self.generated_chapters_content.get(current_chapter_num)\n",
        "        prev_continuity = self.chapter_continuity_data.get(prev_chapter_num, {})\n",
        "\n",
        "        if not prev_chapter_content or not current_chapter_content:\n",
        "            print(\"  Skipping transition check: Missing content.\")\n",
        "            return\n",
        "\n",
        "        system_prompt = f\"You are a professional editor specializing in seamless narrative flow between chapters, maintaining the style of {self.author_style}.\"\n",
        "        prompt = f\"\"\"Analyze the transition between the end of Chapter {prev_chapter_num} and the beginning of Chapter {current_chapter_num}.\n",
        "\n",
        "END OF PREVIOUS CHAPTER ({prev_chapter_num}) - Final Paragraphs:\n",
        "---\n",
        "{prev_continuity.get('ending_hook_text', prev_chapter_content[-1000:])}\n",
        "---\n",
        "\n",
        "BEGINNING OF CURRENT CHAPTER ({current_chapter_num}) - Opening Paragraphs:\n",
        "---\n",
        "{\"\\n\\n\".join(current_chapter_content.split('\\n\\n')[1:4])} {# Get first few paras after title #}\n",
        "---\n",
        "\n",
        "EVALUATION: Is the transition smooth, logical, and engaging? Does the opening effectively pick up from the previous chapter's hook/state?\n",
        "\n",
        "RESPONSE:\n",
        "- If SMOOTH: Respond ONLY with the exact text: TRANSITION: SMOOTH\n",
        "- If NEEDS IMPROVEMENT: Respond with \"TRANSITION: REVISED\" followed by ONLY the improved opening paragraph(s) for Chapter {current_chapter_num} (approx 100-250 words). The revision MUST:\n",
        "    - Create a stronger, clearer link to the previous chapter's end.\n",
        "    - Maintain consistency (character state, plot, tone).\n",
        "    - Match the {self.author_style} voice.\n",
        "    - Avoid repeating info.\n",
        "    - Do NOT include the chapter title.\n",
        "\"\"\"\n",
        "        transition_check_result = self._openrouter_generate(prompt, system_prompt, temperature=0.6)\n",
        "\n",
        "        if \"[OPENROUTER\" in transition_check_result:\n",
        "            print(f\"  Error during transition check API call: {transition_check_result}\")\n",
        "        elif \"TRANSITION: REVISED\" in transition_check_result:\n",
        "            try:\n",
        "                revised_beginning = transition_check_result.split(\"TRANSITION: REVISED\", 1)[1].strip()\n",
        "                if revised_beginning:\n",
        "                    print(f\"  Transition needs improvement. Applying revised opening to Chapter {current_chapter_num}.\")\n",
        "                    # Find the original title line\n",
        "                    original_lines = current_chapter_content.split('\\n', 1)\n",
        "                    original_title_line = original_lines[0]\n",
        "                    body_after_title = original_lines[1] if len(original_lines) > 1 else \"\"\n",
        "\n",
        "                    # Heuristic: Replace the first content block(s) after the title line.\n",
        "                    # Split by double newline after the title part\n",
        "                    parts_after_title = body_after_title.lstrip().split('\\n\\n', 1) # Split only once after title\n",
        "                    original_rest_of_chapter = parts_after_title[1] if len(parts_after_title) > 1 else \"\"\n",
        "\n",
        "                    # Construct the improved chapter\n",
        "                    self.generated_chapters_content[current_chapter_num] = f\"{original_title_line}\\n\\n{revised_beginning}\\n\\n{original_rest_of_chapter}\".strip()\n",
        "                    print(f\"  Chapter {current_chapter_num} opening revised successfully.\")\n",
        "                else:\n",
        "                    print(\"  Transition check indicated revision needed, but no revised text provided.\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error applying revised transition for Chapter {current_chapter_num}: {e}\")\n",
        "        elif \"TRANSITION: SMOOTH\" in transition_check_result:\n",
        "            print(\"  Transition is smooth. No changes needed.\")\n",
        "        else:\n",
        "            print(f\"  Transition check response unclear: {transition_check_result[:200]}...\")\n",
        "\n",
        "    def _perform_final_transition_checks(self):\n",
        "        \"\"\" Loops through chapters to check and potentially improve transitions AFTER initial draft. \"\"\"\n",
        "        print(\"\\n--- Performing Final Pass: Checking Inter-Chapter Transitions ---\")\n",
        "        if len(self.generated_chapters_content) < 2:\n",
        "            print(\"  Skipping transition checks (less than 2 chapters generated).\")\n",
        "            return\n",
        "\n",
        "        for i in range(2, self.num_chapters + 1):\n",
        "            if i in self.generated_chapters_content and (i - 1) in self.generated_chapters_content:\n",
        "                self._check_and_improve_transition(i - 1, i)\n",
        "                time.sleep(0.5) # Brief pause\n",
        "            else:\n",
        "                print(f\"  Skipping transition check for Chapter {i} (missing adjacent chapter content).\")\n",
        "        print(\"--- Finished Final Transition Checks ---\")\n",
        "\n",
        "\n",
        "    # --- Phase 4: Compilation & Output Methods ---\n",
        "    def generate_novel_title(self):\n",
        "        \"\"\" Generates a compelling title, enhanced prompt. \"\"\"\n",
        "        print(\"\\n--- Generating Novel Title ---\")\n",
        "        # Check required elements exist\n",
        "        required_for_title = [self.subject, self.characters, self.themes_motifs, self.genre, self.author_style, self.world_details.get('name'), self.world_details.get('atmosphere')]\n",
        "        if not all(required_for_title):\n",
        "             self.novel_title = f\"A {self.genre.replace('/', ' ')} Story\"\n",
        "             print(f\"Warning: Missing foundational elements for good title generation. Using placeholder: {self.novel_title}\")\n",
        "             return\n",
        "\n",
        "        system_prompt = f\"You are a creative book title generator specializing in {self.genre}, reflecting the style of {self.author_style}.\"\n",
        "        prompt = f\"\"\"\n",
        "Generate ONE compelling, marketable, and genre-appropriate novel title based on the provided details. The title should be intriguing and hint at the core conflict or themes.\n",
        "\n",
        "- Novel Subject: {self.subject}\n",
        "- Genre: {self.genre}\n",
        "- Author Style Influence: {self.author_style}\n",
        "- Protagonist Role/Arc Snippet: {next((data.get('role','') + ': ' + data.get('arc_summary','') for data in self.characters.values() if data.get('role','').lower() == 'protagonist'), 'Protagonist drives the story')}\n",
        "- World: {self.world_details.get('name', 'N/A')} ({self.world_details.get('atmosphere', 'N/A')})\n",
        "- Core Themes: {', '.join(self.themes_motifs.get('themes', []))}\n",
        "- Key Motifs: {', '.join(self.themes_motifs.get('motifs', []))}\n",
        "\n",
        "Return ONLY the generated title. Avoid quotation marks or labels.\n",
        "Novel Title:\n",
        "\"\"\"\n",
        "        title_text = self._openrouter_generate(prompt, system_prompt, temperature=0.8)\n",
        "        if \"[OPENROUTER\" in title_text or not title_text.strip():\n",
        "            print(f\"ERROR generating title: {title_text}. Using placeholder.\")\n",
        "            main_char_name = list(self.characters.keys())[0] if self.characters else 'Adventure'\n",
        "            self.novel_title = f\"The {self.genre.replace('/', ' ')} of {main_char_name}\"\n",
        "        else:\n",
        "             # Cleanup potential prefixes/suffixes\n",
        "             title_text = re.sub(r'^(title|novel title):?\\s*', '', title_text, flags=re.IGNORECASE).strip()\n",
        "             self.novel_title = title_text.strip('\"\\'')\n",
        "        print(f\"Generated Novel Title: {self.novel_title}\")\n",
        "\n",
        "\n",
        "    def compile_and_save_novel(self):\n",
        "        \"\"\" Compiles content into .docx and saves metadata. \"\"\"\n",
        "        print(\"\\n--- Compiling and Saving Novel ---\")\n",
        "        if not self.generated_chapters_content:\n",
        "            print(\"ERROR: No chapter content to save.\")\n",
        "            return\n",
        "\n",
        "        # Ensure title is generated if not already\n",
        "        if self.novel_title == \"Untitled Novel\":\n",
        "            self.generate_novel_title()\n",
        "\n",
        "        doc = Document()\n",
        "        # Define styles (consider defining custom styles for more control)\n",
        "        try:\n",
        "            # Base 'Normal' style for body text\n",
        "            normal_style = doc.styles['Normal']\n",
        "            normal_style.font.name = 'Garamond' # Or another serif font like Times New Roman\n",
        "            normal_style.font.size = Pt(12)\n",
        "            normal_style.paragraph_format.line_spacing = 1.5 # Double spacing essentially\n",
        "            normal_style.paragraph_format.space_after = Pt(0) # No extra space after paragraphs\n",
        "            normal_style.paragraph_format.first_line_indent = Pt(36) # Standard 0.5 inch indent\n",
        "\n",
        "            # Title style\n",
        "            title_style = doc.styles['Title']\n",
        "            title_style.font.name = 'Garamond'\n",
        "            title_style.font.size = Pt(28)\n",
        "            # Ensure title paragraph format doesn't inherit indent etc.\n",
        "            title_style.paragraph_format.first_line_indent = None\n",
        "            title_style.paragraph_format.space_after = Pt(12)\n",
        "\n",
        "            # Heading 1 style for Chapter Titles\n",
        "            # Modify existing 'Heading 1'\n",
        "            heading1_style = doc.styles['Heading 1']\n",
        "            heading1_style.font.name = 'Garamond'\n",
        "            heading1_style.font.size = Pt(16)\n",
        "            heading1_style.font.bold = True\n",
        "            heading1_style.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "            heading1_style.paragraph_format.space_before = Pt(18)\n",
        "            heading1_style.paragraph_format.space_after = Pt(6)\n",
        "            heading1_style.paragraph_format.first_line_indent = None # Headings shouldn't be indented\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"Warning: Could not find default style '{e}'. Formatting may be inconsistent.\")\n",
        "\n",
        "        # Add Title Page elements\n",
        "        title_para = doc.add_paragraph(self.novel_title)\n",
        "        title_para.style = doc.styles['Title']\n",
        "        title_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "        author_para = doc.add_paragraph(f\"Inspired by the style of {self.author_style}\")\n",
        "        author_para.style = doc.styles['Normal']\n",
        "        author_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "        author_para.paragraph_format.first_line_indent = None # Center align needs no indent\n",
        "\n",
        "        genre_para = doc.add_paragraph(f\"Genre: {self.genre}\")\n",
        "        genre_para.style = doc.styles['Normal']\n",
        "        genre_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "        genre_para.paragraph_format.first_line_indent = None\n",
        "        genre_para.paragraph_format.space_after = Pt(24) # Add space before page break\n",
        "\n",
        "\n",
        "        doc.add_page_break()\n",
        "\n",
        "        # Add Chapters\n",
        "        for i in sorted(self.generated_chapters_content.keys()):\n",
        "            chapter_content = self.generated_chapters_content.get(i, f\"[ERROR: Content for Chapter {i} missing]\")\n",
        "            paragraphs = chapter_content.split('\\n\\n') # Split by double newline\n",
        "\n",
        "            if paragraphs:\n",
        "                # Process heading (first paragraph block)\n",
        "                ch_title_line_full = paragraphs[0].strip()\n",
        "                # Try to extract just the title part for the main heading\n",
        "                title_match = re.match(r\"Chapter\\s*\\d+\\s*[-:]\\s*(.*)\", ch_title_line_full, re.IGNORECASE)\n",
        "                heading_text = title_match.group(1).strip() if title_match and title_match.group(1).strip() else f\"Chapter {i}\"\n",
        "\n",
        "                # Add the main heading\n",
        "                ch_heading = doc.add_paragraph(heading_text)\n",
        "                ch_heading.style = doc.styles['Heading 1']\n",
        "                # Alignment is set in style definition now\n",
        "\n",
        "                # Add \"Chapter X\" subheading if needed (optional, stylistic)\n",
        "                # if not heading_text.lower().startswith(\"chapter\"):\n",
        "                #     sub_heading = doc.add_paragraph(f\"Chapter {i}\")\n",
        "                #     sub_heading.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "                #     # Apply a less prominent style if desired\n",
        "\n",
        "                # Add body paragraphs\n",
        "                for para_block in paragraphs[1:]:\n",
        "                    if para_block.strip():\n",
        "                        p = doc.add_paragraph(para_block.strip())\n",
        "                        p.style = doc.styles['Normal']\n",
        "            else: # Handle case where chapter content might not have double newlines\n",
        "                 doc.add_paragraph(f\"Chapter {i}\", style=doc.styles['Heading 1'])\n",
        "                 doc.add_paragraph(chapter_content.strip(), style=doc.styles['Normal'])\n",
        "\n",
        "            if i < self.num_chapters:\n",
        "                doc.add_page_break()\n",
        "\n",
        "        # Save Document\n",
        "        safe_title = re.sub(r'[^\\w\\s-]', '', self.novel_title).strip().replace(' ', '_')\n",
        "        safe_genre = self.genre.replace('/','-').replace(' ','')\n",
        "        filename = f\"{safe_title[:50]}_Novel_{safe_genre}.docx\"\n",
        "        filepath = os.path.join(OUTPUT_DIR, filename)\n",
        "        try:\n",
        "            doc.save(filepath)\n",
        "            print(f\"Novel successfully saved to: {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR saving .docx file: {e}\")\n",
        "\n",
        "        # Save Metadata\n",
        "        self._save_metadata(safe_title)\n",
        "\n",
        "\n",
        "    def _save_metadata(self, safe_title_prefix):\n",
        "        \"\"\" Saves detailed metadata to a JSON file. \"\"\"\n",
        "        print(\"Saving metadata...\")\n",
        "        # Helper for JSON serialization\n",
        "        def serialize_for_json(obj):\n",
        "            if isinstance(obj, dict): return {k: serialize_for_json(v) for k, v in obj.items()}\n",
        "            if isinstance(obj, list): return [serialize_for_json(i) for i in obj]\n",
        "            if isinstance(obj, (int, float, str, bool, type(None))): return obj\n",
        "            return str(obj) # Fallback for other types\n",
        "\n",
        "        metadata = {\n",
        "            \"generation_info\": {\n",
        "                \"model_used\": OPENROUTER_MODEL,\n",
        "                \"api_provider\": \"OpenRouter\",\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S %Z\"),\n",
        "                \"app_title\": APP_TITLE,\n",
        "            },\n",
        "            \"novel_details\": {\n",
        "                \"generated_title\": self.novel_title,\n",
        "                \"subject_premise\": self.subject,\n",
        "                \"author_style_inspiration\": self.author_style,\n",
        "                \"genre\": self.genre,\n",
        "                \"num_chapters_determined\": self.num_chapters,\n",
        "                \"num_chapters_generated_content\": len(self.generated_chapters_content),\n",
        "            },\n",
        "            \"input_context\": {\n",
        "                \"resume_provided\": bool(self.resume_content),\n",
        "                # \"resume_content_snippet\": (self.resume_content[:1000] + \"...\") if self.resume_content else \"N/A\",\n",
        "            },\n",
        "            \"foundational_elements\": {\n",
        "                \"characters_initial\": serialize_for_json(self.characters), # Save initial state if needed, or just final below\n",
        "                \"world_details\": serialize_for_json(self.world_details),\n",
        "                \"themes_motifs\": serialize_for_json(self.themes_motifs),\n",
        "                \"plot_outline\": self.plot_outline,\n",
        "            },\n",
        "            \"planning_and_continuity\": {\n",
        "                \"chapter_plans\": serialize_for_json(self.chapter_plans),\n",
        "                \"chapter_continuity_data\": serialize_for_json(self.chapter_continuity_data), # Includes summaries, flow analyses, etc.\n",
        "            },\n",
        "            \"final_character_states\": serialize_for_json(self.characters) # Final state after all chapters\n",
        "        }\n",
        "\n",
        "        meta_filename = f\"{safe_title_prefix[:50]}_Novel_METADATA.json\"\n",
        "        meta_filepath = os.path.join(OUTPUT_DIR, meta_filename)\n",
        "        try:\n",
        "            with open(meta_filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"Metadata saved to: {meta_filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR saving metadata JSON: {e}\")\n",
        "\n",
        "\n",
        "    def orchestrate_generation(self):\n",
        "        \"\"\" Main public method to run the entire pipeline with flow checks. \"\"\"\n",
        "        start_time = time.time()\n",
        "        print(\"--- Starting Novel Generation Pipeline (OpenRouter) ---\")\n",
        "\n",
        "        # Phase 1: Foundation\n",
        "        if not self.generate_foundational_elements():\n",
        "            print(\"\\nPipeline Halting: Failed during foundational element generation.\")\n",
        "            return\n",
        "\n",
        "        # Phase 2: Detailed Planning\n",
        "        if not self.generate_detailed_chapter_plans():\n",
        "            print(\"\\nPipeline Halting: Failed during detailed chapter planning.\")\n",
        "            return\n",
        "\n",
        "        # Phase 3: Content Generation (includes intra-chapter flow analysis)\n",
        "        if not self.generate_novel_content():\n",
        "            print(\"\\nPipeline Warning: Errors occurred during chapter content generation. Proceeding to save partial content.\")\n",
        "            # Decide if you want to halt entirely or save what was generated\n",
        "            # return # Uncomment to halt completely on content gen error\n",
        "\n",
        "        # Phase 3.5: Final Inter-Chapter Transition Checks (Optional but recommended)\n",
        "        self._perform_final_transition_checks()\n",
        "\n",
        "        # Phase 4: Compilation and Saving\n",
        "        self.compile_and_save_novel() # Includes final title generation\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_time_minutes = (end_time - start_time) / 60\n",
        "        print(f\"\\n--- Novel Generation Pipeline Finished ---\")\n",
        "        print(f\"Total time taken: {total_time_minutes:.2f} minutes.\")\n",
        "\n",
        "\n",
        "# --- Utility Functions (Keep as is) ---\n",
        "def get_user_input_multiline(prompt_message):\n",
        "    # [Keep existing get_user_input_multiline function]\n",
        "    print(prompt_message + \" (Type 'ENDINPUT' on a new line when done, or just press Enter if input is short):\")\n",
        "    lines = []\n",
        "    first_line = input()\n",
        "    if not first_line.strip() and not lines:\n",
        "        return first_line\n",
        "    if first_line.strip().upper() == 'ENDINPUT':\n",
        "        return \"\"\n",
        "    lines.append(first_line)\n",
        "    if len(first_line) < 70 and \"ENDINPUT\" not in first_line.strip().upper():\n",
        "        is_multiline_intent = False\n",
        "        if any(kw in first_line for kw in [\"\\n\", \"\\\\n\"]):\n",
        "             is_multiline_intent = True\n",
        "        if not is_multiline_intent:\n",
        "             if first_line.strip().upper().endswith(\"ENDINPUT\"):\n",
        "                 return first_line.strip()[:-(len(\"ENDINPUT\"))].strip()\n",
        "             return first_line\n",
        "    while True:\n",
        "        try:\n",
        "            line = input()\n",
        "            if line.strip().upper() == 'ENDINPUT': break\n",
        "            lines.append(line)\n",
        "        except EOFError: print(\"INFO: EOF reached.\"); break\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def load_resume_text(file_path):\n",
        "    # [Keep existing load_resume_text function]\n",
        "    if not file_path: return \"\"\n",
        "    resume_text = \"\"\n",
        "    try:\n",
        "        if file_path.lower().endswith(\".pdf\"):\n",
        "            try:\n",
        "                with open(file_path, 'rb') as f:\n",
        "                    reader = pypdf.PdfReader(f)\n",
        "                    try: # Handle encryption\n",
        "                        if hasattr(reader, \"is_encrypted\") and reader.is_encrypted: reader.decrypt('')\n",
        "                    except Exception as decrypt_err:\n",
        "                        print(f\"Warning: PDF '{file_path}' encrypted? Error: {decrypt_err}. Cannot extract.\"); return \"\"\n",
        "                    for page in reader.pages:\n",
        "                        page_text = page.extract_text(); resume_text += (page_text + \"\\n\") if page_text else \"\"\n",
        "                if resume_text.strip(): print(f\"Successfully extracted text from PDF: {file_path}\")\n",
        "                else: print(f\"Warning: No text extracted from PDF '{file_path}'. Image-based or corrupted?\")\n",
        "            except Exception as e_pdf: print(f\"Warning: Error processing PDF '{file_path}': {e_pdf}.\"); resume_text = \"\"\n",
        "        else: # Assume text file\n",
        "            encs = ['utf-8', 'latin-1', 'cp1252']; loaded = False\n",
        "            for enc in encs:\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding=enc) as f: resume_text = f.read()\n",
        "                    print(f\"Resume loaded from text file: {file_path} (using {enc})\"); loaded = True; break\n",
        "                except UnicodeDecodeError: continue\n",
        "                except Exception as e_txt: print(f\"Warning: Error loading text file '{file_path}' with {enc}: {e_txt}.\"); break\n",
        "            if not loaded: print(f\"Warning: Could not load resume from text file '{file_path}'.\")\n",
        "    except FileNotFoundError: print(f\"Warning: Resume file not found: '{file_path}'.\")\n",
        "    except Exception as e_gen: print(f\"Warning: Unexpected error loading '{file_path}': {e_gen}.\")\n",
        "    return resume_text.strip()\n",
        "\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Welcome to the AI Novel Generator (OpenRouter Edition)!\")\n",
        "    print(\"----------------------------------------------------\")\n",
        "\n",
        "    # Allow user to override model if desired\n",
        "    user_openrouter_model = input(f\"Enter OpenRouter Model ID (default: {OPENROUTER_MODEL}): \").strip()\n",
        "    if user_openrouter_model:\n",
        "        OPENROUTER_MODEL = user_openrouter_model\n",
        "    print(f\"Using OpenRouter Model: {OPENROUTER_MODEL}\")\n",
        "    print(\"----------------------------------------------------\")\n",
        "\n",
        "\n",
        "    resume_file_path_input = input(\"Enter path to resume file (text or PDF) (or press Enter to skip): \").strip()\n",
        "    resume_text_content = load_resume_text(resume_file_path_input)\n",
        "\n",
        "    novel_subject_input = get_user_input_multiline(\"Enter the novel's subject/premise\")\n",
        "    author_style_input_str = input(\"Enter the desired author style (e.g., 'Stephen King', 'Jane Austen'): \").strip()\n",
        "    genre_input_str = input(\"Enter the genre(s) (e.g., 'Sci-Fi/Thriller', 'Historical Romance'): \").strip()\n",
        "\n",
        "    # Basic input validation\n",
        "    if not novel_subject_input: print(\"Novel subject/premise cannot be empty. Exiting.\"); exit()\n",
        "    if not author_style_input_str: print(\"Author style empty. Using 'Generic'.\"); author_style_input_str = \"Generic\"\n",
        "    if not genre_input_str: print(\"Genre empty. Using 'Fiction'.\"); genre_input_str = \"Fiction\"\n",
        "\n",
        "\n",
        "    generator = NovelGenerator(\n",
        "        resume_content=resume_text_content,\n",
        "        subject=novel_subject_input,\n",
        "        author_style=author_style_input_str,\n",
        "        genre=genre_input_str\n",
        "    )\n",
        "    generator.orchestrate_generation()\n",
        "\n",
        "    print(\"----------------------------------------------------\")\n",
        "    print(\"Novel generation process completed. Check the output directory.\")\n",
        "    print(\"Review the generated novel and metadata files.\")\n",
        "    print(\"Consider the flow analysis data in the metadata for potential revisions.\")\n",
        "    print(\"----------------------------------------------------\")"
      ],
      "metadata": {
        "id": "3uktLDUaWCrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}