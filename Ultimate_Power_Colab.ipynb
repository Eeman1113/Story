{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "! mkdir /content/docs\n",
        "! cd /content/docs && gdown 1HLxs_x2_Ji4fHCsi5fXcnts5ChPqloe9\n",
        "! echo \"##### Click and drag you resume to the ./docs folder after pressing the files button. An example resume has been added for now #####\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKZIX8SfEFfI",
        "outputId": "db5df6ed-9d59-4eb7-e3af-9b1d0ffd617b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HLxs_x2_Ji4fHCsi5fXcnts5ChPqloe9\n",
            "To: /content/docs/kenji_gamer_resume.pdf\n",
            "100% 52.0k/52.0k [00:00<00:00, 78.9MB/s]\n",
            "##### Click and drag you resume to the ./docs folder after pressing the files button. An example resume has been added for now #####\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcwkQ3OO-C93",
        "outputId": "440486e0-9739-4b35-f58c-5d85eab1e2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [77.5 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,718 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,266 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,545 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,914 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,894 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,659 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,205 kB]\n",
            "Fetched 27.0 MB in 7s (3,713 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "44 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids usb.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 lshw pci.ids pciutils usb.ids\n",
            "0 upgraded, 5 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 883 kB of archives.\n",
            "After this operation, 3,256 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 pci.ids all 0.0~2022.01.22-1ubuntu0.1 [251 kB]\n",
            "6% [1 pci.ids 63.4 kB/251 kB 25%]\u001b[0m"
          ]
        }
      ],
      "source": [
        "! sudo apt update && sudo apt install pciutils lshw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "9Rza-KZA-D5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > ollama.log 2>&1 &"
      ],
      "metadata": {
        "id": "RWnHhM4--F8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ollama run gemma3:12b “write a story on moon”"
      ],
      "metadata": {
        "id": "2nB_d-V_-IAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama\n",
        "!pip install dotenv\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "EXJfHY1R-L79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv python-docx langchain langchain-ollama langchain-community pypdf"
      ],
      "metadata": {
        "id": "GRaCLP-4-NY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app_v2.py\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import docx\n",
        "import traceback # For printing detailed errors\n",
        "import time # To avoid overwhelming the LLM API if needed\n",
        "import re # For robust parsing\n",
        "\n",
        "# --- Langchain Imports ---\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "# --- End Imports ---\n",
        "\n",
        "# Load environment variables (optional, but good practice)\n",
        "load_dotenv()\n",
        "\n",
        "# --- Constants ---\n",
        "# Model Selection: Choose the most capable model available via Ollama\n",
        "# Examples: \"gemma2:latest\", \"llama3:70b\", \"mistral:latest\"\n",
        "# Ensure the model is actually pulled and running in Ollama.\n",
        "DEFAULT_MODEL = os.getenv(\"OLLAMA_MODEL\", \"gemma3:12b\")\n",
        "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
        "OUTPUT_FOLDER = './docs'\n",
        "# Optional: Delay between LLM calls. Increase if hitting rate limits or instability.\n",
        "LLM_CALL_DELAY_SECONDS = 0.5\n",
        "# Placeholder for the resume file - MAKE SURE THIS FILE EXISTS IN OUTPUT_FOLDER\n",
        "# Or adjust the path logic as needed.\n",
        "# --- Constants ---\n",
        "DEFAULT_RESUME_FILENAME = 'kenji_gamer_resume.pdf' # Example filename\n",
        "\n",
        "# --- LLM Initialization Function ---\n",
        "def create_llm(temperature=0.7, top_p=0.9, top_k=40):\n",
        "    \"\"\"\n",
        "    Create and return an OllamaLLM instance with specified parameters.\n",
        "    Allows tuning for different generation tasks.\n",
        "    \"\"\"\n",
        "    print(f\"--- Connecting to Ollama at: {OLLAMA_BASE_URL} with Model: {DEFAULT_MODEL} ---\")\n",
        "    try:\n",
        "        llm = OllamaLLM(\n",
        "            model=DEFAULT_MODEL,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p, # Controls nucleus sampling\n",
        "            top_k=top_k, # Controls top-k sampling\n",
        "            base_url=OLLAMA_BASE_URL,\n",
        "            request_timeout=180.0, # Increased timeout for potentially longer generations\n",
        "            # Add other Ollama parameters if needed (e.g., num_ctx, stop sequences)\n",
        "            # num_predict=512, # Example: Limit max tokens per call if needed\n",
        "        )\n",
        "        # Optional: Simple invoke test to check connection early\n",
        "        # llm.invoke(\"Test connection.\")\n",
        "        print(f\"--- LLM Instance Created (Temp: {temperature}, Top P: {top_p}, Top K: {top_k}) ---\")\n",
        "        return llm\n",
        "    except Exception as e:\n",
        "        print(f\"--- FATAL ERROR: Could not create OllamaLLM instance ---\")\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Ensure Ollama service is running, the model is pulled, and accessible at the specified base URL.\")\n",
        "        print(f\"Attempted Base URL: {OLLAMA_BASE_URL}\")\n",
        "        print(f\"Attempted Model: {DEFAULT_MODEL}\")\n",
        "        traceback.print_exc()\n",
        "        raise # Reraise the exception to stop execution\n",
        "\n",
        "# --- Chain Classes ---\n",
        "\n",
        "class MainCharacterChain:\n",
        "    # Enhanced prompt for deeper character understanding\n",
        "    PROMPT = \"\"\"\n",
        "    Analyze the following resume text to create a rich, multi-faceted character profile suitable for a literary narrative. Go beyond surface-level skills.\n",
        "\n",
        "    Infer and extrapolate:\n",
        "    1.  **Name:** (If mentioned, otherwise suggest one based on context or leave blank)\n",
        "    2.  **Core Identity & Demeanor:** A brief summary (2-3 sentences) of their apparent personality, job/role, and how they present themselves.\n",
        "    3.  **Key Skills/Strengths:** List 3-5 notable skills or positive attributes relevant to potential plot points.\n",
        "    4.  **Potential Motivations:** What might drive this character? What deep-seated desires or goals could be hinted at? (Infer 2-3)\n",
        "    5.  **Potential Flaws/Weaknesses:** What vulnerabilities, biases, or negative traits might they possess? (Infer 2-3)\n",
        "    6.  **Internal Conflicts:** What inner struggles or contradictions could define their character arc? (Infer 1-2)\n",
        "    7.  **Secrets/Hidden Depths:** What might this character be hiding from others, or even themselves? (Infer 1-2)\n",
        "    8.  **Narrative Potential:** Briefly suggest (1-2 sentences) how these traits could fuel a compelling story in the {genre} genre.\n",
        "\n",
        "    Resume Text:\n",
        "    {text}\n",
        "\n",
        "    Detailed Character Profile:\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Slightly lower temperature for extraction, but allow some inference\n",
        "        self.llm = create_llm(temperature=0.6, top_p=0.85)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def load_resume(self, file_name):\n",
        "        \"\"\"Loads text content from a PDF file located in OUTPUT_FOLDER.\"\"\"\n",
        "        file_path = os.path.join(OUTPUT_FOLDER, file_name)\n",
        "        if not os.path.exists(file_path):\n",
        "             raise FileNotFoundError(f\"Resume file not found at: {file_path}\")\n",
        "        try:\n",
        "            print(f\"Loading PDF from: {file_path}\")\n",
        "            loader = PyPDFLoader(file_path)\n",
        "            # load_and_split can sometimes be better, but load is fine for moderate PDFs\n",
        "            docs = loader.load()\n",
        "            if not docs:\n",
        "                print(f\"Warning: PyPDFLoader didn't extract any documents/pages from {file_name}.\")\n",
        "                return None\n",
        "            print(f\"Successfully loaded {len(docs)} page(s) from PDF.\")\n",
        "            full_text = '\\n\\n'.join([doc.page_content for doc in docs if doc.page_content])\n",
        "            # Basic text cleaning (optional)\n",
        "            full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
        "            return full_text\n",
        "        except Exception as e:\n",
        "             print(f\"Error loading or processing PDF {file_path}: {e}\")\n",
        "             traceback.print_exc()\n",
        "             raise\n",
        "\n",
        "    def run(self, file_name, genre):\n",
        "        \"\"\"Loads resume and generates the detailed character profile.\"\"\"\n",
        "        try:\n",
        "            resume_text = self.load_resume(file_name)\n",
        "            if not resume_text or not resume_text.strip():\n",
        "                 print(\"Could not load or resume content is empty.\")\n",
        "                 return \"Error: Could not generate profile due to missing or empty resume content.\"\n",
        "\n",
        "            print(\"Invoking MainCharacterChain...\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            result = self.chain.invoke({\"text\": resume_text, \"genre\": genre})\n",
        "            profile = result.get('text', \"Error: Profile generation failed.\").strip()\n",
        "\n",
        "            # More robust check for valid profile\n",
        "            if not profile or profile.startswith(\"Error:\") or len(profile) < 100: # Increased minimum length\n",
        "                print(f\"Warning: Generated profile seems invalid or too short: '{profile}'\")\n",
        "                return f\"Error: Failed to generate a meaningful profile. LLM Output: {profile}\"\n",
        "            return profile\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in MainCharacterChain.run: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return f\"Error generating profile: {e}\"\n",
        "\n",
        "\n",
        "class SettingChain:\n",
        "    PROMPT = \"\"\"\n",
        "    You are a world-building assistant specializing in atmospheric settings for novels.\n",
        "    Based on the novel's subject, genre, and main character profile, generate a concise description of the primary setting(s).\n",
        "\n",
        "    Focus on:\n",
        "    1.  **Key Locations:** Identify 2-4 significant places where the story unfolds.\n",
        "    2.  **Time Period/Atmosphere:** Describe the general era, mood, and sensory feeling (e.g., oppressive, nostalgic, futuristic, decaying, magical).\n",
        "    3.  **Sensory Details:** Suggest 3-5 recurring sensory elements (specific sights, sounds, smells, textures) that define the world's feel.\n",
        "    4.  **Relation to Character/Plot:** Briefly explain (1-2 sentences) how the setting reflects or influences the main character and potential plot events.\n",
        "\n",
        "    Novel Subject: {subject}\n",
        "    Genre(s): {genre}\n",
        "    Main Character Profile: {profile}\n",
        "\n",
        "    Setting Description:\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Moderate temperature for creative but focused description\n",
        "        self.llm = create_llm(temperature=0.7, top_p=0.9)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def run(self, subject, genre, profile):\n",
        "        \"\"\"Generates the setting description.\"\"\"\n",
        "        try:\n",
        "            print(\"Invoking SettingChain...\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            result = self.chain.invoke({\n",
        "                \"subject\": subject,\n",
        "                \"genre\": genre,\n",
        "                \"profile\": profile\n",
        "            })\n",
        "            setting = result.get('text', \"Error: Setting generation failed.\").strip()\n",
        "            if not setting or setting.startswith(\"Error:\") or len(setting) < 50:\n",
        "                print(f\"Warning: Generated setting seems invalid or too short: '{setting}'\")\n",
        "                return f\"Error: Failed to generate a meaningful setting description. LLM Output: {setting}\"\n",
        "            return setting\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in SettingChain.run: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return f\"Error generating setting: {e}\"\n",
        "\n",
        "\n",
        "class ThemeChain:\n",
        "    PROMPT = \"\"\"\n",
        "    You are a literary analyst identifying core themes.\n",
        "    Based on the novel's subject, genre, character profile, and setting, identify 2-4 central themes that the story explores.\n",
        "    Themes should be abstract concepts (e.g., \"Loss and Memory,\" \"Identity vs. Society,\" \"The Nature of Reality,\" \"Redemption,\" \"Man vs. Nature\").\n",
        "    Provide a brief (1-sentence) explanation for each theme, linking it to the provided context.\n",
        "\n",
        "    Novel Subject: {subject}\n",
        "    Genre(s): {genre}\n",
        "    Main Character Profile: {profile}\n",
        "    Setting Description: {setting}\n",
        "\n",
        "    Identified Themes:\n",
        "    1.  [Theme 1]: [1-sentence explanation]\n",
        "    2.  [Theme 2]: [1-sentence explanation]\n",
        "    3.  [Theme 3 (Optional)]:[1-sentence explanation]\n",
        "    4.  [Theme 4 (Optional)]:[1-sentence explanation]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Lower temperature for analytical task\n",
        "        self.llm = create_llm(temperature=0.5, top_p=0.8)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def parse_themes(self, response):\n",
        "        \"\"\"Parses the numbered list of themes and explanations.\"\"\"\n",
        "        themes = {}\n",
        "        # Regex to capture \"X. [Theme Name]: [Explanation]\"\n",
        "        pattern = re.compile(r\"^\\s*\\d+\\.\\s*\\[?([^:\\]]+)\\]?:\\s*(.*)\", re.MULTILINE)\n",
        "        matches = pattern.findall(response)\n",
        "        if not matches:\n",
        "             # Fallback: Try splitting by lines if regex fails\n",
        "             lines = [line.strip() for line in response.strip().split('\\n') if ':' in line]\n",
        "             for line in lines:\n",
        "                 parts = line.split(':', 1)\n",
        "                 # Clean up theme name (remove potential number/bullet)\n",
        "                 theme_name = re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", parts[0]).strip()\n",
        "                 explanation = parts[1].strip()\n",
        "                 if theme_name and explanation:\n",
        "                     themes[theme_name] = explanation\n",
        "        else:\n",
        "             for match in matches:\n",
        "                 theme_name = match[0].strip()\n",
        "                 explanation = match[1].strip()\n",
        "                 if theme_name and explanation:\n",
        "                     themes[theme_name] = explanation\n",
        "\n",
        "        if not themes:\n",
        "            print(f\"Warning: Could not parse themes from response:\\n---\\n{response}\\n---\")\n",
        "            return {\"Error\": \"Theme parsing failed.\"}\n",
        "        return themes # Returns dict { 'Theme Name': 'Explanation' }\n",
        "\n",
        "    def run(self, subject, genre, profile, setting):\n",
        "        \"\"\"Generates and parses the core themes.\"\"\"\n",
        "        try:\n",
        "            print(\"Invoking ThemeChain...\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            result = self.chain.invoke({\n",
        "                \"subject\": subject,\n",
        "                \"genre\": genre,\n",
        "                \"profile\": profile,\n",
        "                \"setting\": setting\n",
        "            })\n",
        "            raw_themes = result.get('text', \"\").strip()\n",
        "            return self.parse_themes(raw_themes)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in ThemeChain.run: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {\"Error\": f\"Theme generation failed: {e}\"}\n",
        "\n",
        "\n",
        "class TitleChain:\n",
        "    # Prompt now includes themes and setting for better context\n",
        "    PROMPT = \"\"\"\n",
        "    You are a creative book title generator known for evocative and genre-appropriate titles.\n",
        "    Generate ONE compelling novel title based on the provided details.\n",
        "    The title must be highly consistent with the genre(s), author's style, subject, main character, setting, and core themes.\n",
        "    It should be intriguing and memorable.\n",
        "\n",
        "    Subject: {subject}\n",
        "    Genre(s): {genre}\n",
        "    Author's Style Inspiration: {author}\n",
        "    Main Character Profile: {profile}\n",
        "    Setting Description: {setting}\n",
        "    Core Themes: {themes}\n",
        "\n",
        "    Return ONLY the generated title itself, without any quotation marks, labels (like \"Title:\"), or explanatory text.\n",
        "\n",
        "    Novel Title:\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Higher temperature for creative title generation\n",
        "        self.llm = create_llm(temperature=0.85, top_p=0.95)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def run(self, subject, genre, author, profile, setting, themes_str):\n",
        "        \"\"\"Generates the novel title.\"\"\"\n",
        "        try:\n",
        "            print(\"Invoking TitleChain...\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            result = self.chain.invoke({\n",
        "                \"subject\": subject,\n",
        "                \"genre\": genre,\n",
        "                \"author\": author,\n",
        "                \"profile\": profile,\n",
        "                \"setting\": setting,\n",
        "                \"themes\": themes_str\n",
        "            })\n",
        "            title = result.get('text', \"Untitled Novel\").strip()\n",
        "            # Clean the output string thoroughly\n",
        "            title = re.sub(r'^(Title:|Novel Title:)\\s*', '', title, flags=re.IGNORECASE)\n",
        "            title = title.strip('\"\\'')\n",
        "\n",
        "            if not title or len(title) < 3 or title == \"Untitled Novel\":\n",
        "                 print(f\"Warning: Generated title seems invalid: '{title}'. Using placeholder.\")\n",
        "                 # Generate a slightly more descriptive placeholder\n",
        "                 genre_tag = genre.split('/')[0].split(',')[0].strip()\n",
        "                 return f\"Placeholder - {genre_tag} Story about {profile.split('.')[0]}\" # Use first sentence of profile\n",
        "            return title\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in TitleChain.run: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return \"Error Generating Title\"\n",
        "\n",
        "\n",
        "class PlotChain:\n",
        "    # Enhanced prompt incorporating setting and themes\n",
        "    PROMPT = \"\"\"\n",
        "    You are a master storyteller and plot architect, crafting narratives in the style of {author}.\n",
        "    Develop a detailed, multi-act plot outline (e.g., Act I, Act II, Act III or Beginning, Middle, End) for a novel.\n",
        "    The plot must be engaging, coherent, thematically resonant, and build towards a satisfying climax and resolution appropriate for the {genre} genre.\n",
        "\n",
        "    Integrate the following elements seamlessly:\n",
        "    - Main Character Arc: Show how the character (profile below) changes or is challenged, driven by their motivations/flaws.\n",
        "    - Core Themes: Weave the themes ({themes}) into the events and character journey.\n",
        "    - Setting Influence: Show how the setting ({setting}) impacts the mood, obstacles, or events.\n",
        "    - Compelling Attributes: Incorporate story elements like: {features}.\n",
        "    - Supporting Characters: Introduce necessary allies, antagonists, or foils.\n",
        "    - Conflict: Include both internal (character-based) and external (plot-based) conflicts.\n",
        "    - Turning Points: Define key moments that shift the narrative direction.\n",
        "\n",
        "    Novel Subject: {subject}\n",
        "    Genre(s): {genre}\n",
        "    Novel Title: \"{title}\"\n",
        "    Main Character Profile: {profile}\n",
        "    Setting Description: {setting}\n",
        "    Core Themes: {themes}\n",
        "\n",
        "    Detailed Plot Outline:\"\"\"\n",
        "\n",
        "    HELPER_PROMPT = \"\"\"\n",
        "    Generate a comma-separated list of 5-7 diverse and compelling story attributes or narrative devices suitable for the specified genre(s) and author style. Avoid generic terms. Be specific and evocative.\n",
        "    Genre(s): {genre}\n",
        "    Author's Style Inspiration: {author}\n",
        "\n",
        "    Examples for different genres/styles:\n",
        "    Psychological/Ocean Vuong: Fragmented memories, Lyrical prose focus, Visceral sensory details, Intergenerational trauma echoes, Non-linear emotional arcs, Symbolism in mundane objects.\n",
        "    Sci-Fi/Ted Chiang: Thought-provoking central conceit, Exploration of philosophical implications, Rigorous internal logic, Emotional core within intellectual framework, Sense of wonder or unease.\n",
        "    Fantasy/N.K. Jemisin: Intricate world-building reveals, High-stakes societal conflict, Complex moral ambiguity, Unique magic systems with consequences, Characters challenging power structures.\n",
        "    Thriller/Gillian Flynn: Unreliable narrator, Toxic relationships, Dark secrets unraveling, Sharp social commentary, Unexpected plot twists rooted in character psychology.\n",
        "\n",
        "    List of Attributes (comma-separated):\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Balanced temperature for structured creativity\n",
        "        self.llm = create_llm(temperature=0.75, top_p=0.9)\n",
        "        # Main chain for plot generation\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "        # Helper chain to generate dynamic features\n",
        "        self.helper_chain = LLMChain(\n",
        "            llm=self.llm, # Use the same LLM instance\n",
        "            prompt=PromptTemplate.from_template(self.HELPER_PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def run(self, subject, genre, author, profile, title, setting, themes_str):\n",
        "        \"\"\"Generates the detailed novel plot outline.\"\"\"\n",
        "        try:\n",
        "            # Generate dynamic features\n",
        "            print(f\"Generating plot features for genre '{genre}' and author style '{author}'...\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            features_result = self.helper_chain.invoke({\"genre\": genre, \"author\": author})\n",
        "            features = features_result.get('text', \"Compelling conflict, Character depth, Unexpected twists\").strip()\n",
        "            print(f\"Generated plot features: {features}\")\n",
        "\n",
        "            # Generate the main plot outline\n",
        "            print(f\"Generating main plot outline for title: {title}\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            plot_result = self.chain.invoke({\n",
        "                \"features\": features,\n",
        "                \"subject\": subject,\n",
        "                \"genre\": genre,\n",
        "                \"author\": author,\n",
        "                \"profile\": profile,\n",
        "                \"title\": title,\n",
        "                \"setting\": setting,\n",
        "                \"themes\": themes_str\n",
        "            })\n",
        "            plot = plot_result.get('text', \"Error: Plot generation failed.\").strip()\n",
        "\n",
        "            # Check for valid plot (e.g., minimum length, structure)\n",
        "            if not plot or plot.startswith(\"Error:\") or len(plot) < 200: # Increased minimum length\n",
        "                 print(f\"Warning: Generated plot seems invalid or too short: '{plot}'\")\n",
        "                 return f\"Error: Failed to generate a detailed plot. LLM Output: {plot}\"\n",
        "            return plot\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in PlotChain.run: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return f\"Error generating plot: {e}\"\n",
        "\n",
        "\n",
        "class ChaptersChain:\n",
        "    # Prompt updated to request consistency with themes/setting\n",
        "    PROMPT = \"\"\"\n",
        "    You are a meticulous book editor outlining chapter structure in the style of {author}.\n",
        "    Based on the detailed plot outline, generate a list of chapter titles AND brief, one-sentence descriptions capturing the core focus or turning point of each chapter.\n",
        "    Aim for a realistic number of chapters (e.g., 15-35) that logically progress through the plot.\n",
        "    Include a Prologue and/or Epilogue ONLY if appropriate for the story structure, genre, and author's style.\n",
        "\n",
        "    Ensure strict consistency with:\n",
        "    - Novel Title: \"{title}\"\n",
        "    - Genre(s): {genre}\n",
        "    - Author's Style: {author}\n",
        "    - Main Character Arc: {profile}\n",
        "    - Setting: {setting}\n",
        "    - Core Themes: {themes}\n",
        "    - Detailed Plot Outline (provided below)\n",
        "\n",
        "    Use this EXACT format for each entry, with NO blank lines between entries:\n",
        "    [Chapter Type] [Number (if not Prologue/Epilogue)]: [Concise, evocative one-sentence Description]\n",
        "\n",
        "    Example Format:\n",
        "    Prologue: Whispers of the past in the decaying manor.\n",
        "    Chapter 1: A mundane routine shattered by a cryptic message.\n",
        "    Chapter 2: The first venture into the forbidden zone, guided by fear.\n",
        "    ...\n",
        "    Chapter N: The confrontation forces an impossible choice, echoing the core theme of sacrifice.\n",
        "    Epilogue: Lingering questions in the changed landscape.\n",
        "\n",
        "    Detailed Plot Outline:\n",
        "    <PLOT_START>\n",
        "    {plot}\n",
        "    <PLOT_END>\n",
        "\n",
        "    Chapters List (Strict Format Adherence Required):\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Slightly lower temperature for structured output, higher K for variety\n",
        "        self.llm = create_llm(temperature=0.65, top_p=0.9, top_k=50)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def parse(self, response):\n",
        "        \"\"\"Parses the LLM response string into an ordered dictionary of chapters.\"\"\"\n",
        "        chapters = {} # Using dict to store { 'Title': 'Description' }\n",
        "        lines = [line.strip() for line in response.strip().split('\\n') if line.strip()]\n",
        "        print(f\"\\nRaw Chapter Response Lines ({len(lines)}):\")\n",
        "        # for i, line in enumerate(lines): print(f\"  Line {i}: {line}\") # Uncomment for deep debug\n",
        "\n",
        "        parsed_count = 0\n",
        "        # Regex to capture variations like \"Chapter 1: Desc\", \"Prologue: Desc\", \"Epilogue: Desc\"\n",
        "        # Allows optional space after number, handles Prologue/Epilogue case-insensitively\n",
        "        pattern = re.compile(r\"^(Prologue|Epilogue|Chapter\\s*(\\d+))\\s*:\\s*(.+)$\", re.IGNORECASE | re.MULTILINE)\n",
        "\n",
        "        # First pass using regex for well-formatted lines\n",
        "        processed_lines = set()\n",
        "        matches = pattern.findall(response) # Search the whole response block\n",
        "        for match in matches:\n",
        "            full_title = match[0].strip() # e.g., \"Prologue\", \"Chapter 1\"\n",
        "            # Reconstruct title properly if it's a chapter number\n",
        "            if match[1]: # If chapter number was captured\n",
        "                full_title = f\"Chapter {match[1]}\"\n",
        "            description = match[2].strip()\n",
        "            if description:\n",
        "                chapters[full_title] = description\n",
        "                parsed_count += 1\n",
        "                # Mark the raw line containing this match as processed (approximate)\n",
        "                # This is tricky if descriptions contain newlines, but helps avoid double parsing\n",
        "                raw_line_approx = f\"{match[0]}:{description}\"\n",
        "                for i, line in enumerate(lines):\n",
        "                    if raw_line_approx in line: # Check if the core part exists\n",
        "                         processed_lines.add(i)\n",
        "                         break # Mark only the first occurrence\n",
        "            else:\n",
        "                print(f\"  Warning: Skipping match - Empty description: '{match[0]}'\")\n",
        "\n",
        "\n",
        "        # Second pass for lines potentially missed by regex (less strict)\n",
        "        print(f\"Attempting fallback parsing for remaining lines...\")\n",
        "        for i, line in enumerate(lines):\n",
        "            if i in processed_lines: continue # Skip already processed lines\n",
        "\n",
        "            if ':' in line:\n",
        "                parts = line.split(':', 1)\n",
        "                potential_title = parts[0].strip()\n",
        "                potential_desc = parts[1].strip()\n",
        "\n",
        "                # Basic check for plausible chapter titles\n",
        "                is_prologue = \"prologue\" in potential_title.lower()\n",
        "                is_epilogue = \"epilogue\" in potential_title.lower()\n",
        "                is_chapter = \"chapter\" in potential_title.lower() and any(char.isdigit() for char in potential_title)\n",
        "\n",
        "                # Avoid adding if already parsed via regex (handles slight format variations)\n",
        "                if potential_title not in chapters and (is_prologue or is_epilogue or is_chapter):\n",
        "                    if potential_desc:\n",
        "                        print(f\"  Fallback Parsed Line {i}: '{potential_title}' -> '{potential_desc}'\") # Debug fallback\n",
        "                        chapters[potential_title] = potential_desc\n",
        "                        parsed_count += 1\n",
        "                    else:\n",
        "                        print(f\"  Warning: Skipping line {i} (fallback) - Empty description: '{line}'\")\n",
        "                # else:\n",
        "                #      print(f\"  Info: Skipping line {i} (fallback) - Doesn't look like chapter title or already parsed: '{line}'\")\n",
        "            # else:\n",
        "            #     print(f\"  Info: Skipping line {i} (fallback) - No colon found: '{line}'\")\n",
        "\n",
        "\n",
        "        if not chapters:\n",
        "             print(f\"CRITICAL WARNING: Could not parse *any* chapters adhering to the expected format.\")\n",
        "             print(f\"LLM Raw Response was:\\n---\\n{response}\\n---\")\n",
        "             return {} # Return empty dict to signal failure\n",
        "\n",
        "        print(f\"Successfully parsed {parsed_count} chapters.\")\n",
        "        # Return sorted chapters directly from parse function\n",
        "        return dict(sort_chapters(chapters)) # Return sorted dict {title: description}\n",
        "\n",
        "    def run(self, subject, genre, author, profile, title, plot, setting, themes_str):\n",
        "        \"\"\"Generates and parses the chapter list.\"\"\"\n",
        "        try:\n",
        "            print(\"Invoking ChaptersChain...\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            response_result = self.chain.invoke({\n",
        "                \"subject\": subject,\n",
        "                \"genre\": genre,\n",
        "                \"author\": author,\n",
        "                \"profile\": profile,\n",
        "                \"title\": title,\n",
        "                \"plot\": plot,\n",
        "                \"setting\": setting,\n",
        "                \"themes\": themes_str\n",
        "            })\n",
        "            raw_response = response_result.get('text', \"\")\n",
        "            return self.parse(raw_response)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in ChaptersChain.run: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {} # Return empty dict on error\n",
        "\n",
        "\n",
        "class EventChain:\n",
        "    # Prompt now includes profile and themes for better context\n",
        "    PROMPT = \"\"\"\n",
        "    You are a narrative strategist breaking down a chapter into key scenes or events, following the style of {author}.\n",
        "    Based on the overall plot, the chapter's details, character profile, and themes, generate an ordered list of 3-7 key plot events or scenes that MUST occur within this chapter.\n",
        "    Focus on actions, decisions, revelations, significant interactions, or internal character moments that advance the plot AND reflect the character's journey or the novel's themes.\n",
        "    Ensure events flow logically from the chapter summary and overall plot.\n",
        "\n",
        "    Overall Plot Summary:\n",
        "    <PLOT_SUMMARY>\n",
        "    {plot}\n",
        "    </PLOT_SUMMARY>\n",
        "\n",
        "    Main Character Profile:\n",
        "    <CHARACTER>\n",
        "    {profile}\n",
        "    </CHARACTER>\n",
        "\n",
        "    Core Themes: {themes}\n",
        "\n",
        "    Current Chapter Title: \"{chapter_title}\"\n",
        "    Current Chapter Summary: {chapter_summary}\n",
        "\n",
        "    Return ONLY the numbered list of events, one event per line. Start numbering from 1. Be concise but evocative.\n",
        "\n",
        "    Example (Psychological Fiction):\n",
        "    1. Divi awakens to the oppressive silence, the weight of unspoken words heavy in the air.\n",
        "    2. A fragmented memory surfaces: a childhood promise broken.\n",
        "    3. She attempts to write, but the words feel alien, mirroring her internal disconnect.\n",
        "    4. A sound from outside triggers a cascade of anxious thoughts, linking to the theme of vulnerability.\n",
        "    5. The chapter ends with her staring at her reflection, questioning the face looking back.\n",
        "\n",
        "    Numbered Event List for Chapter \"{chapter_title}\":\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Moderate temperature for focused event generation\n",
        "        self.llm = create_llm(temperature=0.7, top_p=0.9)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def parse_events(self, response):\n",
        "        \"\"\"Parses the numbered list response into a list of strings.\"\"\"\n",
        "        events = []\n",
        "        # Regex to find lines starting with a number, optional punctuation, and then text\n",
        "        pattern = re.compile(r\"^\\s*\\d+[\\.\\)\\s]+(.*)\", re.MULTILINE)\n",
        "        matches = pattern.findall(response)\n",
        "\n",
        "        if matches:\n",
        "            for event_text in matches:\n",
        "                if event_text.strip():\n",
        "                    events.append(event_text.strip())\n",
        "        else:\n",
        "            # Fallback: split by lines and try to clean up\n",
        "            lines = [line.strip() for line in response.strip().split('\\n') if line.strip()]\n",
        "            for line in lines:\n",
        "                 # Attempt to remove leading numbers/bullets if regex failed\n",
        "                 cleaned_line = re.sub(r\"^\\s*\\d+[\\.\\)\\s]*\", \"\", line).strip()\n",
        "                 if cleaned_line:\n",
        "                     events.append(cleaned_line)\n",
        "\n",
        "        if not events:\n",
        "             print(f\"  Warning: Could not parse any numbered events from response:\\n---\\n{response}\\n---\")\n",
        "             # Fallback: return the raw response lines (better than nothing)\n",
        "             raw_lines = [line.strip() for line in response.strip().split('\\n') if line.strip()]\n",
        "             return raw_lines if raw_lines else [\"Placeholder event due to parsing failure.\"]\n",
        "        return events\n",
        "\n",
        "    def run(self, plot, profile, themes_str, chapter_title, chapter_summary, author):\n",
        "        \"\"\"Generates and parses the event list for a single chapter.\"\"\"\n",
        "        try:\n",
        "            print(f\"Invoking EventChain for: {chapter_title}\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            result = self.chain.invoke({\n",
        "                \"plot\": plot,\n",
        "                \"profile\": profile,\n",
        "                \"themes\": themes_str,\n",
        "                \"chapter_title\": chapter_title,\n",
        "                \"chapter_summary\": chapter_summary,\n",
        "                \"author\": author # Pass author style for event tone\n",
        "            })\n",
        "            raw_events = result.get('text', \"\").strip()\n",
        "            return self.parse_events(raw_events)\n",
        "        except Exception as e:\n",
        "            print(f\"  Error generating events for '{chapter_title}': {e}\")\n",
        "            # Don't print traceback here, handled in main loop\n",
        "            # Return placeholder on error\n",
        "            return [f\"Event generation error 1 for '{chapter_summary}'\", f\"Event generation error 2 for '{chapter_summary}'\"]\n",
        "\n",
        "\n",
        "# --- Enhanced Writer Chain ---\n",
        "class WriterChain:\n",
        "    # Significantly enhanced prompt focusing on depth, theme, setting, and \"show, don't tell\"\n",
        "    PROMPT = \"\"\"\n",
        "    You are a master novelist embodying the distinct writing style of {author}. Your task is to write a segment of the novel \"{title}\", a {genre} work.\n",
        "\n",
        "    **ESTABLISHED CONTEXT (DO NOT REPEAT):**\n",
        "\n",
        "    <MAIN_CHARACTER_PROFILE>\n",
        "    {profile}\n",
        "    </MAIN_CHARACTER_PROFILE>\n",
        "\n",
        "    <SETTING_DESCRIPTION>\n",
        "    {setting}\n",
        "    </SETTING_DESCRIPTION>\n",
        "\n",
        "    <CORE_THEMES>\n",
        "    {themes}\n",
        "    </CORE_THEMES>\n",
        "\n",
        "    <NOVEL_PLOT_SUMMARY>\n",
        "    {plot}\n",
        "    </NOVEL_PLOT_SUMMARY>\n",
        "\n",
        "    <CURRENT_CHAPTER_INFO>\n",
        "    Chapter Title: {chapter_name}\n",
        "    Chapter Summary: {summary}\n",
        "    </CURRENT_CHAPTER_INFO>\n",
        "\n",
        "    <NARRATIVE_HISTORY>\n",
        "    Key events already occurred (prior chapters/events):\n",
        "    {previous_events}\n",
        "    </NARRATIVE_HISTORY>\n",
        "\n",
        "    <CHAPTER_PROGRESS_SO_FAR>\n",
        "    Narrative written previously within THIS chapter ({chapter_name}):\n",
        "    {previous_paragraphs}\n",
        "    </CHAPTER_PROGRESS_SO_FAR>\n",
        "\n",
        "    **YOUR CURRENT WRITING TASK:**\n",
        "\n",
        "    Bring the following specific event to life. Focus *exclusively* on this moment.\n",
        "\n",
        "    <CURRENT_EVENT_TO_WRITE>\n",
        "    {current_event}\n",
        "    </CURRENT_EVENT_TO_WRITE>\n",
        "\n",
        "    **WRITING INSTRUCTIONS (CRITICAL):**\n",
        "\n",
        "    1.  **Style & Tone:** Write 1-3 detailed paragraphs (approx. 150-400 words total for this event, adjust based on significance) strictly in the voice and style of {author}. Match their typical sentence structure, vocabulary, pacing, and tone.\n",
        "    2.  **Show, Don't Tell:** Demonstrate emotions, character thoughts, and plot developments through actions, dialogue (if appropriate for the event and character), internal monologue, and sensory details, rather than stating them directly.\n",
        "    3.  **Sensory Integration:** Weave in specific sensory details (sight, sound, smell, touch, taste) consistent with the established <SETTING_DESCRIPTION>. Make the scene immersive.\n",
        "    4.  **Character Depth:** Reflect the <MAIN_CHARACTER_PROFILE> (motivations, flaws, internal conflicts) in their reactions, thoughts, and actions during this event.\n",
        "    5.  **Thematic Resonance:** Subtly connect the events or the character's internal experience to the <CORE_THEMES> where appropriate, without being overt.\n",
        "    6.  **Continuity:** Ensure a seamless transition from the <CHAPTER_PROGRESS_SO_FAR>. Do NOT repeat information already covered. Do NOT summarize the event itself.\n",
        "    7.  **Output:** Generate ONLY the newly written narrative paragraphs for the <CURRENT_EVENT_TO_WRITE>. No explanations, labels, or summaries.\n",
        "\n",
        "    New Narrative Paragraphs (Style: {author}):\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # High temperature for creative prose, high top-p for diversity, moderate top-k\n",
        "        self.llm = create_llm(temperature=0.9, top_p=0.95, top_k=60)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True # Set to False in production if too noisy\n",
        "        )\n",
        "\n",
        "    def run(self, genre, author, title, profile, plot, setting, themes_str, chapter_name,\n",
        "            previous_events_history_str, chapter_summary, previous_paragraphs_str, current_event):\n",
        "        \"\"\"Generates narrative paragraphs for a specific event.\"\"\"\n",
        "        # Ensure placeholders are clear if context is empty\n",
        "        if not previous_events_history_str: previous_events_history_str = \"None (This is the beginning of the story).\"\n",
        "        if not previous_paragraphs_str: previous_paragraphs_str = \"None (This is the beginning of the chapter).\"\n",
        "\n",
        "        try:\n",
        "            print(f\"Invoking WriterChain for event: {current_event[:80]}...\") # Log truncated event\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            result = self.chain.invoke({\n",
        "                \"genre\": genre,\n",
        "                \"author\": author,\n",
        "                \"title\": title,\n",
        "                \"profile\": profile,\n",
        "                \"plot\": plot,\n",
        "                \"setting\": setting,\n",
        "                \"themes\": themes_str,\n",
        "                \"chapter_name\": chapter_name,\n",
        "                \"previous_events\": previous_events_history_str,\n",
        "                \"summary\": chapter_summary,\n",
        "                \"previous_paragraphs\": previous_paragraphs_str,\n",
        "                \"current_event\": current_event\n",
        "            })\n",
        "            generated_text = result.get('text', f\"[ERROR: Writing failed for event: '{current_event}']\").strip()\n",
        "\n",
        "            # Basic validation of output\n",
        "            if not generated_text or generated_text.startswith(\"[ERROR:\") or len(generated_text) < 50: # Increased min length\n",
        "                 print(f\"  Warning: WriterChain generated potentially invalid/short output for event '{current_event}'. Output: '{generated_text}'\")\n",
        "                 return f\"[Writer Error - Event: '{current_event}'. LLM Output: '{generated_text}']\"\n",
        "\n",
        "            # Optional: Add post-processing to clean up LLM artifacts (e.g., repeated phrases, stray quotes)\n",
        "            # generated_text = re.sub(r'^\"|\"$', '', generated_text) # Example: remove leading/trailing quotes\n",
        "\n",
        "            return generated_text\n",
        "        except Exception as e:\n",
        "            # Log the error but return a placeholder to avoid crashing the whole process\n",
        "            print(f\"  ERROR occurred in WriterChain.run for event '{current_event}': {e}\")\n",
        "            # Consider logging traceback only if a debug flag is set\n",
        "            # traceback.print_exc()\n",
        "            return f\"[FATAL WRITER ERROR - Event: '{current_event}'. Check logs for details.]\"\n",
        "\n",
        "\n",
        "# --- NEW: Refinement Chain (Optional Post-Processing) ---\n",
        "class RefinementChain:\n",
        "    PROMPT = \"\"\"\n",
        "    You are an expert literary editor refining a draft chapter written in the style of {author}.\n",
        "    The chapter is part of the novel \"{title}\" ({genre}).\n",
        "\n",
        "    **CONTEXT:**\n",
        "    <MAIN_CHARACTER_PROFILE>{profile}</MAIN_CHARACTER_PROFILE>\n",
        "    <SETTING_DESCRIPTION>{setting}</SETTING_DESCRIPTION>\n",
        "    <CORE_THEMES>{themes}</CORE_THEMES>\n",
        "    <NOVEL_PLOT_SUMMARY>{plot}</NOVEL_PLOT_SUMMARY>\n",
        "    <CHAPTER_INFO>Title: {chapter_name}, Summary: {summary}</CHAPTER_INFO>\n",
        "\n",
        "    **DRAFT TEXT FOR REFINEMENT:**\n",
        "    <DRAFT_START>\n",
        "    {draft_text}\n",
        "    <DRAFT_END>\n",
        "\n",
        "    **YOUR TASK:**\n",
        "    Review and refine the provided draft text. Focus on ONE OR TWO of the following aspects (choose based on perceived need or specify focus):\n",
        "    1.  **Stylistic Consistency:** Enhance adherence to {author}'s unique voice, sentence structure, and vocabulary.\n",
        "    2.  **Prose Flow & Pacing:** Improve readability, sentence variety, and transitions between paragraphs. Smooth out awkward phrasing.\n",
        "    3.  **Sensory Detail Enhancement:** Weave in more vivid and relevant sensory details based on the setting.\n",
        "    4.  **Dialogue Polish:** Make dialogue sound more natural and character-specific (if applicable).\n",
        "    5.  **Thematic Resonance:** Subtly strengthen connections to the core themes ({themes}).\n",
        "    6.  **Show, Don't Tell:** Convert any instances of telling into showing through action, internal thought, or description.\n",
        "    7.  **Conciseness:** Trim unnecessary words or redundant phrases without losing meaning or style.\n",
        "\n",
        "    **INSTRUCTIONS:**\n",
        "    - Make subtle but impactful changes. Do NOT rewrite entire sections unless absolutely necessary.\n",
        "    - Preserve the original plot points and events of the draft.\n",
        "    - Output ONLY the refined text for the chapter. Do not include explanations, summaries, or comments about your changes.\n",
        "\n",
        "    Refined Chapter Text (Style: {author}):\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Moderate temperature for controlled editing, high top-p for nuanced choices\n",
        "        self.llm = create_llm(temperature=0.6, top_p=0.95, top_k=50)\n",
        "        self.chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate.from_template(self.PROMPT),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "    def run(self, author, title, genre, profile, setting, themes_str, plot, chapter_name, summary, draft_text):\n",
        "        \"\"\"Refines the draft text of a chapter.\"\"\"\n",
        "        if not draft_text or draft_text.startswith(\"[Content generation skipped\") or draft_text.startswith(\"[Writer Error\"):\n",
        "            print(f\"  Skipping refinement for '{chapter_name}' due to missing or errored draft content.\")\n",
        "            return draft_text # Return original if it's bad\n",
        "\n",
        "        try:\n",
        "            print(f\"Invoking RefinementChain for chapter: {chapter_name}...\")\n",
        "            time.sleep(LLM_CALL_DELAY_SECONDS)\n",
        "            result = self.chain.invoke({\n",
        "                \"author\": author,\n",
        "                \"title\": title,\n",
        "                \"genre\": genre,\n",
        "                \"profile\": profile,\n",
        "                \"setting\": setting,\n",
        "                \"themes\": themes_str,\n",
        "                \"plot\": plot,\n",
        "                \"chapter_name\": chapter_name,\n",
        "                \"summary\": summary,\n",
        "                \"draft_text\": draft_text\n",
        "            })\n",
        "            refined_text = result.get('text', f\"[ERROR: Refinement failed for chapter: '{chapter_name}']\").strip()\n",
        "\n",
        "            # Basic validation\n",
        "            if not refined_text or refined_text.startswith(\"[ERROR:\") or len(refined_text) < len(draft_text) * 0.5: # Check if it didn't shrink too much\n",
        "                 print(f\"  Warning: RefinementChain generated potentially invalid output for '{chapter_name}'. Output: '{refined_text[:100]}...'\")\n",
        "                 return draft_text # Fallback to original draft if refinement seems broken\n",
        "\n",
        "            return refined_text\n",
        "        except Exception as e:\n",
        "            print(f\"  ERROR occurred in RefinementChain.run for chapter '{chapter_name}': {e}\")\n",
        "            # traceback.print_exc() # Optional: uncomment for debugging\n",
        "            return draft_text # Fallback to original draft on error\n",
        "\n",
        "\n",
        "# --- Book Writing Orchestration ---\n",
        "\n",
        "def format_themes_string(themes_dict):\n",
        "    \"\"\"Formats the theme dictionary into a string for prompts.\"\"\"\n",
        "    if not themes_dict or \"Error\" in themes_dict:\n",
        "        return \"N/A\"\n",
        "    return \"; \".join([f\"{name}: {desc}\" for name, desc in themes_dict.items()])\n",
        "\n",
        "def sort_chapters(chapter_dict):\n",
        "    \"\"\"Sorts chapter dictionary keys (titles) into a logical order. Returns list of (title, description) tuples.\"\"\"\n",
        "    def chapter_sort_key(chapter_title):\n",
        "        title_lower = chapter_title.lower().strip()\n",
        "        if title_lower == \"prologue\": return (-1, 0)\n",
        "        if title_lower == \"epilogue\": return (9999, 0)\n",
        "        match = re.match(r\"chapter\\s*(\\d+)\", title_lower)\n",
        "        if match:\n",
        "            try:\n",
        "                num = int(match.group(1))\n",
        "                return (1, num)\n",
        "            except (IndexError, ValueError):\n",
        "                return (2, chapter_title) # Fallback sort by title if number parsing fails\n",
        "        return (3, chapter_title) # Sort any other titles alphabetically after chapters\n",
        "\n",
        "    # Sort the items (title, description pairs) based on the key (title)\n",
        "    return sorted(chapter_dict.items(), key=lambda item: chapter_sort_key(item[0]))\n",
        "\n",
        "\n",
        "def generate_events_for_all_chapters(plot, profile, themes_str, chapter_dict, author):\n",
        "    \"\"\"Generates event lists for all chapters using EventChain.\"\"\"\n",
        "    print(\"\\n--- Generating Events for Each Chapter ---\")\n",
        "    event_generator = EventChain()\n",
        "    event_dict = {} # { 'Chapter Title': ['Event 1', 'Event 2', ...] }\n",
        "\n",
        "    # Use the pre-sorted chapter list from the ChaptersChain parsing\n",
        "    sorted_chapter_items = chapter_dict.items() # chapter_dict should already be sorted\n",
        "\n",
        "    for chapter_title, summary in sorted_chapter_items:\n",
        "         print(f\"Generating events for: {chapter_title}\")\n",
        "         events = event_generator.run(plot, profile, themes_str, chapter_title, summary, author)\n",
        "         if events and not any(\"error\" in evt.lower() for evt in events):\n",
        "            event_dict[chapter_title] = events\n",
        "            print(f\"  Generated {len(events)} events for '{chapter_title}'.\")\n",
        "            # for i, ev in enumerate(events): print(f\"    {i+1}. {ev[:100]}...\") # Log truncated events\n",
        "         else:\n",
        "            print(f\"  WARNING: No valid events generated or parsed for '{chapter_title}'. Chapter content might be basic or skipped.\")\n",
        "            event_dict[chapter_title] = [] # Store empty list to indicate failure/skip\n",
        "\n",
        "    return event_dict\n",
        "\n",
        "\n",
        "def write_book(genre, author, title, profile, plot, setting, themes_str, chapter_dict, event_dict, refine_chapters=False):\n",
        "    \"\"\"Orchestrates the writing of the full book content, event by event, with optional refinement.\"\"\"\n",
        "    print(\"\\n--- Starting Detailed Book Writing Process ---\")\n",
        "    writer_chain = WriterChain()\n",
        "    refiner_chain = RefinementChain() if refine_chapters else None # Instantiate refiner only if needed\n",
        "\n",
        "    book_content = {} # Stores final text: {chapter_title: \"Full chapter text...\"}\n",
        "    previous_events_history = [] # Running list of event descriptions written so far\n",
        "\n",
        "    # Use the pre-sorted chapter list\n",
        "    sorted_chapter_items = chapter_dict.items()\n",
        "    total_chapters = len(sorted_chapter_items)\n",
        "\n",
        "    for chap_idx, (chapter_title, chapter_summary) in enumerate(sorted_chapter_items):\n",
        "        print(f\"\\n--- Writing Chapter {chap_idx+1}/{total_chapters}: {chapter_title} ---\")\n",
        "        print(f\"   Summary: {chapter_summary}\")\n",
        "\n",
        "        chapter_events = event_dict.get(chapter_title, [])\n",
        "        if not chapter_events:\n",
        "            print(f\"   WARNING: No events found for '{chapter_title}'. Skipping content generation.\")\n",
        "            book_content[chapter_title] = f\"[Content generation skipped: No events defined for this chapter.]\"\n",
        "            continue\n",
        "\n",
        "        # Accumulator for text within the *current* chapter\n",
        "        chapter_paragraphs_accumulator = \"\"\n",
        "        total_events = len(chapter_events)\n",
        "\n",
        "        for event_idx, event_description in enumerate(chapter_events):\n",
        "            # Limit history length passed to LLM to avoid excessive context window usage\n",
        "            # Keep maybe the last 20-30 events? Or based on token count?\n",
        "            MAX_HISTORY_EVENTS = 30\n",
        "            limited_history = previous_events_history[-MAX_HISTORY_EVENTS:]\n",
        "            history_str = '\\n'.join(f\"- {evt}\" for evt in limited_history) if limited_history else \"None (Start of Story)\"\n",
        "            progress_str = chapter_paragraphs_accumulator if chapter_paragraphs_accumulator else \"None (Start of Chapter)\"\n",
        "\n",
        "            print(f\"   Writing Event {event_idx+1}/{total_events}: {event_description[:100]}...\") # Log truncated event\n",
        "\n",
        "            # Call the writer chain for the current event\n",
        "            new_paragraphs = writer_chain.run(\n",
        "                genre=genre, author=author, title=title, profile=profile, plot=plot,\n",
        "                setting=setting, themes_str=themes_str, chapter_name=chapter_title,\n",
        "                previous_events_history_str=history_str, chapter_summary=chapter_summary,\n",
        "                previous_paragraphs_str=progress_str, current_event=event_description\n",
        "            )\n",
        "\n",
        "            # Append the newly generated block, handling potential errors\n",
        "            if new_paragraphs.startswith(\"[FATAL WRITER ERROR\") or new_paragraphs.startswith(\"[Writer Error\"):\n",
        "                print(f\"   ERROR detected writing event {event_idx+1}. Adding error message to content.\")\n",
        "            if chapter_paragraphs_accumulator and not chapter_paragraphs_accumulator.endswith('\\n\\n'):\n",
        "                chapter_paragraphs_accumulator += \"\\n\\n\" # Ensure separation\n",
        "            chapter_paragraphs_accumulator += new_paragraphs\n",
        "\n",
        "            # Add the *description* of the event we just attempted to write to the global history\n",
        "            # Even if writing failed, log the attempt.\n",
        "            previous_events_history.append(f\"[{chapter_title}] {event_description}\")\n",
        "\n",
        "        # --- Optional Refinement Step ---\n",
        "        final_chapter_text = chapter_paragraphs_accumulator\n",
        "        if refiner_chain:\n",
        "            print(f\"   Refining chapter: {chapter_title}...\")\n",
        "            final_chapter_text = refiner_chain.run(\n",
        "                author=author, title=title, genre=genre, profile=profile, setting=setting,\n",
        "                themes_str=themes_str, plot=plot, chapter_name=chapter_title,\n",
        "                summary=chapter_summary, draft_text=chapter_paragraphs_accumulator\n",
        "            )\n",
        "            if final_chapter_text != chapter_paragraphs_accumulator:\n",
        "                 print(f\"   Refinement applied for '{chapter_title}'.\")\n",
        "            else:\n",
        "                 print(f\"   Refinement skipped or resulted in no changes for '{chapter_title}'.\")\n",
        "\n",
        "\n",
        "        # Store the fully assembled (and potentially refined) text for the chapter\n",
        "        book_content[chapter_title] = final_chapter_text\n",
        "        print(f\"--- Finished Chapter: {chapter_title} ---\")\n",
        "\n",
        "    print(\"\\n--- Book Writing Process Complete ---\")\n",
        "    return book_content\n",
        "\n",
        "# --- Document Writing Class ---\n",
        "\n",
        "class DocWriter:\n",
        "    def __init__(self, output_folder=OUTPUT_FOLDER):\n",
        "        self.output_folder = output_folder\n",
        "        os.makedirs(self.output_folder, exist_ok=True)\n",
        "        print(f\"Ensured output directory exists: {os.path.abspath(self.output_folder)}\")\n",
        "\n",
        "    def _sanitize_filename(self, name):\n",
        "        \"\"\"Removes or replaces characters invalid for filenames more aggressively.\"\"\"\n",
        "        if not isinstance(name, str): name = str(name)\n",
        "        # Remove invalid chars\n",
        "        name = re.sub(r'[\\\\/*?:\"<>|]', \"\", name)\n",
        "        # Replace spaces and multiple dots/hyphens\n",
        "        name = re.sub(r'\\s+', '_', name)\n",
        "        name = re.sub(r'[_.-]{2,}', '_', name)\n",
        "        # Trim leading/trailing whitespace/underscores/dots/hyphens\n",
        "        name = name.strip('._- ')\n",
        "        # Limit length\n",
        "        max_len = 180 # Slightly shorter for safety across filesystems\n",
        "        if len(name) > max_len:\n",
        "            # Try to keep the beginning and end\n",
        "            name = name[:max_len//2] + \"...\" + name[-(max_len//2 - 3):]\n",
        "        if not name:\n",
        "            name = \"Untitled_Novel\"\n",
        "        return name\n",
        "\n",
        "    def write_doc(self, book_content, chapter_dict, title, genre, author, themes_dict, setting):\n",
        "        \"\"\"Writes the generated book content to a .docx file with enhanced front matter.\"\"\"\n",
        "        print(\"\\n--- Assembling and Writing Document ---\")\n",
        "        doc = docx.Document()\n",
        "\n",
        "        # --- Enhanced Front Matter ---\n",
        "        doc.add_heading(title, level=0)\n",
        "        doc.add_paragraph(f\"Genre: {genre}\")\n",
        "        doc.add_paragraph(f\"Inspired by the style of: {author}\")\n",
        "        doc.add_paragraph(\"\\n\") # Add spacing\n",
        "\n",
        "        # Add Themes\n",
        "        doc.add_heading(\"Core Themes\", level=2)\n",
        "        themes_str = format_themes_string(themes_dict)\n",
        "        if themes_str == \"N/A\" or \"Error\" in themes_dict:\n",
        "             doc.add_paragraph(\"Themes could not be generated or parsed.\")\n",
        "        else:\n",
        "            for theme_name, theme_desc in themes_dict.items():\n",
        "                doc.add_paragraph(f\"- **{theme_name}:** {theme_desc}\", style='List Bullet')\n",
        "        doc.add_paragraph(\"\\n\")\n",
        "\n",
        "        # Add Setting Summary\n",
        "        doc.add_heading(\"Setting Summary\", level=2)\n",
        "        if setting.startswith(\"Error\"):\n",
        "             doc.add_paragraph(\"Setting description could not be generated.\")\n",
        "        else:\n",
        "             # Add setting description, potentially splitting into paragraphs\n",
        "             setting_paras = [p.strip() for p in setting.split('\\n') if p.strip()]\n",
        "             for para in setting_paras:\n",
        "                doc.add_paragraph(para)\n",
        "        doc.add_paragraph(\"\\n\")\n",
        "\n",
        "        # Add Table of Contents (Chapter List)\n",
        "        doc.add_heading(\"Chapters\", level=1)\n",
        "        sorted_chapter_items = chapter_dict.items() # Already sorted\n",
        "        for chapter_title, description in sorted_chapter_items:\n",
        "            doc.add_paragraph(f\"**{chapter_title}:** {description}\", style='List Bullet')\n",
        "        doc.add_page_break() # Page break after ToC\n",
        "\n",
        "        # --- Body ---\n",
        "        print(\"Adding chapter content to document...\")\n",
        "        total_chapters = len(sorted_chapter_items)\n",
        "        for i, (chapter_title, description) in enumerate(sorted_chapter_items):\n",
        "            chapter_heading = chapter_title.strip()\n",
        "            doc.add_heading(chapter_heading, level=1)\n",
        "            print(f\"  Adding Chapter {i+1}/{total_chapters}: {chapter_heading}\")\n",
        "\n",
        "            chapter_text = book_content.get(chapter_title, \"[Error: Chapter content not found]\")\n",
        "\n",
        "            # Add chapter text, splitting by double newlines used as separators\n",
        "            # Also handle single newlines within LLM-generated paragraphs gracefully\n",
        "            paragraphs = chapter_text.split('\\n\\n')\n",
        "            for para_block in paragraphs:\n",
        "                if para_block.strip():\n",
        "                    # Add paragraph, preserving single newlines within the block if desired\n",
        "                    # For standard docx, usually treat each block as one paragraph\n",
        "                    doc.add_paragraph(para_block.strip())\n",
        "\n",
        "            # Add a page break after each chapter for clear separation\n",
        "            if i < total_chapters - 1:\n",
        "                doc.add_page_break()\n",
        "            print(f\"    Added content for '{chapter_title}'\")\n",
        "\n",
        "        # --- Filename Creation ---\n",
        "        safe_basename = self._sanitize_filename(title)\n",
        "        safe_author = self._sanitize_filename(author)\n",
        "        safe_genre = self._sanitize_filename(genre.split('/')[0].split(',')[0])\n",
        "        filename = f\"{safe_basename}_by_{safe_author}_{safe_genre}.docx\"\n",
        "        output_path = os.path.join(self.output_folder, filename)\n",
        "\n",
        "        # --- Saving Document ---\n",
        "        try:\n",
        "            print(f\"\\nAttempting to save document to: {output_path}\")\n",
        "            doc.save(output_path)\n",
        "            print(f\"--- Document saved successfully! ---\")\n",
        "            return output_path # Return path if successful\n",
        "        except PermissionError:\n",
        "            print(f\"\\nERROR: Permission denied trying to save '{output_path}'.\")\n",
        "            print(\"Check file permissions or if the file is open elsewhere.\")\n",
        "            print(f\"Folder: {os.path.abspath(self.output_folder)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR saving document to {output_path}: {e}\")\n",
        "            traceback.print_exc()\n",
        "        return None # Return None if saving failed\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "def main():\n",
        "    process_start_time = time.time()\n",
        "    print(\"=============================================\")\n",
        "    print(\"=== ENHANCED NOVEL GENERATION SYSTEM V2 ===\")\n",
        "    print(f\"=== Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')} ===\")\n",
        "    print(f\"=== Using Model: {DEFAULT_MODEL} ===\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    # --- Configuration ---\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    print(f\"Output Folder: {os.path.abspath(OUTPUT_FOLDER)}\")\n",
        "\n",
        "    # --- Inputs ---\n",
        "    # ** IMPORTANT: Replace with the actual path to your PDF resume file **\n",
        "    # Ensure it's accessible relative to where you run the script, or provide an absolute path.\n",
        "    # It's currently expected inside the OUTPUT_FOLDER.\n",
        "    resume_filename = DEFAULT_RESUME_FILENAME\n",
        "    subject = (\"\"\"\n",
        "Kenji Tanaka, an unassuming yet brilliant strategy gamer and hobbyist survivalist, is abruptly summoned mid-match to the vibrant, chaotic fantasy world of Aethel. Due to a cosmic fluke in the summoning ritual, he's accidentally bestowed with a unique, god-like ability: an 'Administrative Interface' to the world's fundamental laws of magic, physics, and skills. Initially bewildered, Kenji, with his gamer mindset, quickly grasps that he can manipulate reality, learn and master skills instantaneously, and essentially 'debug' or 'mod' his own powers and even aspects of the world around him, bypassing all traditional limitations.\n",
        "\n",
        "The Kingdom of Eldoria, his summoners, expect a prophesied hero to combat the encroaching 'Demon Lord Malakor' and his monstrous legions. While Kenji has the raw power to be that hero, his methods are anything but conventional. He approaches epic quests like game levels, min-maxes his absurd abilities, exploits magical 'bugs,' and crafts hilariously overpowered 'builds' to resolve conflicts with shocking efficiency, often leaving both allies and enemies dumbfounded.\n",
        "\n",
        "As he navigates the politics of Eldoria, the expectations of being a 'Hero,' and the true nature of the 'Demon Lord' (who might be more than just a final boss), Kenji must also decide his ultimate goal: Is it to find a way back to his old life, or to fully embrace his newfound omnipotence in a world that feels like the ultimate immersive RPG? His journey is one of overwhelming power, clever outsmarting of ancient rules, and perhaps, accidentally reshaping Aethel in his own, uniquely optimized image.\"\"\")\n",
        "    author_style = 'Will Wight # (Author of \"Cradle\" series - excellent for power progression and action)'\n",
        "    genre = 'Isekai Fantasy / Overpowered Main Character / LitRPG Adventure Comedy'\n",
        "    # Set to True to enable the experimental refinement pass (uses more LLM calls)\n",
        "    ENABLE_REFINEMENT_PASS = False\n",
        "\n",
        "    print(\"\\n--- Input Parameters ---\")\n",
        "    print(f\"Resume File: {resume_filename} (Expected in: {OUTPUT_FOLDER})\")\n",
        "    print(f\"Subject: {subject[:150]}...\") # Print truncated subject\n",
        "    print(f\"Author Style Inspiration: {author_style}\")\n",
        "    print(f\"Genre(s): {genre}\")\n",
        "    print(f\"Refinement Pass Enabled: {ENABLE_REFINEMENT_PASS}\")\n",
        "    print(\"------------------------\")\n",
        "\n",
        "    # --- Instantiate Chains & Writer ---\n",
        "    try:\n",
        "        print(\"\\n--- Initializing Core Components ---\")\n",
        "        # Note: LLMs are created within each chain now\n",
        "        main_character_chain = MainCharacterChain()\n",
        "        setting_chain = SettingChain()\n",
        "        theme_chain = ThemeChain()\n",
        "        title_chain = TitleChain()\n",
        "        plot_chain = PlotChain()\n",
        "        chapters_chain = ChaptersChain()\n",
        "        # EventChain, WriterChain, RefinementChain instantiated later\n",
        "        doc_writer = DocWriter(output_folder=OUTPUT_FOLDER)\n",
        "        print(\"--- Core Components Initialized Successfully ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFATAL ERROR during component initialization: {e}\")\n",
        "        # Error message likely printed during LLM creation attempt\n",
        "        return # Stop execution\n",
        "\n",
        "    # --- Generate Novel Components Sequentially ---\n",
        "    generation_successful = True\n",
        "    try:\n",
        "        # 1. Generate Profile\n",
        "        print(\"\\n--- Step 1: Generating Main Character Profile ---\")\n",
        "        start = time.time()\n",
        "        profile = main_character_chain.run(resume_filename, genre)\n",
        "        print(f\"Profile Generation Time: {time.time() - start:.2f}s\")\n",
        "        if profile.startswith(\"Error:\"):\n",
        "            print(f\"PROFILE GENERATION FAILED: {profile}\")\n",
        "            generation_successful = False\n",
        "        else:\n",
        "            print(f\"Profile Generated:\\n---\\n{profile}\\n---\")\n",
        "\n",
        "        # 2. Generate Setting (Requires Profile)\n",
        "        setting = \"Error: Setting generation skipped due to profile error.\"\n",
        "        if generation_successful:\n",
        "            print(\"\\n--- Step 2: Generating Setting Description ---\")\n",
        "            start = time.time()\n",
        "            setting = setting_chain.run(subject, genre, profile)\n",
        "            print(f\"Setting Generation Time: {time.time() - start:.2f}s\")\n",
        "            if setting.startswith(\"Error:\"):\n",
        "                print(f\"SETTING GENERATION FAILED: {setting}\")\n",
        "                generation_successful = False # Allow continuing, but flag issue\n",
        "            else:\n",
        "                print(f\"Setting Generated:\\n---\\n{setting}\\n---\")\n",
        "\n",
        "        # 3. Generate Themes (Requires Profile & Setting)\n",
        "        themes_dict = {\"Error\": \"Theme generation skipped due to prior errors.\"}\n",
        "        themes_str = \"N/A\"\n",
        "        if generation_successful: # Only proceed if profile/setting likely okay\n",
        "            print(\"\\n--- Step 3: Generating Core Themes ---\")\n",
        "            start = time.time()\n",
        "            themes_dict = theme_chain.run(subject, genre, profile, setting)\n",
        "            print(f\"Theme Generation Time: {time.time() - start:.2f}s\")\n",
        "            if \"Error\" in themes_dict:\n",
        "                print(f\"THEME GENERATION/PARSING FAILED: {themes_dict['Error']}\")\n",
        "                # Don't stop, but note the failure\n",
        "            else:\n",
        "                themes_str = format_themes_string(themes_dict)\n",
        "                print(f\"Themes Generated:\\n---\\n{themes_str}\\n---\")\n",
        "\n",
        "        # 4. Generate Title (Requires Profile, Setting, Themes)\n",
        "        title = \"Error - Title Generation Failed\"\n",
        "        if generation_successful: # Proceed even if themes failed, using \"N/A\"\n",
        "            print(\"\\n--- Step 4: Generating Novel Title ---\")\n",
        "            start = time.time()\n",
        "            title = title_chain.run(subject, genre, author_style, profile, setting, themes_str)\n",
        "            print(f\"Title Generation Time: {time.time() - start:.2f}s\")\n",
        "            if title.startswith(\"Error\") or \"Placeholder\" in title:\n",
        "                 print(f\"TITLE GENERATION FAILED/PLACEHOLDER: {title}\")\n",
        "                 # Allow continuing with placeholder/error title\n",
        "            else:\n",
        "                 print(f\"Title Generated: '{title}'\")\n",
        "\n",
        "        # 5. Generate Plot (Requires Profile, Setting, Themes, Title)\n",
        "        plot = \"Error: Plot generation skipped due to prior errors.\"\n",
        "        if generation_successful:\n",
        "            print(\"\\n--- Step 5: Generating Detailed Plot Outline ---\")\n",
        "            start = time.time()\n",
        "            plot = plot_chain.run(subject, genre, author_style, profile, title, setting, themes_str)\n",
        "            print(f\"Plot Generation Time: {time.time() - start:.2f}s\")\n",
        "            if plot.startswith(\"Error\"):\n",
        "                print(f\"PLOT GENERATION FAILED: {plot}\")\n",
        "                generation_successful = False # Cannot proceed without plot\n",
        "            else:\n",
        "                print(f\"Plot Generated:\\n---\\n{plot}\\n---\")\n",
        "\n",
        "        # 6. Generate Chapter List (Requires Plot, Profile, Setting, Themes, Title)\n",
        "        chapter_dict = {}\n",
        "        if generation_successful:\n",
        "            print(\"\\n--- Step 6: Generating Chapter List & Summaries ---\")\n",
        "            start = time.time()\n",
        "            # chapter_dict should be { 'Chapter 1': 'Description...', ... } and sorted\n",
        "            chapter_dict = chapters_chain.run(subject, genre, author_style, profile, title, plot, setting, themes_str)\n",
        "            print(f\"Chapter List Generation Time: {time.time() - start:.2f}s\")\n",
        "            if not chapter_dict:\n",
        "                 print(\"ERROR: Failed to generate or parse chapters. Cannot write book content.\")\n",
        "                 generation_successful = False\n",
        "            else:\n",
        "                 print(\"Chapters Generated & Parsed:\")\n",
        "                 for chap_title, chap_desc in chapter_dict.items(): # Already sorted\n",
        "                      print(f\"  - {chap_title}: {chap_desc}\")\n",
        "\n",
        "        # 7. Generate Events for Each Chapter (Requires Plot, Profile, Themes, Chapters)\n",
        "        event_dict = {}\n",
        "        if generation_successful:\n",
        "            print(\"\\n--- Step 7: Generating Events for All Chapters ---\")\n",
        "            start = time.time()\n",
        "            event_dict = generate_events_for_all_chapters(plot, profile, themes_str, chapter_dict, author_style)\n",
        "            print(f\"Event Generation Time: {time.time() - start:.2f}s\")\n",
        "            if not any(event_dict.values()): # Check if *any* events were generated\n",
        "                print(\"CRITICAL WARNING: Failed to generate events for *any* chapter. Book content will likely be empty or skipped.\")\n",
        "                # Allow proceeding, but the book will be mostly empty chapters\n",
        "\n",
        "        # --- Write the Book Content ---\n",
        "        book_content = {}\n",
        "        if generation_successful and chapter_dict: # Need chapters to write\n",
        "            print(\"\\n--- Step 8: Writing Full Book Content ---\")\n",
        "            start = time.time()\n",
        "            book_content = write_book(\n",
        "                genre, author_style, title, profile, plot, setting, themes_str,\n",
        "                chapter_dict, event_dict,\n",
        "                refine_chapters=ENABLE_REFINEMENT_PASS\n",
        "            )\n",
        "            print(f\"Book Writing Time: {time.time() - start:.2f}s\")\n",
        "        elif not generation_successful:\n",
        "             print(\"\\n--- Skipping Book Writing due to errors in previous steps ---\")\n",
        "        else:\n",
        "             print(\"\\n--- Skipping Book Writing as no chapters were generated ---\")\n",
        "\n",
        "\n",
        "        # --- Save to Document ---\n",
        "        if book_content: # Only save if some content was generated\n",
        "            print(\"\\n--- Step 9: Saving Document ---\")\n",
        "            start = time.time()\n",
        "            saved_path = doc_writer.write_doc(book_content, chapter_dict, title, genre, author_style, themes_dict, setting)\n",
        "            print(f\"Document Saving Time: {time.time() - start:.2f}s\")\n",
        "            if saved_path:\n",
        "                print(f\"\\nSuccess! Novel saved to: {saved_path}\")\n",
        "            else:\n",
        "                print(\"\\nFailed to save the document.\")\n",
        "        else:\n",
        "            print(\"\\n--- Skipping Document Saving as no book content was generated ---\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "         print(f\"\\nCRITICAL FILE ERROR: {e}\")\n",
        "         print(f\"Please ensure the required file ('{resume_filename}') exists in the correct directory.\")\n",
        "         print(f\"Expected location: '{os.path.abspath(OUTPUT_FOLDER)}'\")\n",
        "         generation_successful = False\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- AN UNEXPECTED ERROR OCCURRED DURING NOVEL GENERATION ---\")\n",
        "        print(f\"Error Type: {type(e).__name__}\")\n",
        "        print(f\"Error Details: {e}\")\n",
        "        print(\"--- Traceback ---\")\n",
        "        traceback.print_exc()\n",
        "        print(\"-----------------\")\n",
        "        generation_successful = False\n",
        "\n",
        "    finally:\n",
        "        end_time = time.time()\n",
        "        total_time = end_time - process_start_time\n",
        "        print(\"\\n============================================\")\n",
        "        print(f\"=== NOVEL GENERATION PROCESS {'FINISHED' if generation_successful else 'FINISHED WITH ERRORS'} ===\")\n",
        "        print(f\"=== Total Execution Time: {total_time:.2f} seconds ===\")\n",
        "        print(\"============================================\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure you have Ollama running with the specified DEFAULT_MODEL pulled.\n",
        "    # Example: `ollama run gemma2` in your terminal.\n",
        "    # Ensure the resume PDF (e.g., 'divi_1.pdf') is in the './docs_generated/' folder\n",
        "    # or update DEFAULT_RESUME_FILENAME and OUTPUT_FOLDER constants.\n",
        "    main()"
      ],
      "metadata": {
        "id": "wHeOmn5E-Qgc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}